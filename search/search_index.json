{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Grafito","text":"<p>Grafito is a SQLite-based property graph database with a Cypher-like query language, vector search, and full-text search.</p>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>Property graph model with labels, relationships, and JSON properties</li> <li>Cypher queries plus a Python API</li> <li>Vector and hybrid search (ANN backends supported)</li> <li>FTS5-based full-text search</li> <li>Import tools (Neo4j dumps, JSON, NetworkX)</li> </ul>"},{"location":"#get-started","title":"Get Started","text":"<ul> <li>Install</li> <li>Quick Start</li> <li>Core Concepts</li> </ul>"},{"location":"#key-sections","title":"Key Sections","text":"<ul> <li>Database API</li> <li>Cypher Guide</li> <li>Vector Search</li> <li>Embeddings</li> <li>APOC Procedures</li> </ul>"},{"location":"#examples","title":"Examples","text":"<ul> <li>Social Network</li> <li>Company Structure</li> <li>Northwind</li> </ul>"},{"location":"advanced/architecture/","title":"Advanced: Architecture","text":"<p>Grafito is a SQLite-backed property graph database with a Cypher-like query engine and pluggable indexes.</p>"},{"location":"advanced/architecture/#high-level-components","title":"High-Level Components","text":"<ul> <li>Storage: SQLite database, JSON properties stored as text.</li> <li>Schema: Tables for nodes, labels, relationships, indexes, constraints.</li> <li>Cypher Engine: Parser + executor + evaluator for graph queries.</li> <li>Indexes:</li> <li>Property indexes</li> <li>Full-text search (FTS5)</li> <li>Vector/ANN backends</li> <li>Integrations: Optional helpers for NetworkX, RDF, visualization.</li> </ul>"},{"location":"advanced/architecture/#core-modules","title":"Core Modules","text":"<ul> <li><code>grafito/database.py</code>: Main API surface (<code>GrafitoDatabase</code>).</li> <li><code>grafito/schema.py</code>: SQLite schema and initialization.</li> <li><code>grafito/cypher/</code>: Lexer, parser, AST, and execution engine.</li> <li><code>grafito/indexers/</code>: Property index metadata and helpers.</li> <li><code>grafito/text_index/</code>: SQLite FTS and optional BM25S integration.</li> <li><code>grafito/vector_index/</code>: ANN backends and persistence.</li> <li><code>grafito/embedding_functions/</code>: Embedding provider integrations.</li> </ul>"},{"location":"advanced/architecture/#execution-flow-cypher","title":"Execution Flow (Cypher)","text":"<p>1) Parse query into an AST. 2) Execute clauses in order, carrying intermediate results. 3) Evaluate expressions and functions with the evaluator. 4) Apply filters and ordering. 5) Return result rows.</p>"},{"location":"advanced/architecture/#traversal","title":"Traversal","text":"<p>Traversal and shortest-path functionality are implemented in <code>grafito/query.py</code> (BFS/DFS) and used by the database API.</p>"},{"location":"advanced/architecture/#index-lifecycle","title":"Index Lifecycle","text":"<p>Vector indexes and text indexes are registered in the database instance, stored as metadata, and rebuilt/loaded on demand.</p>"},{"location":"advanced/performance/","title":"Advanced: Performance","text":"<p>Grafito performance depends on SQLite configuration, index usage, and query patterns. This page summarizes practical tips.</p>"},{"location":"advanced/performance/#general-tips","title":"General Tips","text":"<ul> <li>Use transactions for bulk inserts (<code>db.begin_transaction()</code> / <code>db.commit()</code>).</li> <li>Keep properties lean; avoid large blobs in node properties.</li> <li>Prefer targeted labels and relationship types to reduce scan size.</li> </ul>"},{"location":"advanced/performance/#indexing","title":"Indexing","text":"<ul> <li>Create property indexes for frequently filtered properties.</li> <li>Use full-text search for text-heavy filtering instead of <code>CONTAINS</code>.</li> <li>Use vector indexes for semantic search at scale.</li> </ul>"},{"location":"advanced/performance/#text-search-fts5","title":"Text Search (FTS5)","text":"<ul> <li>Ensure your SQLite build supports FTS5.</li> <li>Rebuild the FTS index after bulk updates if needed.</li> </ul>"},{"location":"advanced/performance/#vector-indexing","title":"Vector Indexing","text":"<ul> <li>Choose an ANN backend appropriate for your dataset size.</li> <li>Persist vector indexes on disk for faster startups.</li> <li>Rebuild indexes after large batch updates.</li> </ul>"},{"location":"advanced/performance/#query-planning","title":"Query Planning","text":"<ul> <li>Filter early (labels/types/properties) and avoid wide graph traversals.</li> <li>Keep shortest-path searches bounded where possible.</li> </ul>"},{"location":"advanced/performance/#operational-notes","title":"Operational Notes","text":"<ul> <li>For large workloads, use a file-backed database instead of <code>:memory:</code>.</li> <li>Consider WAL mode in SQLite for better concurrent reads.</li> </ul>"},{"location":"advanced/schema/","title":"Advanced: SQLite Schema","text":"<p>Grafito stores the property graph in SQLite using a normalized schema. See <code>grafito/schema.py</code> for the source of truth.</p>"},{"location":"advanced/schema/#core-tables","title":"Core Tables","text":""},{"location":"advanced/schema/#nodes","title":"nodes","text":"<p>Stores graph nodes.</p> <ul> <li><code>id</code> (INTEGER PRIMARY KEY)</li> <li><code>created_at</code> (REAL, julian day)</li> <li><code>properties</code> (TEXT, JSON)</li> <li><code>uri</code> (TEXT, optional)</li> </ul>"},{"location":"advanced/schema/#labels","title":"labels","text":"<p>Normalized label names.</p> <ul> <li><code>id</code> (INTEGER PRIMARY KEY)</li> <li><code>name</code> (TEXT UNIQUE, case-insensitive)</li> </ul>"},{"location":"advanced/schema/#node_labels","title":"node_labels","text":"<p>Many-to-many table between nodes and labels.</p> <ul> <li><code>node_id</code> (INTEGER, FK -&gt; nodes)</li> <li><code>label_id</code> (INTEGER, FK -&gt; labels)</li> </ul>"},{"location":"advanced/schema/#relationships","title":"relationships","text":"<p>Directed edges between nodes.</p> <ul> <li><code>id</code> (INTEGER PRIMARY KEY)</li> <li><code>source_node_id</code> (INTEGER, FK -&gt; nodes)</li> <li><code>target_node_id</code> (INTEGER, FK -&gt; nodes)</li> <li><code>type</code> (TEXT)</li> <li><code>created_at</code> (REAL)</li> <li><code>properties</code> (TEXT, JSON)</li> <li><code>uri</code> (TEXT, optional)</li> </ul>"},{"location":"advanced/schema/#index-metadata","title":"Index Metadata","text":""},{"location":"advanced/schema/#property_indexes","title":"property_indexes","text":"<p>Metadata for property indexes and uniqueness.</p> <ul> <li><code>name</code> (TEXT PRIMARY KEY)</li> <li><code>entity</code> (TEXT)</li> <li><code>label_or_type</code> (TEXT)</li> <li><code>property</code> (TEXT)</li> <li><code>unique_flag</code> (INTEGER)</li> </ul>"},{"location":"advanced/schema/#property_constraints","title":"property_constraints","text":"<p>Schema constraints registry.</p> <ul> <li><code>name</code> (TEXT PRIMARY KEY)</li> <li><code>entity</code> (TEXT)</li> <li><code>label_or_type</code> (TEXT)</li> <li><code>property</code> (TEXT)</li> <li><code>constraint_type</code> (TEXT)</li> <li><code>type_name</code> (TEXT, optional)</li> </ul>"},{"location":"advanced/schema/#vector-indexing","title":"Vector Indexing","text":""},{"location":"advanced/schema/#vector_indexes","title":"vector_indexes","text":"<p>Metadata for vector indexes.</p> <ul> <li><code>name</code> (TEXT PRIMARY KEY)</li> <li><code>dim</code> (INTEGER)</li> <li><code>backend</code> (TEXT)</li> <li><code>method</code> (TEXT)</li> <li><code>options</code> (TEXT, JSON)</li> </ul>"},{"location":"advanced/schema/#vector_entries","title":"vector_entries","text":"<p>Optional persisted vectors.</p> <ul> <li><code>index_name</code> (TEXT)</li> <li><code>node_id</code> (INTEGER)</li> <li><code>vector</code> (TEXT, JSON)</li> <li><code>updated_at</code> (REAL)</li> </ul>"},{"location":"advanced/schema/#full-text-search-fts5","title":"Full-Text Search (FTS5)","text":""},{"location":"advanced/schema/#fts_index-virtual-table","title":"fts_index (virtual table)","text":"<ul> <li><code>entity_type</code> (<code>node</code> or <code>relationship</code>)</li> <li><code>entity_id</code> (INTEGER)</li> <li><code>label_type</code> (label or relationship type)</li> <li><code>content</code> (TEXT)</li> </ul>"},{"location":"advanced/schema/#fts_config","title":"fts_config","text":"<p>Defines which properties are indexed.</p> <ul> <li><code>entity_type</code> (TEXT)</li> <li><code>label_type</code> (TEXT, nullable)</li> <li><code>property</code> (TEXT)</li> <li><code>weight</code> (REAL, optional)</li> </ul> <p>FTS content is maintained via triggers on <code>nodes</code>, <code>node_labels</code>, and <code>relationships</code>.</p>"},{"location":"api/cypher/","title":"Cypher Execution API","text":""},{"location":"api/cypher/#grafito.cypher.executor.CypherExecutor","title":"<code>grafito.cypher.executor.CypherExecutor</code>","text":"<p>Executes Cypher query AST against a GrafitoDatabase.</p> Source code in <code>grafito/cypher/executor.py</code> <pre><code>class CypherExecutor:\n    \"\"\"Executes Cypher query AST against a GrafitoDatabase.\"\"\"\n\n    def __init__(self, db: GrafitoDatabase):\n        self.db = db\n\n    def _make_evaluator(self, context: dict[str, Any]) -&gt; ExpressionEvaluator:\n        \"\"\"Build an expression evaluator with pattern comprehension support.\"\"\"\n        return ExpressionEvaluator(context, pattern_matcher=self._pattern_comprehension_matcher)\n\n    def _evaluate_properties(\n        self,\n        properties: dict[str, Any] | None,\n        context: dict[str, Any] | None,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Evaluate property map expressions against the current context.\"\"\"\n        if not properties:\n            return {}\n        evaluator = self._make_evaluator(context or {})\n        evaluated: dict[str, Any] = {}\n        for key, expr in properties.items():\n            if isinstance(expr, Expression):\n                evaluated[key] = evaluator.evaluate(expr)\n            else:\n                evaluated[key] = expr\n        return evaluated\n\n    def _pattern_comprehension_matcher(self, expr: PatternComprehension, context: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"Evaluate a pattern comprehension against the current context.\"\"\"\n        return self._evaluate_pattern_comprehension(expr, context)\n\n    def _evaluate_pattern_comprehension(self, expr: PatternComprehension, context: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"Evaluate a pattern comprehension by matching the pattern and projecting results.\"\"\"\n        matches = self._match_pattern(expr.pattern)\n        results = []\n\n        for match in matches:\n            if not self._pattern_bindings_match(context, match):\n                continue\n\n            merged = context.copy()\n            merged.update(match)\n            evaluator = self._make_evaluator(merged)\n\n            if expr.where_expr is not None:\n                try:\n                    if not evaluator.evaluate(expr.where_expr):\n                        continue\n                except CypherExecutionError:\n                    continue\n\n            results.append(self._serialize_value(evaluator.evaluate(expr.projection)))\n\n        return results\n\n    def _pattern_bindings_match(self, context: dict[str, Any], match: dict[str, Any]) -&gt; bool:\n        \"\"\"Check if matched variables are compatible with existing context bindings.\"\"\"\n        for name, value in match.items():\n            if name not in context:\n                continue\n            if not self._same_entity(context[name], value):\n                return False\n        return True\n\n    def _same_entity(self, left: Any, right: Any) -&gt; bool:\n        \"\"\"Compare two bound entities by id when possible.\"\"\"\n        if left is right:\n            return True\n        left_id = self._entity_id(left)\n        right_id = self._entity_id(right)\n        if left_id is not None and right_id is not None:\n            return left_id == right_id\n        return left == right\n\n    def _entity_id(self, value: Any) -&gt; Any:\n        \"\"\"Extract an entity id from nodes/relationships or serialized dicts.\"\"\"\n        if hasattr(value, 'id'):\n            return value.id\n        if isinstance(value, dict) and 'id' in value:\n            return value['id']\n        return None\n\n    def execute(self, query: Query) -&gt; list[dict]:\n        \"\"\"Execute a query and return results.\n\n        Args:\n            query: Parsed Query AST\n\n        Returns:\n            List of result dictionaries\n\n        Raises:\n            CypherExecutionError: If execution fails\n        \"\"\"\n        if query.union_clauses:\n            return self._execute_union(query)\n\n        if isinstance(query.clause, SubqueryClause):\n            return self._execute_subquery(query.clause, [])\n        if isinstance(query.clause, ProcedureCallClause):\n            return self._execute_procedure_call(query.clause, [])\n\n        # Check if multi-clause query (with WITH)\n        if query.clauses:\n            return self._execute_multi_clause(query.clauses, initial_results=None)\n\n        # Single clause query\n        if isinstance(query.clause, CreateClause):\n            return self._execute_create(query.clause)\n        elif isinstance(query.clause, MergeClause):\n            return self._execute_merge(query.clause)\n        elif isinstance(query.clause, MatchClause):\n            return self._execute_match(query.clause)\n        elif isinstance(query.clause, UnwindClause):\n            return self._execute_unwind(query.clause, [{}])\n        elif isinstance(query.clause, WithClause):\n            return self._execute_with(query.clause, [{}])\n        elif isinstance(query.clause, CreateIndexClause):\n            return self._execute_create_index(query.clause)\n        elif isinstance(query.clause, DropIndexClause):\n            return self._execute_drop_index(query.clause)\n        elif isinstance(query.clause, ShowIndexesClause):\n            return self._execute_show_indexes(query.clause)\n        elif isinstance(query.clause, CreateConstraintClause):\n            return self._execute_create_constraint(query.clause)\n        elif isinstance(query.clause, DropConstraintClause):\n            return self._execute_drop_constraint(query.clause)\n        elif isinstance(query.clause, ShowConstraintsClause):\n            return self._execute_show_constraints(query.clause)\n        elif isinstance(query.clause, ForeachClause):\n            return self._execute_foreach(query.clause, [{}])\n        else:\n            raise CypherExecutionError(f\"Unknown clause type: {type(query.clause)}\")\n\n    def _execute_union(self, query: Query) -&gt; list[dict]:\n        \"\"\"Execute UNION/UNION ALL queries.\"\"\"\n        results = self.execute(Query(clause=query.clause, clauses=query.clauses))\n\n        for union_clause in query.union_clauses:\n            union_results = self.execute(union_clause.query)\n            if union_clause.all:\n                results.extend(union_results)\n            else:\n                results = self._union_distinct(results, union_results)\n\n        return results\n\n    def _union_distinct(self, left: list[dict], right: list[dict]) -&gt; list[dict]:\n        \"\"\"Return union of two result sets with distinct rows.\"\"\"\n        seen = {self._freeze_result(row) for row in left}\n        combined = left[:]\n        for row in right:\n            frozen = self._freeze_result(row)\n            if frozen in seen:\n                continue\n            seen.add(frozen)\n            combined.append(row)\n        return combined\n\n    def _freeze_result(self, value: Any) -&gt; Any:\n        \"\"\"Convert results to hashable structures for UNION distinct.\"\"\"\n        if isinstance(value, dict):\n            return tuple(sorted((k, self._freeze_result(v)) for k, v in value.items()))\n        if isinstance(value, list):\n            return tuple(self._freeze_result(v) for v in value)\n        return value\n\n    def _execute_multi_clause(self, clauses: list, initial_results: list[dict] | None = None) -&gt; list[dict]:\n        \"\"\"Execute multi-clause query with WITH pipeline.\n\n        Args:\n            clauses: List of clause AST nodes (MATCH, WITH, etc.)\n\n        Returns:\n            Final result set\n\n        The WITH clause acts as a pipeline:\n        - MATCH (n) returns results\n        - WITH filters/transforms those results\n        - Next MATCH uses WITH results as context\n        \"\"\"\n        results = initial_results if initial_results is not None else []\n\n        for i, clause in enumerate(clauses):\n            if not results and isinstance(\n                clause,\n                (WithClause, UnwindClause, LoadCsvClause, ProcedureCallClause, ForeachClause, SubqueryClause),\n            ):\n                results = [{}]\n            if isinstance(clause, MatchClause):\n                # Execute MATCH with current context\n                new_results = self._execute_match(clause, context=results)\n                results = new_results\n            elif isinstance(clause, CreateClause):\n                new_results = self._execute_create(clause, context=results if results else None)\n                results = new_results\n            elif isinstance(clause, MergeClause):\n                # Execute MERGE\n                new_results = self._execute_merge(clause, context=results if results else None)\n                results = new_results\n            elif isinstance(clause, WithClause):\n                # Apply WITH transformation to current results\n                results = self._execute_with(clause, results)\n            elif isinstance(clause, UnwindClause):\n                results = self._execute_unwind(clause, results)\n            elif isinstance(clause, LoadCsvClause):\n                results = self._execute_load_csv(clause, results)\n            elif isinstance(clause, ForeachClause):\n                results = self._execute_foreach(clause, results)\n            elif isinstance(clause, SetClause):\n                self._execute_set(results, clause)\n            elif isinstance(clause, ReturnClause):\n                results = self._apply_return(results, clause)\n            elif isinstance(clause, SubqueryClause):\n                results = self._execute_subquery(clause, results)\n            elif isinstance(clause, ProcedureCallClause):\n                results = self._execute_procedure_call(clause, results)\n            else:\n                raise CypherExecutionError(f\"Unknown clause type in multi-clause query: {type(clause)}\")\n\n        return results\n\n    def _execute_subquery(self, clause: SubqueryClause, input_results: list[dict]) -&gt; list[dict]:\n        \"\"\"Execute CALL { ... } subquery with scoped variables.\"\"\"\n        if not input_results:\n            input_results = [{}]\n\n        output = []\n        for row in input_results:\n            sub_results = self._execute_query_with_context(clause.query, [row])\n            for sub_row in sub_results:\n                merged = row.copy()\n                merged.update(sub_row)\n                output.append(merged)\n\n        return output\n\n    def _execute_procedure_call(\n        self,\n        clause: ProcedureCallClause,\n        input_results: list[dict],\n    ) -&gt; list[dict]:\n        \"\"\"Execute CALL procedure with optional YIELD projection.\"\"\"\n        if not input_results:\n            input_results = [{}]\n\n        output = []\n        for row in input_results:\n            evaluator = self._make_evaluator(row)\n            args = [evaluator.evaluate(arg) for arg in clause.arguments]\n            proc_results = self._invoke_procedure(clause.name, args)\n            if not proc_results:\n                continue\n            for proc_row in proc_results:\n                if clause.yield_items:\n                    projected = {key: proc_row.get(key) for key in clause.yield_items}\n                else:\n                    projected = proc_row\n                merged = row.copy()\n                merged.update(projected)\n                output.append(merged)\n        return output\n\n    def _invoke_procedure(self, name: str, args: list[Any]) -&gt; list[dict]:\n        \"\"\"Dispatch supported procedures by name.\"\"\"\n        lower_name = name.lower()\n        if lower_name == \"db.vector.search\":\n            if len(args) &lt; 2:\n                raise CypherExecutionError(\"db.vector.search expects at least index and vector\")\n            index = args[0]\n            vector = args[1]\n            k = args[2] if len(args) &gt; 2 else None\n            options = args[3] if len(args) &gt; 3 else None\n            if not isinstance(index, str):\n                raise CypherExecutionError(\"db.vector.search index must be a string\")\n            if not isinstance(vector, list):\n                raise CypherExecutionError(\"db.vector.search vector must be a list\")\n            if options is not None and not isinstance(options, dict):\n                raise CypherExecutionError(\"db.vector.search options must be a map\")\n            options = options or {}\n            candidate_multiplier = options.get(\"candidate_multiplier\")\n            reranker_name = options.get(\"reranker\")\n            if candidate_multiplier is not None and not isinstance(candidate_multiplier, int):\n                raise CypherExecutionError(\"db.vector.search candidate_multiplier must be an integer\")\n            if reranker_name is not None and not isinstance(reranker_name, str):\n                raise CypherExecutionError(\"db.vector.search reranker must be a string\")\n            properties_filter = self._coerce_vector_properties_filter(options.get(\"properties\"))\n            rerank_flag = bool(options.get(\"rerank\", False) or reranker_name is not None)\n            results = self.db.semantic_search(\n                vector,\n                k=k,\n                index=index,\n                filter_labels=options.get(\"labels\"),\n                filter_props=properties_filter,\n                rerank=rerank_flag,\n                reranker=reranker_name,\n                candidate_multiplier=candidate_multiplier,\n            )\n            return [{\"node\": row[\"node\"], \"score\": row[\"score\"]} for row in results]\n\n        if lower_name == \"db.uri_index.create\":\n            if len(args) &lt; 1:\n                raise CypherExecutionError(\"db.uri_index.create expects entity ('node' or 'relationship')\")\n            entity = args[0]\n            unique = args[1] if len(args) &gt; 1 else True\n            name = args[2] if len(args) &gt; 2 else None\n            if not isinstance(entity, str):\n                raise CypherExecutionError(\"db.uri_index.create entity must be a string\")\n            if unique is not None and not isinstance(unique, bool):\n                raise CypherExecutionError(\"db.uri_index.create unique must be a boolean\")\n            if name is not None and not isinstance(name, str):\n                raise CypherExecutionError(\"db.uri_index.create name must be a string\")\n            entity_lower = entity.lower()\n            if entity_lower in {\"node\", \"nodes\"}:\n                index_name = self.db.create_node_uri_index(unique=bool(unique), name=name)\n            elif entity_lower in {\"relationship\", \"relationships\"}:\n                index_name = self.db.create_relationship_uri_index(unique=bool(unique), name=name)\n            else:\n                raise CypherExecutionError(\"db.uri_index.create entity must be 'node' or 'relationship'\")\n            return [{\"name\": index_name}]\n\n        if lower_name == \"apoc.load.jsonarray\":\n            if len(args) != 1:\n                raise CypherExecutionError(\"apoc.load.jsonArray expects 1 argument\")\n            source = args[0]\n            if not isinstance(source, str):\n                raise CypherExecutionError(\"apoc.load.jsonArray expects a string path or URL\")\n            data = self._load_json_from_source(source)\n            if not isinstance(data, list):\n                raise CypherExecutionError(\"apoc.load.jsonArray expects a JSON array\")\n            return [{\"value\": item} for item in data]\n\n        if lower_name == \"apoc.load.json\":\n            if len(args) != 1:\n                raise CypherExecutionError(\"apoc.load.json expects 1 argument\")\n            source = args[0]\n            if not isinstance(source, str):\n                raise CypherExecutionError(\"apoc.load.json expects a string path or URL\")\n            data = self._load_json_from_source(source)\n            if data is None:\n                return []\n            if isinstance(data, list):\n                return [{\"value\": item} for item in data]\n            return [{\"value\": data}]\n\n        if lower_name == \"apoc.load.jsonparams\":\n            if len(args) not in (3, 4):\n                raise CypherExecutionError(\"apoc.load.jsonParams expects 3 or 4 arguments\")\n            source = args[0]\n            params = args[1]\n            headers = args[2]\n            options = args[3] if len(args) == 4 else None\n            if not isinstance(source, str):\n                raise CypherExecutionError(\"apoc.load.jsonParams expects a string path or URL\")\n            if not isinstance(params, dict):\n                raise CypherExecutionError(\"apoc.load.jsonParams expects a params map\")\n            if not isinstance(headers, dict):\n                raise CypherExecutionError(\"apoc.load.jsonParams expects a headers map\")\n            if options is not None and not isinstance(options, dict):\n                raise CypherExecutionError(\"apoc.load.jsonParams options must be a map\")\n            url = self._apply_query_params(source, params)\n            data = self._load_json_from_source(url, headers=headers, options=options)\n            if data is None:\n                return []\n            if isinstance(data, list):\n                return [{\"value\": item} for item in data]\n            return [{\"value\": data}]\n\n        if lower_name == \"apoc.import.json\":\n            if len(args) not in (1, 2):\n                raise CypherExecutionError(\"apoc.import.json expects 1 or 2 arguments\")\n            source = args[0]\n            options = args[1] if len(args) == 2 else None\n            if not isinstance(source, (str, bytes, bytearray)):\n                raise CypherExecutionError(\"apoc.import.json expects a string path/URL or bytes\")\n            if options is not None and not isinstance(options, dict):\n                raise CypherExecutionError(\"apoc.import.json options must be a map\")\n\n            payload = self._load_import_text_with_options(source, options)\n            if payload is None:\n                return []\n            entries = self._parse_import_payload(payload)\n\n            id_field = (options or {}).get(\"idField\", \"id\")\n            labels_field = (options or {}).get(\"labelsField\", \"labels\")\n            props_field = (options or {}).get(\"propertiesField\", \"properties\")\n            rel_type_field = (options or {}).get(\"relTypeField\", \"label\")\n            start_field = (options or {}).get(\"startField\", \"start\")\n            end_field = (options or {}).get(\"endField\", \"end\")\n            type_field = (options or {}).get(\"typeField\", \"type\")\n\n            node_lookup: dict[Any, int] = {}\n            created_nodes = 0\n            created_rels = 0\n\n            for entry in entries:\n                if not isinstance(entry, dict):\n                    raise CypherExecutionError(\"apoc.import.json entries must be objects\")\n                entry_type = entry.get(type_field)\n                is_relationship = False\n                if isinstance(entry_type, str) and entry_type.lower() in (\"relationship\", \"rel\", \"edge\"):\n                    is_relationship = True\n                if entry_type is None and (start_field in entry or end_field in entry):\n                    is_relationship = True\n\n                if not is_relationship:\n                    labels = self._normalize_import_labels(entry.get(labels_field))\n                    props = self._normalize_import_properties(entry.get(props_field))\n                    node = self.db.create_node(labels=labels, properties=props)\n                    created_nodes += 1\n                    node_id = entry.get(id_field)\n                    if node_id is not None:\n                        node_lookup[node_id] = node.id\n                    continue\n\n                start_ref = self._resolve_import_ref(entry.get(start_field))\n                end_ref = self._resolve_import_ref(entry.get(end_field))\n                if start_ref is None or end_ref is None:\n                    raise CypherExecutionError(\"apoc.import.json relationships need start/end\")\n                if start_ref not in node_lookup or end_ref not in node_lookup:\n                    raise CypherExecutionError(\"apoc.import.json relationship references unknown nodes\")\n                rel_type = entry.get(rel_type_field) or entry.get(\"type\") or \"RELATED_TO\"\n                rel_props = self._normalize_import_properties(entry.get(props_field))\n                self.db.create_relationship(\n                    source_id=node_lookup[start_ref],\n                    target_id=node_lookup[end_ref],\n                    rel_type=str(rel_type),\n                    properties=rel_props,\n                )\n                created_rels += 1\n\n            return [{\"nodes\": created_nodes, \"relationships\": created_rels}]\n\n        if lower_name == \"apoc.load.html\":\n            if len(args) != 2:\n                raise CypherExecutionError(\"apoc.load.html expects 2 arguments\")\n            source = args[0]\n            selectors = args[1]\n            if not isinstance(source, str):\n                raise CypherExecutionError(\"apoc.load.html expects a string path or URL\")\n            if not isinstance(selectors, dict):\n                raise CypherExecutionError(\"apoc.load.html expects a selector map\")\n            html = self._load_html_from_source(source)\n            root = self._parse_html(html)\n            value: dict[str, list[dict[str, Any]]] = {}\n            for key, selector in selectors.items():\n                if not isinstance(selector, str):\n                    raise CypherExecutionError(\"apoc.load.html selectors must be strings\")\n                nodes = self._select_html_nodes(root, selector)\n                value[key] = [{\"text\": node.text_content().strip()} for node in nodes]\n            return [{\"value\": value}]\n\n        if lower_name == \"apoc.load.xml\":\n            if len(args) not in (2, 3):\n                raise CypherExecutionError(\"apoc.load.xml expects 2 or 3 arguments\")\n            source = args[0]\n            xpath = args[1]\n            options = args[2] if len(args) == 3 else None\n            if not isinstance(source, str):\n                raise CypherExecutionError(\"apoc.load.xml expects a string path or URL\")\n            if not isinstance(xpath, str):\n                raise CypherExecutionError(\"apoc.load.xml expects an XPath string\")\n            if options is not None and not isinstance(options, dict):\n                raise CypherExecutionError(\"apoc.load.xml options must be a map\")\n            xml_payload = self._load_xml_from_source(source, options=options)\n            if xml_payload is None:\n                return []\n            try:\n                import xml.etree.ElementTree as ET\n                root = ET.fromstring(xml_payload)\n            except Exception as exc:\n                raise CypherExecutionError(f\"Failed to parse XML from {source}: {exc}\") from exc\n            if xpath.startswith(\"/\"):\n                xpath = f\".{xpath}\"\n            matches = root.findall(xpath)\n            return [{\"value\": self._element_to_dict(match)} for match in matches]\n\n        if lower_name == \"apoc.load.xmlparams\":\n            if len(args) not in (4, 5):\n                raise CypherExecutionError(\"apoc.load.xmlParams expects 4 or 5 arguments\")\n            source = args[0]\n            xpath = args[1]\n            params = args[2]\n            headers = args[3]\n            options = args[4] if len(args) == 5 else None\n            if not isinstance(source, str):\n                raise CypherExecutionError(\"apoc.load.xmlParams expects a string path or URL\")\n            if not isinstance(xpath, str):\n                raise CypherExecutionError(\"apoc.load.xmlParams expects an XPath string\")\n            if not isinstance(params, dict):\n                raise CypherExecutionError(\"apoc.load.xmlParams expects a params map\")\n            if not isinstance(headers, dict):\n                raise CypherExecutionError(\"apoc.load.xmlParams expects a headers map\")\n            if options is not None and not isinstance(options, dict):\n                raise CypherExecutionError(\"apoc.load.xmlParams options must be a map\")\n            url = self._apply_query_params(source, params)\n            xml_payload = self._load_xml_from_source(url, options=options)\n            if xml_payload is None:\n                return []\n            try:\n                import xml.etree.ElementTree as ET\n                root = ET.fromstring(xml_payload)\n            except Exception as exc:\n                raise CypherExecutionError(f\"Failed to parse XML from {source}: {exc}\") from exc\n            if xpath.startswith(\"/\"):\n                xpath = f\".{xpath}\"\n            matches = root.findall(xpath)\n            return [{\"value\": self._element_to_dict(match)} for match in matches]\n\n        raise CypherExecutionError(f\"Unknown procedure: {name}\")\n\n    def _load_json_from_source(\n        self,\n        source: str,\n        headers: dict[str, str] | None = None,\n        options: dict[str, Any] | None = None,\n    ) -&gt; Any:\n        \"\"\"Load JSON data from a URL or local file path.\"\"\"\n        archive_member = None\n        if \"!\" in source:\n            source, archive_member = source.split(\"!\", 1)\n\n        parsed = urllib.parse.urlparse(source)\n        options = options or {}\n        method = options.get(\"method\") or \"GET\"\n        payload = options.get(\"payload\")\n        timeout = options.get(\"timeout\")\n        retry = options.get(\"retry\", 0)\n        fail_on_error = options.get(\"failOnError\", True)\n        options_headers = options.get(\"headers\")\n        auth = options.get(\"auth\")\n        if timeout is not None and not isinstance(timeout, (int, float)):\n            raise CypherExecutionError(\"apoc.load.jsonParams timeout must be a number\")\n        if retry is not None and not isinstance(retry, int):\n            raise CypherExecutionError(\"apoc.load.jsonParams retry must be an integer\")\n        if options_headers is not None and not isinstance(options_headers, dict):\n            raise CypherExecutionError(\"apoc.load.jsonParams headers must be a map\")\n        if not isinstance(fail_on_error, bool):\n            raise CypherExecutionError(\"apoc.load.jsonParams failOnError must be a boolean\")\n\n        if parsed.scheme in (\"http\", \"https\"):\n            cache_dir = os.getenv(\"GRAFITO_APOC_CACHE_DIR\")\n            cache_path = None\n            can_cache = (\n                method.upper() == \"GET\"\n                and payload is None\n                and not headers\n                and not options_headers\n                and not auth\n                and not options.get(\"params\")\n            )\n            if cache_dir and can_cache and archive_member is None:\n                os.makedirs(cache_dir, exist_ok=True)\n                url_hash = hashlib.sha256(source.encode(\"utf-8\")).hexdigest()\n                cache_path = os.path.join(cache_dir, f\"{url_hash}.json\")\n            if cache_path and os.path.exists(cache_path):\n                try:\n                    with open(cache_path, encoding=\"utf-8\") as handle:\n                        payload = handle.read()\n                except Exception as exc:\n                    raise CypherExecutionError(\n                        f\"Failed to read cached JSON {cache_path}: {exc}\"\n                    ) from exc\n            else:\n                if archive_member is not None:\n                    payload_bytes = self._load_bytes_from_source(\n                        source,\n                        \"JSON\",\n                        headers=headers,\n                        options=options,\n                    )\n                    if payload_bytes is None:\n                        return None\n                    payload = self._extract_json_from_archive(\n                        payload_bytes,\n                        source,\n                        archive_member,\n                    )\n                else:\n                    request_headers = {\"User-Agent\": \"GrafitoCypher/0.1\"}\n                    if headers:\n                        request_headers.update(headers)\n                    if options_headers:\n                        request_headers.update(options_headers)\n                    if auth:\n                        if isinstance(auth, dict):\n                            user = auth.get(\"user\") or auth.get(\"username\")\n                            password = auth.get(\"password\") or auth.get(\"pass\")\n                            if user is None or password is None:\n                                raise CypherExecutionError(\"apoc.load.jsonParams auth map needs user/password\")\n                            token = f\"{user}:{password}\".encode(\"utf-8\")\n                        elif isinstance(auth, str):\n                            token = auth.encode(\"utf-8\")\n                        else:\n                            raise CypherExecutionError(\"apoc.load.jsonParams auth must be a string or map\")\n                        request_headers[\"Authorization\"] = f\"Basic {base64.b64encode(token).decode('ascii')}\"\n\n                    data_bytes = None\n                    if payload is not None:\n                        if isinstance(payload, (dict, list)):\n                            data_bytes = orjson.dumps(payload)\n                            request_headers.setdefault(\"Content-Type\", \"application/json\")\n                        elif isinstance(payload, str):\n                            data_bytes = payload.encode(\"utf-8\")\n                        elif isinstance(payload, bytes):\n                            data_bytes = payload\n                        else:\n                            raise CypherExecutionError(\"apoc.load.jsonParams payload must be string, bytes, list, or map\")\n\n                    attempts = retry + 1 if retry is not None else 1\n                    last_exc: Exception | None = None\n                    for _ in range(attempts):\n                        try:\n                            request = urllib.request.Request(\n                                source,\n                                headers=request_headers,\n                                data=data_bytes,\n                                method=method.upper(),\n                            )\n                            with urllib.request.urlopen(request, timeout=timeout) as handle:\n                                payload = handle.read().decode(\"utf-8\")\n                            last_exc = None\n                            break\n                        except Exception as exc:\n                            last_exc = exc\n                    if last_exc is not None:\n                        if fail_on_error:\n                            raise CypherExecutionError(\n                                f\"Failed to load JSON from {source}: {last_exc}\"\n                            ) from last_exc\n                        return None\n\n                if cache_path:\n                    try:\n                        with open(cache_path, \"w\", encoding=\"utf-8\") as handle:\n                            handle.write(payload)\n                    except Exception:\n                        pass\n        else:\n            path = source\n            if parsed.scheme == \"file\":\n                path = urllib.request.url2pathname(parsed.path)\n            if not os.path.exists(path):\n                raise CypherExecutionError(f\"JSON file not found: {path}\")\n            try:\n                if archive_member is not None:\n                    with open(path, \"rb\") as handle:\n                        payload_bytes = handle.read()\n                    payload = self._extract_json_from_archive(\n                        payload_bytes,\n                        path,\n                        archive_member,\n                    )\n                else:\n                    with open(path, encoding=\"utf-8\") as handle:\n                        payload = handle.read()\n            except Exception as exc:\n                raise CypherExecutionError(f\"Failed to read JSON file {path}: {exc}\") from exc\n        if payload is None:\n            return None\n        try:\n            data = orjson.loads(payload)\n        except orjson.JSONDecodeError as exc:\n            cleaned = payload.lstrip(\"\\ufeff\")\n            cleaned = re.sub(r\",\\s*(\\]|\\})\", r\"\\1\", cleaned)\n            try:\n                data = orjson.loads(cleaned)\n            except orjson.JSONDecodeError as exc2:\n                raise CypherExecutionError(\n                    f\"Invalid JSON payload from {source}: {exc}\"\n                ) from exc2\n        return data\n\n    def _load_html_from_source(self, source: str) -&gt; str:\n        \"\"\"Load HTML content from a URL or local file path.\"\"\"\n        parsed = urllib.parse.urlparse(source)\n        if parsed.scheme in (\"http\", \"https\"):\n            try:\n                request = urllib.request.Request(\n                    source,\n                    headers={\"User-Agent\": \"GrafitoCypher/0.1\"},\n                )\n                with urllib.request.urlopen(request) as handle:\n                    return handle.read().decode(\"utf-8\")\n            except Exception as exc:\n                raise CypherExecutionError(f\"Failed to load HTML from {source}: {exc}\") from exc\n        path = source\n        if parsed.scheme == \"file\":\n            path = urllib.request.url2pathname(parsed.path)\n        if not os.path.exists(path):\n            raise CypherExecutionError(f\"HTML file not found: {path}\")\n        try:\n            with open(path, encoding=\"utf-8\") as handle:\n                return handle.read()\n        except Exception as exc:\n            raise CypherExecutionError(f\"Failed to read HTML file {path}: {exc}\") from exc\n\n    def _load_bytes_from_source(\n        self,\n        source: str,\n        kind: str,\n        headers: dict[str, str] | None = None,\n        options: dict[str, Any] | None = None,\n    ) -&gt; bytes | None:\n        \"\"\"Load raw bytes from a URL or local file path.\"\"\"\n        parsed = urllib.parse.urlparse(source)\n        options = options or {}\n        method = options.get(\"method\") or \"GET\"\n        payload = options.get(\"payload\")\n        timeout = options.get(\"timeout\")\n        retry = options.get(\"retry\", 0)\n        fail_on_error = options.get(\"failOnError\", True)\n        options_headers = options.get(\"headers\")\n        auth = options.get(\"auth\")\n        if timeout is not None and not isinstance(timeout, (int, float)):\n            raise CypherExecutionError(f\"apoc.load.{kind.lower()}Params timeout must be a number\")\n        if retry is not None and not isinstance(retry, int):\n            raise CypherExecutionError(f\"apoc.load.{kind.lower()}Params retry must be an integer\")\n        if options_headers is not None and not isinstance(options_headers, dict):\n            raise CypherExecutionError(f\"apoc.load.{kind.lower()}Params headers must be a map\")\n        if not isinstance(fail_on_error, bool):\n            raise CypherExecutionError(f\"apoc.load.{kind.lower()}Params failOnError must be a boolean\")\n\n        if parsed.scheme in (\"http\", \"https\"):\n            request_headers = {\"User-Agent\": \"GrafitoCypher/0.1\"}\n            if headers:\n                request_headers.update(headers)\n            if options_headers:\n                request_headers.update(options_headers)\n            if auth:\n                if isinstance(auth, dict):\n                    user = auth.get(\"user\") or auth.get(\"username\")\n                    password = auth.get(\"password\") or auth.get(\"pass\")\n                    if user is None or password is None:\n                        raise CypherExecutionError(\n                            f\"apoc.load.{kind.lower()}Params auth map needs user/password\"\n                        )\n                    token = f\"{user}:{password}\".encode(\"utf-8\")\n                elif isinstance(auth, str):\n                    token = auth.encode(\"utf-8\")\n                else:\n                    raise CypherExecutionError(\n                        f\"apoc.load.{kind.lower()}Params auth must be a string or map\"\n                    )\n                request_headers[\"Authorization\"] = f\"Basic {base64.b64encode(token).decode('ascii')}\"\n\n            data_bytes = None\n            if payload is not None:\n                if isinstance(payload, (dict, list)):\n                    data_bytes = orjson.dumps(payload)\n                    request_headers.setdefault(\"Content-Type\", \"application/json\")\n                elif isinstance(payload, str):\n                    data_bytes = payload.encode(\"utf-8\")\n                elif isinstance(payload, bytes):\n                    data_bytes = payload\n                else:\n                    raise CypherExecutionError(\n                        f\"apoc.load.{kind.lower()}Params payload must be string, bytes, list, or map\"\n                    )\n\n            attempts = retry + 1 if retry is not None else 1\n            last_exc: Exception | None = None\n            for _ in range(attempts):\n                try:\n                    request = urllib.request.Request(\n                        source,\n                        headers=request_headers,\n                        data=data_bytes,\n                        method=method.upper(),\n                    )\n                    with urllib.request.urlopen(request, timeout=timeout) as handle:\n                        return handle.read()\n                except Exception as exc:\n                    last_exc = exc\n            if last_exc is not None:\n                if fail_on_error:\n                    raise CypherExecutionError(\n                        f\"Failed to load {kind} from {source}: {last_exc}\"\n                    ) from last_exc\n                return None\n            return None\n        path = source\n        if parsed.scheme == \"file\":\n            path = urllib.request.url2pathname(parsed.path)\n        if not os.path.exists(path):\n            raise CypherExecutionError(f\"{kind} file not found: {path}\")\n        try:\n            with open(path, \"rb\") as handle:\n                return handle.read()\n        except Exception as exc:\n            raise CypherExecutionError(f\"Failed to read {kind} file {path}: {exc}\") from exc\n\n    def _load_xml_from_source(self, source: str, options: dict[str, Any] | None = None) -&gt; str | None:\n        \"\"\"Load XML content from a URL or local file path with optional compression.\"\"\"\n        payload = self._load_bytes_from_source(source, \"XML\", options=options)\n        if payload is None:\n            return None\n        compression = None\n        archive_path = None\n        if options:\n            compression = options.get(\"compression\")\n            archive_path = options.get(\"path\") or options.get(\"fileName\")\n        if compression is None:\n            lower_source = source.lower()\n            if lower_source.endswith(\".gz\"):\n                compression = \"gzip\"\n            elif lower_source.endswith(\".bz2\"):\n                compression = \"bz2\"\n            elif lower_source.endswith(\".xz\") or lower_source.endswith(\".lzma\"):\n                compression = \"xz\"\n            elif lower_source.endswith(\".zip\"):\n                compression = \"zip\"\n\n        if compression:\n            compression = str(compression).lower()\n            if compression in (\"gzip\", \"gz\"):\n                import gzip\n\n                payload = gzip.decompress(payload)\n            elif compression in (\"bz2\", \"bzip2\"):\n                import bz2\n\n                payload = bz2.decompress(payload)\n            elif compression in (\"xz\", \"lzma\"):\n                import lzma\n\n                payload = lzma.decompress(payload)\n            elif compression == \"zip\":\n                import zipfile\n\n                with zipfile.ZipFile(io.BytesIO(payload)) as archive:\n                    members = archive.namelist()\n                    if archive_path:\n                        if archive_path not in members:\n                            raise CypherExecutionError(\n                                f\"XML entry not found in zip archive: {archive_path}\"\n                            )\n                        target = archive_path\n                    else:\n                        xml_members = [name for name in members if name.lower().endswith(\".xml\")]\n                        target = xml_members[0] if xml_members else members[0]\n                    payload = archive.read(target)\n            else:\n                raise CypherExecutionError(f\"Unsupported XML compression: {compression}\")\n\n        try:\n            return payload.decode(\"utf-8\")\n        except UnicodeDecodeError as exc:\n            raise CypherExecutionError(f\"Failed to decode XML from {source}: {exc}\") from exc\n\n    def _element_to_dict(self, element: Any) -&gt; dict[str, Any]:\n        \"\"\"Convert an XML element to a nested dict structure.\"\"\"\n        result: dict[str, Any] = {\"_tag\": element.tag}\n        if element.attrib:\n            result[\"_attributes\"] = dict(element.attrib)\n        text = (element.text or \"\").strip()\n        if text:\n            result[\"_text\"] = text\n        for child in list(element):\n            child_value = self._element_to_dict(child)\n            key = child.tag\n            if key in result:\n                existing = result[key]\n                if isinstance(existing, list):\n                    existing.append(child_value)\n                else:\n                    result[key] = [existing, child_value]\n            else:\n                result[key] = child_value\n        return result\n\n    def _parse_html(self, html: str) -&gt; _HtmlNode:\n        \"\"\"Parse HTML into a simple node tree.\"\"\"\n        parser = _HtmlTreeBuilder()\n        parser.feed(html)\n        parser.close()\n        return parser.root\n\n    def _parse_html_selector_segment(self, segment: str) -&gt; tuple[str | None, list[str], int | None]:\n        \"\"\"Parse a minimal selector segment: tag(.class)*(:eq(n))?\"\"\"\n        eq = None\n        base = segment\n        if \":eq(\" in segment:\n            base, eq_part = segment.split(\":eq(\", 1)\n            if not eq_part.endswith(\")\"):\n                raise CypherExecutionError(f\"Unsupported HTML selector segment: {segment}\")\n            try:\n                eq = int(eq_part[:-1])\n            except ValueError as exc:\n                raise CypherExecutionError(f\"Unsupported HTML selector segment: {segment}\") from exc\n\n        base = base.strip()\n        if not base:\n            raise CypherExecutionError(f\"Unsupported HTML selector segment: {segment}\")\n\n        parts = base.split(\".\")\n        tag = parts[0] or None\n        classes = [part for part in parts[1:] if part]\n\n        name_pattern = re.compile(r\"^[a-zA-Z0-9_-]+$\")\n        if tag and not name_pattern.match(tag):\n            raise CypherExecutionError(f\"Unsupported HTML selector segment: {segment}\")\n        for cls in classes:\n            if not name_pattern.match(cls):\n                raise CypherExecutionError(f\"Unsupported HTML selector segment: {segment}\")\n\n        return tag.lower() if tag else None, classes, eq\n\n    def _select_html_nodes(self, root: _HtmlNode, selector: str) -&gt; list[_HtmlNode]:\n        \"\"\"Select nodes using a minimal descendant-selector engine.\"\"\"\n        segments = [segment for segment in selector.split() if segment]\n        if not segments:\n            return []\n\n        current = [root]\n        for segment in segments:\n            tag, classes, eq = self._parse_html_selector_segment(segment)\n            matches: list[_HtmlNode] = []\n            for base in current:\n                stack = list(reversed(base.children))\n                while stack:\n                    node = stack.pop()\n                    stack.extend(reversed(node.children))\n                    if not self._html_node_matches(node, tag, classes, eq):\n                        continue\n                    matches.append(node)\n            current = matches\n        return current\n\n    def _html_node_matches(\n        self,\n        node: _HtmlNode,\n        tag: str | None,\n        classes: list[str],\n        eq: int | None,\n    ) -&gt; bool:\n        \"\"\"Match a node against a selector segment.\"\"\"\n        if tag and node.tag != tag:\n            return False\n        if classes:\n            node_classes = node.classes()\n            if any(cls not in node_classes for cls in classes):\n                return False\n        if eq is not None:\n            if node.parent is None:\n                return False\n            siblings = [child for child in node.parent.children if child.tag == node.tag]\n            try:\n                index = siblings.index(node)\n            except ValueError:\n                return False\n            if index != eq:\n                return False\n        return True\n\n    def _coerce_vector_properties_filter(self, props: Any) -&gt; Any:\n        \"\"\"Coerce Cypher map filters into PropertyFilter/PropertyFilterGroup.\"\"\"\n        if props is None:\n            return None\n        if isinstance(props, PropertyFilterGroup):\n            return props\n        if not isinstance(props, dict):\n            raise CypherExecutionError(\"db.vector.search properties must be a map\")\n\n        logical_key = None\n        if \"$or\" in props or \"or\" in props:\n            logical_key = \"$or\" if \"$or\" in props else \"or\"\n            operator = \"OR\"\n        elif \"$and\" in props or \"and\" in props:\n            logical_key = \"$and\" if \"$and\" in props else \"and\"\n            operator = \"AND\"\n\n        if logical_key is not None:\n            if len(props) != 1:\n                raise CypherExecutionError(\n                    \"Logical properties filter must only contain the operator key\"\n                )\n            filters = props[logical_key]\n            if not isinstance(filters, list):\n                raise CypherExecutionError(\"Logical properties filter must be a list\")\n            dict_filters = [self._coerce_properties_map(item) for item in filters]\n            return PropertyFilterGroup(operator, *dict_filters)\n\n        return self._coerce_properties_map(props)\n\n    def _apply_query_params(self, source: str, params: dict[str, Any]) -&gt; str:\n        \"\"\"Apply query parameters to a URL.\"\"\"\n        parsed = urllib.parse.urlparse(source)\n        if parsed.scheme not in (\"http\", \"https\"):\n            return source\n        query_items = urllib.parse.parse_qsl(parsed.query, keep_blank_values=True)\n        for key, value in params.items():\n            if isinstance(value, (list, tuple)):\n                for item in value:\n                    query_items.append((key, item))\n            else:\n                query_items.append((key, value))\n        query = urllib.parse.urlencode(query_items, doseq=True)\n        return urllib.parse.urlunparse(parsed._replace(query=query))\n\n    def _extract_json_from_archive(self, payload: bytes, source: str, member: str) -&gt; str:\n        \"\"\"Extract a JSON payload from a tar archive.\"\"\"\n        import tarfile\n\n        lower_source = source.lower()\n        if lower_source.endswith(\".tgz\") or lower_source.endswith(\".tar.gz\"):\n            mode = \"r:gz\"\n        elif lower_source.endswith(\".tar.bz2\") or lower_source.endswith(\".tbz2\"):\n            mode = \"r:bz2\"\n        elif lower_source.endswith(\".tar.xz\") or lower_source.endswith(\".txz\"):\n            mode = \"r:xz\"\n        elif lower_source.endswith(\".tar\"):\n            mode = \"r:\"\n        else:\n            raise CypherExecutionError(\n                f\"Unsupported JSON archive type for {source}; expected .tar, .tgz, .tar.gz, .tar.bz2, or .tar.xz\"\n            )\n\n        normalized_member = member.lstrip(\"./\")\n        with tarfile.open(fileobj=io.BytesIO(payload), mode=mode) as archive:\n            for item in archive.getmembers():\n                if item.isdir():\n                    continue\n                name = item.name.lstrip(\"./\")\n                if name == normalized_member:\n                    handle = archive.extractfile(item)\n                    if handle is None:\n                        break\n                    data = handle.read()\n                    try:\n                        return data.decode(\"utf-8\")\n                    except UnicodeDecodeError as exc:\n                        raise CypherExecutionError(\n                            f\"Failed to decode JSON entry {member} from {source}: {exc}\"\n                        ) from exc\n        raise CypherExecutionError(f\"JSON entry not found in archive {source}: {member}\")\n\n    def _load_import_text(self, source: str) -&gt; str | None:\n        \"\"\"Load raw text for JSON/JSONL import, supporting tar archives.\"\"\"\n        return self._load_import_text_with_options(source, None)\n\n    def _load_import_text_with_options(self, source: Any, options: dict[str, Any] | None) -&gt; str | None:\n        \"\"\"Load import payload from string/bytes with optional decompression.\"\"\"\n        if isinstance(source, (bytes, bytearray)):\n            payload_bytes = bytes(source)\n            return self._decode_import_payload(payload_bytes, \"&lt;memory&gt;\", options)\n\n        if not isinstance(source, str):\n            raise CypherExecutionError(\"apoc.import.json expects a string path/URL or bytes\")\n\n        archive_member = None\n        if \"!\" in source:\n            source, archive_member = source.split(\"!\", 1)\n\n        payload_bytes = self._load_bytes_from_source(source, \"JSON\")\n        if payload_bytes is None:\n            return None\n        if archive_member is not None:\n            return self._extract_json_from_archive(payload_bytes, source, archive_member)\n        return self._decode_import_payload(payload_bytes, source, options)\n\n    def _decode_import_payload(\n        self,\n        payload: bytes,\n        source: str,\n        options: dict[str, Any] | None,\n    ) -&gt; str:\n        \"\"\"Decode import payload, applying optional compression.\"\"\"\n        compression = None\n        if options:\n            compression = options.get(\"compression\")\n        if compression:\n            payload = self._decompress_payload(payload, compression, options or {}, source)\n        try:\n            return payload.decode(\"utf-8\")\n        except UnicodeDecodeError as exc:\n            raise CypherExecutionError(f\"Failed to decode JSON from {source}: {exc}\") from exc\n\n    def _decompress_payload(\n        self,\n        payload: bytes,\n        compression: str,\n        options: dict[str, Any],\n        source: str,\n    ) -&gt; bytes:\n        \"\"\"Decompress raw payload bytes based on compression option.\"\"\"\n        compression = str(compression).upper()\n        if compression == \"DEFLATE\":\n            import zlib\n\n            return zlib.decompress(payload)\n        if compression in (\"GZIP\", \"GZ\"):\n            import gzip\n\n            return gzip.decompress(payload)\n        if compression in (\"BZ2\", \"BZIP2\"):\n            import bz2\n\n            return bz2.decompress(payload)\n        if compression in (\"XZ\", \"LZMA\"):\n            import lzma\n\n            return lzma.decompress(payload)\n        if compression == \"ZIP\":\n            import zipfile\n\n            path = options.get(\"path\")\n            with zipfile.ZipFile(io.BytesIO(payload)) as archive:\n                members = archive.namelist()\n                target = path or (members[0] if members else None)\n                if target is None or target not in members:\n                    raise CypherExecutionError(\n                        f\"JSON entry not found in zip archive {source}: {path}\"\n                    )\n                return archive.read(target)\n        raise CypherExecutionError(f\"Unsupported compression type: {compression}\")\n\n    def _parse_import_payload(self, payload: str) -&gt; list[dict[str, Any]]:\n        \"\"\"Parse JSON or JSONL payload into a list of entries.\"\"\"\n        try:\n            data = orjson.loads(payload)\n        except orjson.JSONDecodeError:\n            entries: list[dict[str, Any]] = []\n            for line in payload.splitlines():\n                line = line.strip()\n                if not line:\n                    continue\n                entries.append(orjson.loads(line))\n            return entries\n\n        if isinstance(data, list):\n            return data\n        if isinstance(data, dict):\n            nodes = data.get(\"nodes\") or []\n            rels = data.get(\"relationships\") or data.get(\"rels\") or []\n            if nodes or rels:\n                return list(nodes) + list(rels)\n            return [data]\n        raise CypherExecutionError(\"apoc.import.json expects JSON object, array, or JSONL\")\n\n    def _normalize_import_labels(self, value: Any) -&gt; list[str]:\n        if value is None:\n            return []\n        if isinstance(value, list):\n            return [str(item) for item in value]\n        if isinstance(value, str):\n            return [value]\n        raise CypherExecutionError(\"apoc.import.json labels must be a string or list\")\n\n    def _normalize_import_properties(self, value: Any) -&gt; dict[str, Any]:\n        if value is None:\n            return {}\n        if isinstance(value, dict):\n            return value\n        raise CypherExecutionError(\"apoc.import.json properties must be a map\")\n\n    def _resolve_import_ref(self, value: Any) -&gt; Any:\n        if isinstance(value, dict):\n            return value.get(\"id\") or value.get(\"identity\")\n        return value\n\n    def _coerce_properties_map(self, props: Any) -&gt; dict:\n        if not isinstance(props, dict):\n            raise CypherExecutionError(\"Properties filter entries must be maps\")\n        coerced = {}\n        for key, value in props.items():\n            if isinstance(value, dict):\n                coerced[key] = self._coerce_property_operator(value)\n            else:\n                coerced[key] = value\n        return coerced\n\n    def _coerce_property_operator(self, spec: dict) -&gt; PropertyFilter:\n        operator_map = {\n            \"gt\": PropertyFilter.gt,\n            \"$gt\": PropertyFilter.gt,\n            \"lt\": PropertyFilter.lt,\n            \"$lt\": PropertyFilter.lt,\n            \"gte\": PropertyFilter.gte,\n            \"$gte\": PropertyFilter.gte,\n            \"lte\": PropertyFilter.lte,\n            \"$lte\": PropertyFilter.lte,\n            \"ne\": PropertyFilter.ne,\n            \"$ne\": PropertyFilter.ne,\n            \"between\": PropertyFilter.between,\n            \"$between\": PropertyFilter.between,\n            \"contains\": PropertyFilter.contains,\n            \"$contains\": PropertyFilter.contains,\n            \"starts_with\": PropertyFilter.starts_with,\n            \"$starts_with\": PropertyFilter.starts_with,\n            \"ends_with\": PropertyFilter.ends_with,\n            \"$ends_with\": PropertyFilter.ends_with,\n            \"regex\": PropertyFilter.regex,\n            \"$regex\": PropertyFilter.regex,\n        }\n\n        case_sensitive = spec.get(\"case_sensitive\")\n        if case_sensitive is not None and not isinstance(case_sensitive, bool):\n            raise CypherExecutionError(\"case_sensitive must be a boolean\")\n\n        operator_keys = [key for key in spec.keys() if key != \"case_sensitive\"]\n        if len(operator_keys) != 1:\n            raise CypherExecutionError(\"Property filter map must contain a single operator\")\n\n        op_key = operator_keys[0]\n        if op_key not in operator_map:\n            raise CypherExecutionError(f\"Unsupported property filter operator: {op_key}\")\n\n        value = spec[op_key]\n        if op_key in (\"between\", \"$between\"):\n            if not isinstance(value, list) or len(value) != 2:\n                raise CypherExecutionError(\"between expects a two-item list\")\n            return operator_map[op_key](value[0], value[1])\n\n        if op_key in (\"contains\", \"$contains\", \"starts_with\", \"$starts_with\", \"ends_with\", \"$ends_with\"):\n            if case_sensitive is None:\n                return operator_map[op_key](value)\n            return operator_map[op_key](value, case_sensitive=case_sensitive)\n\n        return operator_map[op_key](value)\n\n    def _execute_query_with_context(self, query: Query, initial_results: list[dict]) -&gt; list[dict]:\n        \"\"\"Execute a query with initial results as context.\"\"\"\n        if query.union_clauses:\n            return self._execute_union(query)\n\n        if query.clauses:\n            return self._execute_multi_clause(query.clauses, initial_results=initial_results)\n\n        if isinstance(query.clause, WithClause):\n            return self._execute_with(query.clause, initial_results)\n\n        if isinstance(query.clause, SubqueryClause):\n            return self._execute_subquery(query.clause, initial_results)\n        if isinstance(query.clause, ProcedureCallClause):\n            return self._execute_procedure_call(query.clause, initial_results)\n\n        if isinstance(query.clause, UnwindClause):\n            return self._execute_unwind(query.clause, initial_results)\n        if isinstance(query.clause, LoadCsvClause):\n            return self._execute_load_csv(query.clause, initial_results)\n\n        if isinstance(query.clause, MatchClause):\n            return self._execute_match(query.clause, context=initial_results)\n        elif isinstance(query.clause, CreateClause):\n            return self._execute_create(query.clause)\n        elif isinstance(query.clause, MergeClause):\n            return self._execute_merge(query.clause)\n        else:\n            raise CypherExecutionError(f\"Unknown clause type: {type(query.clause)}\")\n\n    def _execute_unwind(self, clause: UnwindClause, input_results: list[dict]) -&gt; list[dict]:\n        \"\"\"Execute UNWIND clause to expand a list into rows.\"\"\"\n        if not input_results:\n            input_results = [{}]\n\n        results = []\n        for match in input_results:\n            evaluator = self._make_evaluator(match)\n            value = evaluator.evaluate(clause.list_expr)\n            if value is None:\n                continue\n            if not isinstance(value, (list, tuple)):\n                raise CypherExecutionError(\"UNWIND expects a list expression\")\n            for item in value:\n                row = match.copy()\n                row[clause.variable] = item\n                results.append(row)\n        return results\n\n    def _execute_create(self, clause: CreateClause, context: list[dict] | None = None) -&gt; list[dict]:\n        \"\"\"Execute CREATE clause.\n\n        Supports:\n        - Single node: CREATE (n:Person {name: 'Alice'})\n        - Multiple nodes: CREATE (a:Person), (b:Person)\n        - Nodes with relationships: CREATE (a:Person)-[r:KNOWS]-&gt;(b:Person)\n\n        Args:\n            clause: CreateClause AST node\n\n        Returns:\n            List with created entity info\n        \"\"\"\n        if context:\n            results = []\n            for row in context:\n                row_result = row.copy()\n                for pattern in clause.patterns:\n                    self._apply_create_pattern_with_context(pattern, row_result)\n                results.append(row_result)\n            return results\n\n        results = []\n        for pattern in clause.patterns:\n            if len(pattern.elements) == 1 and pattern.elements[0].relationship is None:\n                # Simple node creation: CREATE (n:Person)\n                elem = pattern.elements[0]\n                node_pattern = elem.node\n                properties = self._evaluate_properties(node_pattern.properties, None)\n                node = self.db.create_node(\n                    labels=node_pattern.labels,\n                    properties=properties\n                )\n\n                # Build result\n                result = {}\n                if node_pattern.variable:\n                    result[node_pattern.variable] = node.to_dict()\n                results.append(result if result else {'created': node.to_dict()})\n            else:\n                # Pattern with relationships: CREATE (a)-[r]-&gt;(b)\n                result = self._create_pattern_with_relationships(pattern)\n                results.append(result)\n\n        return results\n\n    def _create_pattern_with_relationships(self, pattern: Pattern, return_dicts: bool = True) -&gt; dict:\n        \"\"\"Create nodes and relationships from a pattern.\n\n        Args:\n            pattern: Pattern AST node\n\n        Returns:\n            Dictionary with created nodes and relationships\n        \"\"\"\n        if len(pattern.elements) != 2:\n            raise CypherExecutionError(\n                \"Only single-hop relationship patterns supported in CREATE (e.g., (a)-[r]-&gt;(b))\"\n            )\n\n        source_elem = pattern.elements[0]\n        target_elem = pattern.elements[1]\n        rel_pattern = source_elem.relationship\n\n        if rel_pattern is None:\n            raise CypherExecutionError(\"Invalid relationship pattern in CREATE\")\n        if rel_pattern.min_hops != 1 or rel_pattern.max_hops != 1:\n            raise CypherExecutionError(\"Variable-length relationships are not supported in CREATE\")\n\n        # Create source node\n        source_properties = self._evaluate_properties(source_elem.node.properties, None)\n        source_node = self.db.create_node(\n            labels=source_elem.node.labels,\n            properties=source_properties\n        )\n\n        # Create target node\n        target_properties = self._evaluate_properties(target_elem.node.properties, None)\n        target_node = self.db.create_node(\n            labels=target_elem.node.labels,\n            properties=target_properties\n        )\n\n        # Create relationship\n        # For CREATE, we ignore direction and always create outgoing from source to target\n        rel_type = rel_pattern.rel_type if rel_pattern.rel_type else \"RELATED_TO\"\n        rel_properties = self._evaluate_properties(rel_pattern.properties, None)\n        relationship = self.db.create_relationship(\n            source_id=source_node.id,\n            target_id=target_node.id,\n            rel_type=rel_type,\n            properties=rel_properties\n        )\n\n        # Build result\n        result = {}\n        if source_elem.node.variable:\n            result[source_elem.node.variable] = source_node.to_dict() if return_dicts else source_node\n        if rel_pattern.variable:\n            result[rel_pattern.variable] = relationship.to_dict() if return_dicts else relationship\n        if target_elem.node.variable:\n            result[target_elem.node.variable] = target_node.to_dict() if return_dicts else target_node\n\n        return result\n\n    def _apply_create_pattern_with_context(self, pattern: Pattern, row: dict) -&gt; None:\n        \"\"\"Create nodes/relationships honoring existing bindings in row.\"\"\"\n        if len(pattern.elements) == 1 and pattern.elements[0].relationship is None:\n            elem = pattern.elements[0]\n            node_pattern = elem.node\n            if node_pattern.variable and node_pattern.variable in row:\n                return\n            properties = self._evaluate_properties(node_pattern.properties, row)\n            node = self.db.create_node(\n                labels=node_pattern.labels,\n                properties=properties\n            )\n            if node_pattern.variable:\n                row[node_pattern.variable] = node\n            return\n\n        if len(pattern.elements) != 2:\n            raise CypherExecutionError(\n                \"Only single-hop relationship patterns supported in CREATE (e.g., (a)-[r]-&gt;(b))\"\n            )\n\n        source_elem = pattern.elements[0]\n        target_elem = pattern.elements[1]\n        rel_pattern = source_elem.relationship\n\n        if rel_pattern is None:\n            raise CypherExecutionError(\"Invalid relationship pattern in CREATE\")\n        if rel_pattern.min_hops != 1 or rel_pattern.max_hops != 1:\n            raise CypherExecutionError(\"Variable-length relationships are not supported in CREATE\")\n\n        source_node = None\n        if source_elem.node.variable:\n            source_node = self._resolve_bound_node(row.get(source_elem.node.variable))\n        if source_node is None:\n            source_properties = self._evaluate_properties(source_elem.node.properties, row)\n            source_node = self.db.create_node(\n                labels=source_elem.node.labels,\n                properties=source_properties\n            )\n            if source_elem.node.variable:\n                row[source_elem.node.variable] = source_node\n\n        target_node = None\n        if target_elem.node.variable:\n            target_node = self._resolve_bound_node(row.get(target_elem.node.variable))\n        if target_node is None:\n            target_properties = self._evaluate_properties(target_elem.node.properties, row)\n            target_node = self.db.create_node(\n                labels=target_elem.node.labels,\n                properties=target_properties\n            )\n            if target_elem.node.variable:\n                row[target_elem.node.variable] = target_node\n\n        rel_type = rel_pattern.rel_type if rel_pattern.rel_type else \"RELATED_TO\"\n        rel_properties = self._evaluate_properties(rel_pattern.properties, row)\n        relationship = self.db.create_relationship(\n            source_id=source_node.id,\n            target_id=target_node.id,\n            rel_type=rel_type,\n            properties=rel_properties\n        )\n\n        if rel_pattern.variable:\n            row[rel_pattern.variable] = relationship\n        if pattern.variable:\n            row[pattern.variable] = Path(nodes=[source_node, target_node], relationships=[relationship])\n\n    def _resolve_bound_node(self, value: Any) -&gt; Node | None:\n        \"\"\"Resolve a bound node from a context value.\"\"\"\n        if isinstance(value, Node):\n            return value\n        if isinstance(value, dict) and 'id' in value:\n            return self.db.get_node(value['id'])\n        return None\n\n    def _execute_merge(\n        self,\n        clause: MergeClause,\n        context: list[dict] | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Execute MERGE clause (find or create pattern).\n\n        MERGE is like an \"upsert\":\n        1. Try to MATCH the pattern\n        2. If found: run ON MATCH SET (if present)\n        3. If not found: CREATE the pattern and run ON CREATE SET (if present)\n\n        Args:\n            clause: MergeClause AST node\n\n        Returns:\n            List with node/relationship info\n        \"\"\"\n        def build_match_result(matches: list[dict], return_dicts: bool) -&gt; dict:\n            result: dict[str, Any] = {}\n            for match in matches:\n                for var_name, obj in match.items():\n                    if return_dicts and hasattr(obj, 'to_dict'):\n                        result[var_name] = obj.to_dict()\n                    else:\n                        result[var_name] = obj\n                break\n            return result\n\n        def create_pattern_result(\n            pattern: Pattern,\n            row_context: dict[str, Any] | None,\n            return_dicts: bool,\n        ) -&gt; dict:\n            if len(pattern.elements) == 1 and pattern.elements[0].relationship is None:\n                elem = pattern.elements[0]\n                node_pattern = elem.node\n                properties = self._evaluate_properties(node_pattern.properties, row_context)\n                node = self.db.create_node(\n                    labels=node_pattern.labels,\n                    properties=properties\n                )\n\n                if clause.on_create_set:\n                    match = {node_pattern.variable: node} if node_pattern.variable else {}\n                    self._execute_set([match], clause.on_create_set)\n                    node = self.db.get_node(node.id)\n\n                result = {}\n                if node_pattern.variable:\n                    result[node_pattern.variable] = node.to_dict() if return_dicts else node\n                return result if result else {'created': node.to_dict() if return_dicts else node}\n\n            if row_context:\n                source_elem = pattern.elements[0]\n                target_elem = pattern.elements[1]\n                rel_pattern = source_elem.relationship\n                if rel_pattern is None:\n                    raise CypherExecutionError(\"Invalid relationship pattern in MERGE\")\n\n                source_node = None\n                if source_elem.node.variable and source_elem.node.variable in row_context:\n                    source_node = self._resolve_bound_node(row_context.get(source_elem.node.variable))\n                if source_node is None:\n                    source_props = self._evaluate_properties(source_elem.node.properties, row_context)\n                    source_node = self.db.create_node(\n                        labels=source_elem.node.labels,\n                        properties=source_props\n                    )\n\n                target_node = None\n                if target_elem.node.variable and target_elem.node.variable in row_context:\n                    target_node = self._resolve_bound_node(row_context.get(target_elem.node.variable))\n                if target_node is None:\n                    target_props = self._evaluate_properties(target_elem.node.properties, row_context)\n                    target_node = self.db.create_node(\n                        labels=target_elem.node.labels,\n                        properties=target_props\n                    )\n\n                rel_type = rel_pattern.rel_type if rel_pattern.rel_type else \"RELATED_TO\"\n                rel_props = self._evaluate_properties(rel_pattern.properties, row_context)\n\n                existing_rels: list[Relationship] = []\n                if rel_pattern.direction == \"outgoing\":\n                    existing_rels = self.db.match_relationships(\n                        source_id=source_node.id,\n                        target_id=target_node.id,\n                        rel_type=rel_type,\n                        properties=rel_props if rel_props else None\n                    )\n                elif rel_pattern.direction == \"incoming\":\n                    existing_rels = self.db.match_relationships(\n                        source_id=target_node.id,\n                        target_id=source_node.id,\n                        rel_type=rel_type,\n                        properties=rel_props if rel_props else None\n                    )\n                else:\n                    existing_rels = self.db.match_relationships(\n                        source_id=source_node.id,\n                        target_id=target_node.id,\n                        rel_type=rel_type,\n                        properties=rel_props if rel_props else None\n                    )\n                    if not existing_rels:\n                        existing_rels = self.db.match_relationships(\n                            source_id=target_node.id,\n                            target_id=source_node.id,\n                            rel_type=rel_type,\n                            properties=rel_props if rel_props else None\n                        )\n\n                if existing_rels:\n                    rel = existing_rels[0]\n                else:\n                    rel = self.db.create_relationship(\n                        source_id=source_node.id,\n                        target_id=target_node.id,\n                        rel_type=rel_type,\n                        properties=rel_props\n                    )\n\n                created_result = {}\n                if source_elem.node.variable:\n                    created_result[source_elem.node.variable] = (\n                        source_node.to_dict() if return_dicts else source_node\n                    )\n                if rel_pattern.variable:\n                    created_result[rel_pattern.variable] = rel.to_dict() if return_dicts else rel\n                if target_elem.node.variable:\n                    created_result[target_elem.node.variable] = (\n                        target_node.to_dict() if return_dicts else target_node\n                    )\n            else:\n                created_result = self._create_pattern_with_relationships(\n                    pattern,\n                    return_dicts=return_dicts\n                )\n\n            if clause.on_create_set:\n                match = {}\n                for var_name, entity in created_result.items():\n                    if hasattr(entity, 'labels'):\n                        match[var_name] = entity\n                    elif hasattr(entity, 'source_id'):\n                        match[var_name] = entity\n                    elif isinstance(entity, dict) and 'labels' in entity:\n                        match[var_name] = self.db.get_node(entity['id'])\n                    elif isinstance(entity, dict) and 'type' in entity:\n                        match[var_name] = self.db.get_relationship(entity['id'])\n\n                if match:\n                    self._execute_set([match], clause.on_create_set)\n\n                    if return_dicts:\n                        for var_name, entity in match.items():\n                            if hasattr(entity, 'to_dict'):\n                                created_result[var_name] = entity.to_dict()\n\n            return created_result\n\n        if context:\n            results = []\n            for row in context:\n                row_result = row.copy()\n                for pattern in clause.patterns:\n                    matches = [\n                        match for match in self._match_pattern(pattern, context=row_result)\n                        if self._pattern_bindings_match(row_result, match)\n                    ]\n\n                    if matches:\n                        if clause.on_match_set:\n                            self._execute_set(matches, clause.on_match_set)\n                        merge_result = build_match_result(matches, return_dicts=False)\n                    else:\n                        merge_result = create_pattern_result(\n                            pattern,\n                            row_context=row_result,\n                            return_dicts=False\n                        )\n                    row_result.update(merge_result)\n                results.append(row_result)\n            return results\n\n        results = []\n        for pattern in clause.patterns:\n            matches = self._match_pattern(pattern)\n\n            if matches:\n                if clause.on_match_set:\n                    self._execute_set(matches, clause.on_match_set)\n                results.append(build_match_result(matches, return_dicts=True))\n            else:\n                results.append(create_pattern_result(pattern, row_context=None, return_dicts=True))\n\n        return results\n\n    def _execute_match(self, clause: MatchClause, context: list[dict] = None) -&gt; list[dict]:\n        \"\"\"Execute MATCH clause with optional WHERE, DELETE, SET, RETURN, ORDER BY, SKIP, LIMIT.\n\n        Args:\n            clause: MatchClause AST node\n            context: Optional context from previous WITH clause (not yet fully implemented)\n\n        Returns:\n            List of result dictionaries\n        \"\"\"\n        pattern_vars = self._collect_pattern_variables(clause.patterns) if clause.optional else set()\n        input_rows = context if context else [{}]\n        matches = []\n\n        for row in input_rows:\n            property_filters = self._extract_property_filters(clause.where_clause, context=row)\n            row_matches = [row]\n            for pattern in clause.patterns:\n                pattern_matches = []\n                for partial in row_matches:\n                    for match in self._match_pattern(pattern, property_filters, context=partial):\n                        if not self._pattern_bindings_match(partial, match):\n                            continue\n                        merged = partial.copy()\n                        merged.update(match)\n                        pattern_matches.append(merged)\n                row_matches = pattern_matches\n                if not row_matches:\n                    break\n\n            if clause.where_clause:\n                row_matches = self._filter_where(row_matches, clause.where_clause)\n\n            if row_matches:\n                matches.extend(row_matches)\n            elif clause.optional:\n                fallback = row.copy()\n                for var in pattern_vars:\n                    fallback.setdefault(var, None)\n                matches.append(fallback)\n\n        if clause.optional and not matches and not context:\n            matches = [{var: None for var in pattern_vars}]\n\n        # Apply DELETE if present (mutating operation)\n        if clause.delete_clause:\n            return self._execute_delete(matches, clause.delete_clause)\n\n        # Apply SET if present (mutating operation)\n        if clause.set_clause:\n            self._execute_set(matches, clause.set_clause)\n\n        # Apply REMOVE if present (mutating operation)\n        if clause.remove_clause:\n            self._execute_remove(matches, clause.remove_clause)\n\n        # Apply ORDER BY BEFORE RETURN (needs access to Node objects)\n        if clause.order_by_clause:\n            matches = self._apply_order_by(matches, clause.order_by_clause)\n\n        # Apply SKIP (before LIMIT and RETURN)\n        if clause.skip_clause:\n            matches = matches[clause.skip_clause.count:]\n\n        # Apply LIMIT (on raw matches if no RETURN, or will be applied after RETURN)\n        if clause.limit_clause and not clause.return_clause:\n            matches = matches[:clause.limit_clause.count]\n\n        # Apply RETURN projection if present\n        if clause.return_clause:\n            matches = self._apply_return(matches, clause.return_clause)\n            # Apply LIMIT after RETURN if present\n            if clause.limit_clause:\n                matches = matches[:clause.limit_clause.count]\n\n        return matches\n\n    def _match_pattern(\n        self,\n        pattern: Pattern,\n        property_filters: dict[str, dict[str, Any]] | None = None,\n        context: dict[str, Any] | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Match a pattern and return variable bindings.\n\n        Args:\n            pattern: Pattern AST node\n\n        Returns:\n            List of dictionaries mapping variables to matched entities\n        \"\"\"\n        if isinstance(pattern, PatternFunction):\n            return self._match_pattern_function(pattern)\n\n        if len(pattern.elements) == 1 and pattern.elements[0].relationship is None:\n            # Simple node pattern: (n:Label {props})\n            return self._match_single_node(\n                pattern.elements[0],\n                path_variable=pattern.variable,\n                property_filters=property_filters,\n                context=context\n            )\n        else:\n            # Relationship pattern: (a)-[r]-&gt;(b)\n            return self._match_relationship_pattern(\n                pattern,\n                path_variable=pattern.variable,\n                property_filters=property_filters,\n                context=context\n            )\n\n    def _collect_pattern_variables(self, patterns: list[Pattern]) -&gt; set[str]:\n        \"\"\"Collect variable names from patterns.\"\"\"\n        variables: set[str] = set()\n        for pattern in patterns:\n            if isinstance(pattern, PatternFunction):\n                if pattern.variable:\n                    variables.add(pattern.variable)\n                for elem in pattern.pattern.elements:\n                    if elem.node.variable:\n                        variables.add(elem.node.variable)\n                    if elem.relationship and elem.relationship.variable:\n                        variables.add(elem.relationship.variable)\n                continue\n            if pattern.variable:\n                variables.add(pattern.variable)\n            for elem in pattern.elements:\n                if elem.node.variable:\n                    variables.add(elem.node.variable)\n                if elem.relationship and elem.relationship.variable:\n                    variables.add(elem.relationship.variable)\n        return variables\n\n    def _merge_property_filters(\n        self,\n        base: dict[str, Any],\n        extra: dict[str, Any],\n    ) -&gt; dict[str, Any] | None:\n        \"\"\"Merge property filters, returning None when there is a conflict.\"\"\"\n        merged = dict(base)\n        for key, value in extra.items():\n            if key in merged and merged[key] != value:\n                return None\n            merged[key] = value\n        return merged\n\n    def _extract_property_filters(\n        self,\n        where_clause: WhereClause | None,\n        context: dict[str, Any] | None = None,\n    ) -&gt; dict[str, dict[str, Any]]:\n        \"\"\"Extract equality filters from WHERE for simple pushdown.\"\"\"\n        if where_clause is None:\n            return {}\n        filters = self._collect_property_filters(where_clause.condition, context=context)\n        return filters\n\n    def _collect_property_filters(\n        self,\n        expr: Expression,\n        context: dict[str, Any] | None = None\n    ) -&gt; dict[str, dict[str, Any]]:\n        \"\"\"Collect property = literal filters from AND-connected expressions.\"\"\"\n        if isinstance(expr, BinaryOp) and expr.operator == \"AND\":\n            left = self._collect_property_filters(expr.left, context=context)\n            right = self._collect_property_filters(expr.right, context=context)\n            if not left:\n                return right\n            if not right:\n                return left\n            merged: dict[str, dict[str, Any]] = {}\n            for var, props in left.items():\n                merged[var] = dict(props)\n            for var, props in right.items():\n                if var not in merged:\n                    merged[var] = dict(props)\n                    continue\n                merged_props = self._merge_property_filters(merged[var], props)\n                if merged_props is None:\n                    return {}\n                merged[var] = merged_props\n            return merged\n\n        if isinstance(expr, BinaryOp) and expr.operator == \"=\":\n            if isinstance(expr.left, PropertyAccess) and isinstance(expr.right, Literal):\n                if expr.right.value is None:\n                    return {}\n                return {expr.left.variable: {expr.left.property: expr.right.value}}\n            if isinstance(expr.right, PropertyAccess) and isinstance(expr.left, Literal):\n                if expr.left.value is None:\n                    return {}\n                return {expr.right.variable: {expr.right.property: expr.left.value}}\n            if context is not None:\n                evaluator = self._make_evaluator(context)\n                if isinstance(expr.left, PropertyAccess):\n                    try:\n                        value = evaluator.evaluate(expr.right)\n                    except CypherExecutionError:\n                        return {}\n                    if value is None or isinstance(value, (Node, Relationship, list, dict)):\n                        return {}\n                    return {expr.left.variable: {expr.left.property: value}}\n                if isinstance(expr.right, PropertyAccess):\n                    try:\n                        value = evaluator.evaluate(expr.left)\n                    except CypherExecutionError:\n                        return {}\n                    if value is None or isinstance(value, (Node, Relationship, list, dict)):\n                        return {}\n                    return {expr.right.variable: {expr.right.property: value}}\n\n        return {}\n\n    def _match_pattern_function(self, pattern_func: PatternFunction) -&gt; list[dict]:\n        \"\"\"Match shortestPath/allShortestPaths patterns.\"\"\"\n        inner = pattern_func.pattern\n        if len(inner.elements) != 2:\n            raise CypherExecutionError(\n                f\"{pattern_func.name} only supports a single relationship pattern\"\n            )\n\n        source_elem = inner.elements[0]\n        target_elem = inner.elements[1]\n        rel_pattern = source_elem.relationship\n        if rel_pattern is None:\n            raise CypherExecutionError(\n                f\"{pattern_func.name} requires a relationship pattern\"\n            )\n\n        source_properties = self._evaluate_properties(source_elem.node.properties, None)\n        target_properties = self._evaluate_properties(target_elem.node.properties, None)\n        rel_properties = self._evaluate_properties(rel_pattern.properties, None)\n\n        start_nodes = self.db.match_nodes(\n            labels=source_elem.node.labels if source_elem.node.labels else None,\n            properties=source_properties if source_properties else None\n        )\n        end_nodes = self.db.match_nodes(\n            labels=target_elem.node.labels if target_elem.node.labels else None,\n            properties=target_properties if target_properties else None\n        )\n\n        all_paths = pattern_func.name == 'ALLSHORTESTPATHS'\n\n        results = []\n        for start_node in start_nodes:\n            for end_node in end_nodes:\n                paths = self._find_shortest_paths(\n                    start_node,\n                    end_node,\n                    rel_pattern,\n                    all_paths=all_paths,\n                    rel_properties=rel_properties\n                )\n                for nodes_path, rels_path in paths:\n                    bindings = {}\n                    if source_elem.node.variable:\n                        bindings[source_elem.node.variable] = start_node\n                    if target_elem.node.variable:\n                        bindings[target_elem.node.variable] = end_node\n                    if rel_pattern.variable:\n                        if rel_pattern.min_hops == 1 and rel_pattern.max_hops == 1:\n                            bindings[rel_pattern.variable] = rels_path[0]\n                        else:\n                            bindings[rel_pattern.variable] = rels_path\n                    if pattern_func.variable:\n                        bindings[pattern_func.variable] = Path(\n                            nodes=nodes_path,\n                            relationships=rels_path\n                        )\n                    results.append(bindings)\n\n        return results\n\n    def _resolve_max_hops(self, rel_pattern: RelationshipPattern) -&gt; int:\n        \"\"\"Resolve max hop limit for a relationship pattern.\"\"\"\n        max_hops = rel_pattern.max_hops\n        if max_hops is None:\n            max_hops = getattr(self.db, \"cypher_max_hops\", None)\n            if not max_hops or max_hops &lt;= 0:\n                raise CypherExecutionError(\n                    \"Unbounded variable-length paths require a configured max hop limit\"\n                )\n        return max_hops\n\n    def _find_shortest_paths(\n        self,\n        start_node: Node,\n        end_node: Node,\n        rel_pattern: RelationshipPattern,\n        all_paths: bool = False,\n        rel_properties: dict[str, Any] | None = None\n    ) -&gt; list[tuple[list[Node], list[Relationship]]]:\n        \"\"\"Find shortest paths honoring relationship constraints.\"\"\"\n        min_hops = rel_pattern.min_hops\n        max_hops = self._resolve_max_hops(rel_pattern)\n\n        if start_node.id == end_node.id:\n            if min_hops == 0:\n                return [([start_node], [])]\n            return []\n\n        from collections import deque\n\n        results: list[tuple[list[Node], list[Relationship]]] = []\n        queue = deque([(start_node, [start_node], [], {start_node.id})])\n        shortest_len = None\n\n        while queue:\n            current_node, nodes_path, rels_path, visited_ids = queue.popleft()\n            depth = len(rels_path)\n\n            if shortest_len is not None and depth &gt;= shortest_len:\n                continue\n            if depth &gt;= max_hops:\n                continue\n\n            for rel, next_node in self._get_next_relationships(\n                current_node,\n                rel_pattern,\n                rel_properties=rel_properties\n            ):\n                if next_node.id in visited_ids:\n                    continue\n                new_nodes = nodes_path + [next_node]\n                new_rels = rels_path + [rel]\n                new_depth = depth + 1\n                if new_depth &gt; max_hops:\n                    continue\n\n                if next_node.id == end_node.id and new_depth &gt;= min_hops:\n                    if shortest_len is None or new_depth == shortest_len:\n                        results.append((new_nodes, new_rels))\n                        shortest_len = new_depth\n                    elif new_depth &lt; shortest_len:\n                        results = [(new_nodes, new_rels)]\n                        shortest_len = new_depth\n\n                    if not all_paths:\n                        return results[:1]\n\n                if shortest_len is None or new_depth &lt; shortest_len:\n                    queue.append((next_node, new_nodes, new_rels, visited_ids | {next_node.id}))\n\n        return results\n\n    def _match_single_node(\n        self,\n        element: PatternElement,\n        path_variable: str | None = None,\n        property_filters: dict[str, dict[str, Any]] | None = None,\n        context: dict[str, Any] | None = None,\n    ) -&gt; list[dict]:\n        \"\"\"Match a single node pattern.\n\n        Args:\n            element: PatternElement with node pattern only\n\n        Returns:\n            List of variable bindings\n        \"\"\"\n        node_pattern = element.node\n        if context and node_pattern.variable and node_pattern.variable in context:\n            bound = self._resolve_bound_node(context.get(node_pattern.variable))\n            if bound is None:\n                return []\n            evaluated_properties = self._evaluate_properties(node_pattern.properties, context)\n            if not self._node_matches_pattern(bound, node_pattern, properties=evaluated_properties):\n                return []\n            result = {}\n            result[node_pattern.variable] = bound\n            if path_variable:\n                result[path_variable] = Path(nodes=[bound], relationships=[])\n            return [result]\n\n        evaluated_properties = self._evaluate_properties(node_pattern.properties, context)\n        merged_properties = evaluated_properties\n        if property_filters and node_pattern.variable in property_filters:\n            merged_properties = self._merge_property_filters(\n                evaluated_properties,\n                property_filters[node_pattern.variable]\n            )\n            if merged_properties is None:\n                return []\n\n        # Use match_nodes API\n        nodes = self.db.match_nodes(\n            labels=node_pattern.labels if node_pattern.labels else None,\n            properties=merged_properties if merged_properties else None\n        )\n\n        # Build results\n        results = []\n        for node in nodes:\n            result = {}\n            if node_pattern.variable:\n                result[node_pattern.variable] = node\n            if path_variable:\n                result[path_variable] = Path(nodes=[node], relationships=[])\n            results.append(result)\n\n        return results\n\n    def _match_relationship_pattern(\n        self,\n        pattern: Pattern,\n        path_variable: str | None = None,\n        property_filters: dict[str, dict[str, Any]] | None = None,\n        context: dict[str, Any] | None = None,\n    ) -&gt; list[dict]:\n        \"\"\"Match a relationship pattern like (a)-[r:TYPE]-&gt;(b).\n\n        Args:\n            pattern: Pattern with multiple elements connected by relationships\n\n        Returns:\n            List of variable bindings for (source, relationship, target) tuples\n        \"\"\"\n        if len(pattern.elements) != 2:\n            return self._match_multi_hop_relationship_pattern(\n                pattern,\n                path_variable=path_variable,\n                context=context\n            )\n\n        source_elem = pattern.elements[0]\n        target_elem = pattern.elements[1]\n        rel_pattern = source_elem.relationship\n\n        if rel_pattern is None:\n            raise CypherExecutionError(\"Invalid relationship pattern\")\n\n        if rel_pattern.min_hops != 1 or rel_pattern.max_hops != 1:\n            return self._match_variable_length_relationship_pattern(\n                source_elem,\n                target_elem,\n                rel_pattern,\n                path_variable=path_variable,\n                context=context\n            )\n\n        filters = property_filters or {}\n        source_properties = self._evaluate_properties(source_elem.node.properties, context)\n        if source_elem.node.variable in filters:\n            source_properties = self._merge_property_filters(\n                source_properties,\n                filters[source_elem.node.variable]\n            )\n            if source_properties is None:\n                return []\n\n        target_properties = self._evaluate_properties(target_elem.node.properties, context)\n        if target_elem.node.variable in filters:\n            target_properties = self._merge_property_filters(\n                target_properties,\n                filters[target_elem.node.variable]\n            )\n            if target_properties is None:\n                return []\n\n        rel_properties = self._evaluate_properties(rel_pattern.properties, context)\n        if rel_pattern.variable and rel_pattern.variable in filters:\n            rel_properties = self._merge_property_filters(\n                rel_properties,\n                filters[rel_pattern.variable]\n            )\n            if rel_properties is None:\n                return []\n\n        # Match source nodes\n        source_nodes = None\n        if context and source_elem.node.variable and source_elem.node.variable in context:\n            bound_source = self._resolve_bound_node(context.get(source_elem.node.variable))\n            if bound_source and self._node_matches_pattern(bound_source, source_elem.node, properties=source_properties):\n                source_nodes = [bound_source]\n            else:\n                return []\n        if source_nodes is None:\n            source_nodes = self.db.match_nodes(\n                labels=source_elem.node.labels if source_elem.node.labels else None,\n                properties=source_properties if source_properties else None\n            )\n\n        target_ids = None\n        if context and target_elem.node.variable and target_elem.node.variable in context:\n            bound_target = self._resolve_bound_node(context.get(target_elem.node.variable))\n            if bound_target and self._node_matches_pattern(bound_target, target_elem.node, properties=target_properties):\n                target_ids = {bound_target.id}\n            else:\n                return []\n        elif target_elem.node.labels or target_properties:\n            target_nodes = self.db.match_nodes(\n                labels=target_elem.node.labels if target_elem.node.labels else None,\n                properties=target_properties if target_properties else None\n            )\n            target_ids = {node.id for node in target_nodes}\n\n        # For each source node, find matching relationships\n        results = []\n        for source_node in source_nodes:\n            # Get relationships based on direction\n            if rel_pattern.direction == 'outgoing':\n                rels = self.db.match_relationships(\n                    source_id=source_node.id,\n                    rel_type=rel_pattern.rel_type,\n                    properties=rel_properties if rel_properties else None\n                )\n            elif rel_pattern.direction == 'incoming':\n                rels = self.db.match_relationships(\n                    target_id=source_node.id,\n                    rel_type=rel_pattern.rel_type,\n                    properties=rel_properties if rel_properties else None\n                )\n            else:  # 'both'\n                outgoing = self.db.match_relationships(\n                    source_id=source_node.id,\n                    rel_type=rel_pattern.rel_type,\n                    properties=rel_properties if rel_properties else None\n                )\n                incoming = self.db.match_relationships(\n                    target_id=source_node.id,\n                    rel_type=rel_pattern.rel_type,\n                    properties=rel_properties if rel_properties else None\n                )\n                rels = outgoing + incoming\n\n            # For each relationship, check target node matches\n            for rel in rels:\n                # Determine target node id based on direction\n                if rel_pattern.direction == 'incoming':\n                    target_id = rel.source_id\n                else:\n                    target_id = rel.target_id\n\n                if target_ids is not None and target_id not in target_ids:\n                    continue\n\n                target_node = self.db.get_node(target_id)\n                if target_node is None:\n                    continue\n\n                # Check if target matches pattern\n                if target_elem.node.labels:\n                    if not all(label in target_node.labels for label in target_elem.node.labels):\n                        continue\n\n                if target_properties:\n                    props_match = all(\n                        target_node.properties.get(k) == v\n                        for k, v in target_properties.items()\n                    )\n                    if not props_match:\n                        continue\n\n                # Build result\n                result = {}\n                if source_elem.node.variable:\n                    result[source_elem.node.variable] = source_node\n                if rel_pattern.variable:\n                    result[rel_pattern.variable] = rel\n                if target_elem.node.variable:\n                    result[target_elem.node.variable] = target_node\n                if path_variable:\n                    result[path_variable] = Path(nodes=[source_node, target_node], relationships=[rel])\n\n                results.append(result)\n\n        return results\n\n    def _match_multi_hop_relationship_pattern(\n        self,\n        pattern: Pattern,\n        path_variable: str | None = None,\n        context: dict[str, Any] | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Match multi-hop relationship patterns across a chain.\"\"\"\n        elements = pattern.elements\n        if len(elements) &lt; 2:\n            return []\n\n        first_elem = elements[0]\n        first_properties = self._evaluate_properties(first_elem.node.properties, context)\n        start_nodes = self.db.match_nodes(\n            labels=first_elem.node.labels if first_elem.node.labels else None,\n            properties=first_properties if first_properties else None\n        )\n\n        results = []\n\n        for start_node in start_nodes:\n            base_bindings = {}\n            if first_elem.node.variable:\n                base_bindings[first_elem.node.variable] = start_node\n\n            def walk(\n                index: int,\n                current_node: Node,\n                bindings: dict,\n                node_path: list[Node],\n                rel_path: list[Relationship]\n            ) -&gt; None:\n                if index == len(elements) - 1:\n                    if path_variable:\n                        bindings[path_variable] = Path(\n                            nodes=node_path.copy(),\n                            relationships=rel_path.copy()\n                        )\n                    results.append(bindings)\n                    return\n\n                rel_pattern = elements[index].relationship\n                if rel_pattern is None:\n                    raise CypherExecutionError(\"Missing relationship in multi-hop pattern\")\n\n                next_node_pattern = elements[index + 1].node\n\n                rel_properties = self._evaluate_properties(rel_pattern.properties, context)\n                next_properties = self._evaluate_properties(next_node_pattern.properties, context)\n\n                for next_node, rel_value, segment_nodes in self._expand_relationship_segment(\n                    current_node,\n                    rel_pattern,\n                    next_node_pattern,\n                    rel_properties=rel_properties,\n                    target_properties=next_properties\n                ):\n                    if next_node_pattern.variable and context and next_node_pattern.variable in context:\n                        bound_next = self._resolve_bound_node(context.get(next_node_pattern.variable))\n                        if bound_next is None or bound_next.id != next_node.id:\n                            continue\n                    new_bindings = bindings.copy()\n                    if rel_pattern.variable:\n                        new_bindings[rel_pattern.variable] = rel_value\n                    if next_node_pattern.variable:\n                        new_bindings[next_node_pattern.variable] = next_node\n                    if isinstance(rel_value, list):\n                        new_rel_path = rel_path + rel_value\n                    else:\n                        new_rel_path = rel_path + [rel_value]\n                    new_node_path = node_path + segment_nodes[1:]\n                    walk(index + 1, next_node, new_bindings, new_node_path, new_rel_path)\n\n            walk(0, start_node, base_bindings, [start_node], [])\n\n        return results\n\n    def _expand_relationship_segment(\n        self,\n        start_node: Node,\n        rel_pattern: RelationshipPattern,\n        target_pattern: NodePattern,\n        rel_properties: dict[str, Any] | None = None,\n        target_properties: dict[str, Any] | None = None\n    ) -&gt; list[tuple[Node, Any, list[Node]]]:\n        \"\"\"Expand a relationship segment to matching end nodes.\"\"\"\n        if rel_pattern.min_hops == 1 and rel_pattern.max_hops == 1:\n            results = []\n            for rel, next_node in self._get_next_relationships(\n                start_node,\n                rel_pattern,\n                rel_properties=rel_properties\n            ):\n                if not self._node_matches_pattern(\n                    next_node,\n                    target_pattern,\n                    properties=target_properties\n                ):\n                    continue\n                results.append((next_node, rel, [start_node, next_node]))\n            return results\n\n        return self._expand_variable_length_segment(\n            start_node,\n            rel_pattern,\n            target_pattern,\n            rel_properties=rel_properties,\n            target_properties=target_properties\n        )\n\n    def _expand_variable_length_segment(\n        self,\n        start_node: Node,\n        rel_pattern: RelationshipPattern,\n        target_pattern: NodePattern,\n        rel_properties: dict[str, Any] | None = None,\n        target_properties: dict[str, Any] | None = None\n    ) -&gt; list[tuple[Node, list[Relationship], list[Node]]]:\n        \"\"\"Expand a variable-length segment with DFS and hop limits.\"\"\"\n        min_hops = rel_pattern.min_hops\n        max_hops = rel_pattern.max_hops\n\n        if max_hops is None:\n            max_hops = getattr(self.db, \"cypher_max_hops\", None)\n            if not max_hops or max_hops &lt;= 0:\n                raise CypherExecutionError(\n                    \"Unbounded variable-length paths require a configured max hop limit\"\n                )\n\n        results = []\n\n        def dfs(\n            current_node: Node,\n            depth: int,\n            rel_path: list[Relationship],\n            node_path: list[Node],\n            visited_ids: set[int]\n        ):\n            if depth &gt;= min_hops and self._node_matches_pattern(\n                current_node,\n                target_pattern,\n                properties=target_properties\n            ):\n                results.append((current_node, rel_path.copy(), node_path.copy()))\n\n            if depth == max_hops:\n                return\n\n            for rel, next_node in self._get_next_relationships(\n                current_node,\n                rel_pattern,\n                rel_properties=rel_properties\n            ):\n                if next_node.id in visited_ids:\n                    continue\n                visited_ids.add(next_node.id)\n                rel_path.append(rel)\n                node_path.append(next_node)\n                dfs(next_node, depth + 1, rel_path, node_path, visited_ids)\n                node_path.pop()\n                rel_path.pop()\n                visited_ids.remove(next_node.id)\n\n        dfs(start_node, 0, [], [start_node], {start_node.id})\n\n        return results\n\n    def _match_variable_length_relationship_pattern(\n        self,\n        source_elem: PatternElement,\n        target_elem: PatternElement,\n        rel_pattern: RelationshipPattern,\n        path_variable: str | None = None,\n        context: dict[str, Any] | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Match variable-length relationship pattern (e.g., [:TYPE*1..3]).\"\"\"\n        min_hops = rel_pattern.min_hops\n        max_hops = rel_pattern.max_hops\n\n        if max_hops is None:\n            max_hops = getattr(self.db, \"cypher_max_hops\", None)\n            if not max_hops or max_hops &lt;= 0:\n                raise CypherExecutionError(\n                    \"Unbounded variable-length paths require a configured max hop limit\"\n                )\n\n        source_properties = self._evaluate_properties(source_elem.node.properties, context)\n        target_properties = self._evaluate_properties(target_elem.node.properties, context)\n        rel_properties = self._evaluate_properties(rel_pattern.properties, context)\n\n        # Match source nodes\n        source_nodes = None\n        if context and source_elem.node.variable and source_elem.node.variable in context:\n            bound_source = self._resolve_bound_node(context.get(source_elem.node.variable))\n            if bound_source and self._node_matches_pattern(bound_source, source_elem.node, properties=source_properties):\n                source_nodes = [bound_source]\n            else:\n                return []\n        if source_nodes is None:\n            source_nodes = self.db.match_nodes(\n                labels=source_elem.node.labels if source_elem.node.labels else None,\n                properties=source_properties if source_properties else None\n            )\n        bound_target = None\n        if context and target_elem.node.variable and target_elem.node.variable in context:\n            bound_target = self._resolve_bound_node(context.get(target_elem.node.variable))\n\n        results = []\n\n        for source_node in source_nodes:\n            def dfs(current_node, depth, rel_path, node_path, visited_ids):\n                if depth &gt;= min_hops:\n                    if self._node_matches_pattern(\n                        current_node,\n                        target_elem.node,\n                        properties=target_properties\n                    ):\n                        if not bound_target or current_node.id == bound_target.id:\n                            result = {}\n                            if source_elem.node.variable:\n                                result[source_elem.node.variable] = source_node\n                            if target_elem.node.variable:\n                                result[target_elem.node.variable] = current_node\n                            if rel_pattern.variable:\n                                result[rel_pattern.variable] = rel_path.copy()\n                            if path_variable:\n                                result[path_variable] = Path(\n                                    nodes=node_path.copy(),\n                                    relationships=rel_path.copy()\n                                )\n                            results.append(result)\n\n                if depth == max_hops:\n                    return\n\n                for rel, next_node in self._get_next_relationships(\n                    current_node,\n                    rel_pattern,\n                    rel_properties=rel_properties\n                ):\n                    if next_node.id in visited_ids:\n                        continue\n                    visited_ids.add(next_node.id)\n                    rel_path.append(rel)\n                    node_path.append(next_node)\n                    dfs(next_node, depth + 1, rel_path, node_path, visited_ids)\n                    node_path.pop()\n                    rel_path.pop()\n                    visited_ids.remove(next_node.id)\n\n            dfs(source_node, 0, [], [source_node], {source_node.id})\n\n        return results\n\n    def _node_matches_pattern(\n        self,\n        node: Node,\n        pattern: NodePattern,\n        properties: dict[str, Any] | None = None\n    ) -&gt; bool:\n        \"\"\"Check if a node matches a node pattern (labels and properties).\"\"\"\n        if pattern.labels:\n            if not all(label in node.labels for label in pattern.labels):\n                return False\n\n        props = properties if properties is not None else pattern.properties\n        if props:\n            for key, value in props.items():\n                if node.properties.get(key) != value:\n                    return False\n\n        return True\n\n    def _get_next_relationships(\n        self,\n        current_node: Node,\n        rel_pattern: RelationshipPattern,\n        rel_properties: dict[str, Any] | None = None\n    ) -&gt; list[tuple[Relationship, Node]]:\n        \"\"\"Get relationships and next nodes for variable-length traversal.\"\"\"\n        results = []\n\n        if rel_pattern.direction in ('outgoing', 'both'):\n            rels = self.db.match_relationships(\n                source_id=current_node.id,\n                rel_type=rel_pattern.rel_type\n            )\n            for rel in rels:\n                if not self._relationship_matches_pattern(rel, rel_pattern, rel_properties):\n                    continue\n                next_node = self.db.get_node(rel.target_id)\n                if next_node:\n                    results.append((rel, next_node))\n\n        if rel_pattern.direction in ('incoming', 'both'):\n            rels = self.db.match_relationships(\n                target_id=current_node.id,\n                rel_type=rel_pattern.rel_type\n            )\n            for rel in rels:\n                if not self._relationship_matches_pattern(rel, rel_pattern, rel_properties):\n                    continue\n                next_node = self.db.get_node(rel.source_id)\n                if next_node:\n                    results.append((rel, next_node))\n\n        return results\n\n    def _relationship_matches_pattern(\n        self,\n        rel: Relationship,\n        rel_pattern: RelationshipPattern,\n        properties: dict[str, Any] | None = None\n    ) -&gt; bool:\n        \"\"\"Check if a relationship matches type/properties constraints.\"\"\"\n        if rel_pattern.rel_type and rel.type != rel_pattern.rel_type:\n            return False\n\n        props = properties if properties is not None else rel_pattern.properties\n        if props:\n            for key, value in props.items():\n                if rel.properties.get(key) != value:\n                    return False\n\n        return True\n\n    def _filter_where(self, matches: list[dict], where_clause: WhereClause) -&gt; list[dict]:\n        \"\"\"Filter matches using WHERE clause.\n\n        Args:\n            matches: List of variable bindings\n            where_clause: WhereClause AST node\n\n        Returns:\n            Filtered list of matches\n        \"\"\"\n        filtered = []\n\n        for match in matches:\n            evaluator = self._make_evaluator(match)\n            try:\n                result = evaluator.evaluate(where_clause.condition)\n                if result:\n                    filtered.append(match)\n            except CypherExecutionError:\n                # Skip matches that fail evaluation\n                continue\n\n        return filtered\n\n    def _apply_return(self, matches: list[dict], return_clause: ReturnClause) -&gt; list[dict]:\n        \"\"\"Apply RETURN projection to matches.\n\n        Args:\n            matches: List of variable bindings\n            return_clause: ReturnClause AST node\n\n        Returns:\n            Projected results\n        \"\"\"\n        # Check if any return item is an aggregation function\n        has_aggregation = any(isinstance(item.expression, FunctionCall) for item in return_clause.items)\n\n        if has_aggregation:\n            # Aggregation mode: return a single row with aggregated values\n            return self._apply_aggregation_return(matches, return_clause)\n        else:\n            # Normal mode: return one row per match\n            return self._apply_normal_return(matches, return_clause)\n\n    def _format_property_key(self, expr: PropertyAccess | PropertyLookup) -&gt; str:\n        \"\"\"Format property access expressions for result keys.\"\"\"\n        if isinstance(expr, PropertyAccess):\n            return f\"{expr.variable}.{expr.property}\"\n        return self._format_property_lookup(expr)\n\n    def _format_property_lookup(self, expr: PropertyLookup) -&gt; str:\n        base = expr.base_expr\n        if isinstance(base, PropertyAccess):\n            base_key = f\"{base.variable}.{base.property}\"\n        elif isinstance(base, PropertyLookup):\n            base_key = self._format_property_lookup(base)\n        elif isinstance(base, Variable):\n            base_key = base.name\n        else:\n            base_key = str(base)\n        return f\"{base_key}.{expr.property}\"\n\n    def _apply_normal_return(self, matches: list[dict], return_clause: ReturnClause) -&gt; list[dict]:\n        \"\"\"Apply non-aggregated RETURN projection.\"\"\"\n        results = []\n\n        for match in matches:\n            result = {}\n\n            for item in return_clause.items:\n                value = self._evaluate_return_expression(match, item.expression)\n\n                if item.alias:\n                    key = item.alias\n                elif isinstance(item.expression, Variable):\n                    key = item.expression.name\n                elif isinstance(item.expression, (PropertyAccess, PropertyLookup)):\n                    key = self._format_property_key(item.expression)\n                else:\n                    key = str(item.expression)\n\n                result[key] = value\n\n            results.append(result)\n\n        if return_clause.distinct:\n            return self._apply_distinct(results)\n        return results\n\n    def _apply_aggregation_return(self, matches: list[dict], return_clause: ReturnClause) -&gt; list[dict]:\n        \"\"\"Apply aggregated RETURN projection (COUNT, SUM, AVG, MIN, MAX).\"\"\"\n        result = {}\n\n        for item in return_clause.items:\n            if isinstance(item.expression, FunctionCall):\n                # Evaluate aggregation function\n                func_name = item.expression.function_name\n                arguments = item.expression.arguments\n                distinct = item.expression.distinct\n                star = item.expression.star\n\n                # Generate result key (e.g., \"COUNT(n)\" or \"SUM(n.age)\")\n                if item.alias:\n                    key = item.alias\n                else:\n                    distinct_prefix = \"DISTINCT \" if distinct else \"\"\n                    if star:\n                        key = f\"{func_name}({distinct_prefix}*)\"\n                    elif len(arguments) == 1:\n                        argument = arguments[0]\n                        if isinstance(argument, Literal):\n                            key = f\"{func_name}({distinct_prefix}{argument.value})\"\n                        elif isinstance(argument, Variable):\n                            key = f\"{func_name}({distinct_prefix}{argument.name})\"\n                        elif isinstance(argument, PropertyAccess):\n                            key = f\"{func_name}({distinct_prefix}{argument.variable}.{argument.property})\"\n                        else:\n                            key = func_name\n                    else:\n                        key = func_name\n\n                # Calculate aggregation\n                value = self._calculate_aggregation(func_name, arguments, matches, distinct, star)\n                result[key] = value\n\n            else:\n                # Mixed aggregation and non-aggregation not fully supported yet\n                # For now, just evaluate the expression on the first match\n                if len(matches) &gt; 0:\n                    evaluator = self._make_evaluator(matches[0])\n                    value = evaluator.evaluate(item.expression)\n                else:\n                    value = None\n\n                key = item.alias if item.alias else str(item.expression)\n                result[key] = value\n\n        results = [result]\n        if return_clause.distinct:\n            return self._apply_distinct(results)\n        return results\n\n    def _apply_distinct(self, rows: list[dict]) -&gt; list[dict]:\n        \"\"\"Remove duplicate rows while preserving order.\"\"\"\n        seen = set()\n        distinct_rows = []\n        for row in rows:\n            frozen = self._freeze_result(row)\n            if frozen in seen:\n                continue\n            seen.add(frozen)\n            distinct_rows.append(row)\n        return distinct_rows\n\n    def _evaluate_return_expression(self, match: dict, expr: Any) -&gt; Any:\n        \"\"\"Evaluate a RETURN expression against a match row.\"\"\"\n        if isinstance(expr, PatternComprehension):\n            return self._evaluate_pattern_comprehension(expr, match)\n\n        if isinstance(expr, Variable):\n            var_name = expr.name\n            if var_name in match:\n                return self._serialize_value(match[var_name])\n            return None\n\n        if isinstance(expr, PropertyAccess):\n            var_name = expr.variable\n            prop_name = expr.property\n            if var_name not in match:\n                return None\n            obj = match[var_name]\n            if hasattr(obj, 'properties'):\n                return obj.properties.get(prop_name)\n            if isinstance(obj, dict):\n                return obj.get(prop_name)\n            return None\n\n        evaluator = self._make_evaluator(match)\n        value = evaluator.evaluate(expr)\n        return self._serialize_value(value)\n\n    def _serialize_value(self, value: Any) -&gt; Any:\n        \"\"\"Convert model instances to dictionaries for output.\"\"\"\n        if hasattr(value, 'to_dict'):\n            return value.to_dict()\n        if isinstance(value, list):\n            return [self._serialize_value(item) for item in value]\n        if isinstance(value, dict):\n            return {k: self._serialize_value(v) for k, v in value.items()}\n        return value\n\n    def _calculate_aggregation(\n        self,\n        func_name: str,\n        arguments: list[Any],\n        matches: list[dict],\n        distinct: bool = False,\n        star: bool = False,\n    ) -&gt; Any:\n        \"\"\"Calculate aggregation function value.\n\n        Args:\n            func_name: Function name (COUNT, SUM, AVG, MIN, MAX)\n            argument: Expression to aggregate over (or None for COUNT(*))\n            matches: List of variable bindings\n\n        Returns:\n            Aggregated value\n        \"\"\"\n        if func_name != 'COUNT' and star:\n            raise CypherExecutionError(f\"{func_name}(*) is not supported\")\n\n        if func_name == 'COUNT':\n            if star:\n                # COUNT(*) - count all rows\n                return len(matches)\n            else:\n                if not arguments:\n                    raise CypherExecutionError(\"COUNT() expects an argument or *\")\n                # COUNT(expr) - count non-null values\n                values = []\n                for match in matches:\n                    evaluator = self._make_evaluator(match)\n                    try:\n                        value = evaluator.evaluate(arguments[0]) if arguments else None\n                        if value is not None:\n                            values.append(value)\n                    except:\n                        pass\n                if distinct:\n                    values = self._distinct_values(values)\n                return len(values)\n\n        elif func_name in ('SUM', 'AVG', 'MIN', 'MAX', 'COLLECT', 'STDDEV', 'PERCENTILECONT'):\n            if not arguments:\n                raise CypherExecutionError(f\"{func_name}() expects at least 1 argument\")\n            # Collect values\n            values = []\n            for match in matches:\n                evaluator = self._make_evaluator(match)\n                try:\n                    value = evaluator.evaluate(arguments[0]) if arguments else None\n                    if func_name == 'COLLECT':\n                        values.append(value)\n                    elif value is not None:\n                        values.append(value)\n                except:\n                    pass\n\n            if distinct:\n                values = self._distinct_values(values)\n\n            if func_name == 'COLLECT':\n                return values\n\n            if not values:\n                return None\n\n            if func_name == 'SUM':\n                return sum(values)\n            elif func_name == 'AVG':\n                return sum(values) / len(values)\n            elif func_name == 'MIN':\n                return min(values)\n            elif func_name == 'MAX':\n                return max(values)\n            elif func_name == 'STDDEV':\n                if len(values) == 1:\n                    return 0.0\n                mean = sum(values) / len(values)\n                variance = sum((value - mean) ** 2 for value in values) / len(values)\n                return variance ** 0.5\n            elif func_name == 'PERCENTILECONT':\n                if len(arguments) &lt; 2:\n                    raise CypherExecutionError(\"PERCENTILECONT requires value and percentile\")\n                percentile = evaluator.evaluate(arguments[1])\n                if percentile is None:\n                    return None\n                if not isinstance(percentile, (int, float)):\n                    raise CypherExecutionError(\"PERCENTILECONT percentile must be a number\")\n                if percentile &lt; 0 or percentile &gt; 1:\n                    raise CypherExecutionError(\"PERCENTILECONT percentile must be between 0 and 1\")\n                sorted_values = sorted(values)\n                if len(sorted_values) == 1:\n                    return float(sorted_values[0])\n                index = percentile * (len(sorted_values) - 1)\n                lower_index = int(index)\n                upper_index = min(lower_index + 1, len(sorted_values) - 1)\n                lower = sorted_values[lower_index]\n                upper = sorted_values[upper_index]\n                if lower_index == upper_index:\n                    return float(lower)\n                fraction = index - lower_index\n                return lower + (upper - lower) * fraction\n\n        raise CypherExecutionError(f\"Unknown aggregation function: {func_name}\")\n\n    def _distinct_values(self, values: list[Any]) -&gt; list[Any]:\n        \"\"\"Return distinct values preserving first occurrence order.\"\"\"\n        seen = set()\n        distinct_values = []\n        for value in values:\n            frozen = self._freeze_result(value)\n            if frozen in seen:\n                continue\n            seen.add(frozen)\n            distinct_values.append(value)\n        return distinct_values\n\n    def _execute_delete(self, matches: list[dict], delete_clause) -&gt; list[dict]:\n        \"\"\"Execute DELETE clause to delete nodes and relationships.\n\n        Args:\n            matches: List of variable bindings\n            delete_clause: DeleteClause AST node\n\n        Returns:\n            List with count of deleted items\n        \"\"\"\n        deleted_nodes = 0\n        deleted_rels = 0\n\n        for match in matches:\n            for var_name in delete_clause.variables:\n                if var_name not in match:\n                    raise CypherExecutionError(f\"Variable '{var_name}' not found for DELETE\")\n\n                obj = match[var_name]\n\n                # Check if it's a Node or Relationship\n                if hasattr(obj, 'source_id'):  # It's a Relationship\n                    self.db.delete_relationship(obj.id)\n                    deleted_rels += 1\n                elif hasattr(obj, 'labels'):  # It's a Node\n                    self.db.delete_node(obj.id)\n                    deleted_nodes += 1\n                else:\n                    raise CypherExecutionError(\n                        f\"Variable '{var_name}' is not a node or relationship\"\n                    )\n\n        return [{'deleted_nodes': deleted_nodes, 'deleted_relationships': deleted_rels}]\n\n    def _execute_set(self, matches: list[dict], set_clause) -&gt; None:\n        \"\"\"Execute SET clause to update node properties.\n\n        Args:\n            matches: List of variable bindings\n            set_clause: SetClause AST node\n        \"\"\"\n        for match in matches:\n            for set_item in set_clause.items:\n                var_name = set_item.variable\n                prop_name = set_item.property\n\n                if var_name not in match:\n                    raise CypherExecutionError(f\"Variable '{var_name}' not found for SET\")\n\n                obj = match[var_name]\n\n                # Evaluate the value expression\n                evaluator = self._make_evaluator(match)\n                value = evaluator.evaluate(set_item.value)\n\n                if prop_name is None:\n                    if set_item.operator == \"+=\":\n                        if not isinstance(value, dict):\n                            raise CypherExecutionError(\"SET += expects a map value\")\n                        merged = obj.properties.copy()\n                        merged.update(value)\n                        self._apply_properties_update(obj, merged, replace=True)\n                    elif set_item.operator == \"=\":\n                        if not isinstance(value, dict):\n                            raise CypherExecutionError(\"SET = expects a map value\")\n                        self._apply_properties_update(obj, value, replace=True)\n                    else:\n                        raise CypherExecutionError(f\"Unsupported SET operator: {set_item.operator}\")\n                else:\n                    new_properties = obj.properties.copy()\n                    new_properties[prop_name] = value\n                    self._apply_properties_update(obj, new_properties, replace=True)\n\n    def _apply_properties_update(self, obj: Any, properties: dict, replace: bool) -&gt; None:\n        \"\"\"Apply property updates to a node or relationship.\"\"\"\n        if not hasattr(obj, 'properties'):\n            raise CypherExecutionError(\"SET target does not have properties\")\n        if hasattr(obj, 'labels'):\n            if replace:\n                self.db.replace_node_properties(obj.id, properties)\n            else:\n                self.db.update_node_properties(obj.id, properties)\n            obj.properties = properties\n            return\n        if hasattr(obj, 'source_id'):\n            if replace:\n                self.db.replace_relationship_properties(obj.id, properties)\n            else:\n                self.db.update_relationship_properties(obj.id, properties)\n            obj.properties = properties\n            return\n        raise CypherExecutionError(\"SET target is not a node or relationship\")\n\n    def _execute_load_csv(self, clause: LoadCsvClause, input_results: list[dict]) -&gt; list[dict]:\n        \"\"\"Execute LOAD CSV clause to produce rows.\"\"\"\n        if not input_results:\n            input_results = [{}]\n\n        output = []\n        for row in input_results:\n            evaluator = self._make_evaluator(row)\n            source = evaluator.evaluate(clause.source)\n            if not isinstance(source, str):\n                raise CypherExecutionError(\"LOAD CSV source must be a string\")\n\n            rows = self._read_csv_rows(source, clause.with_headers)\n            for csv_row in rows:\n                merged = row.copy()\n                merged[clause.variable] = csv_row\n                output.append(merged)\n        return output\n\n    def _read_csv_rows(self, source: str, with_headers: bool) -&gt; list[Any]:\n        \"\"\"Read CSV rows from a URL or local path.\"\"\"\n        if source.startswith(\"http://\") or source.startswith(\"https://\"):\n            with urllib.request.urlopen(source) as response:\n                data = response.read().decode(\"utf-8\")\n            handle = io.StringIO(data)\n            return self._parse_csv(handle, with_headers)\n\n        if source.startswith(\"file://\"):\n            source = source[len(\"file://\"):]\n        if not os.path.exists(source):\n            raise CypherExecutionError(f\"LOAD CSV file not found: {source}\")\n        with open(source, \"r\", encoding=\"utf-8\") as handle:\n            data = handle.read()\n        return self._parse_csv(io.StringIO(data), with_headers)\n\n    def _parse_csv(self, handle, with_headers: bool) -&gt; list[Any]:\n        if with_headers:\n            reader = csv.DictReader(handle)\n            cleaned_rows = []\n            for row in reader:\n                cleaned = {key: value for key, value in row.items() if isinstance(key, str)}\n                cleaned_rows.append(cleaned)\n            return cleaned_rows\n        reader = csv.reader(handle)\n        return [list(row) for row in reader]\n\n    def _execute_remove(self, matches: list[dict], remove_clause) -&gt; None:\n        \"\"\"Execute REMOVE clause to remove properties or labels from nodes.\n\n        Args:\n            matches: List of variable bindings\n            remove_clause: RemoveClause AST node\n\n        Supports:\n            REMOVE n.property  - Remove a property\n            REMOVE n:Label     - Remove a label\n        \"\"\"\n        for match in matches:\n            for remove_item in remove_clause.items:\n                var_name = remove_item.variable\n\n                if var_name not in match:\n                    raise CypherExecutionError(f\"Variable '{var_name}' not found for REMOVE\")\n\n                obj = match[var_name]\n\n                if not hasattr(obj, 'labels'):  # Must be a Node\n                    raise CypherExecutionError(\n                        f\"REMOVE is only supported for nodes, not relationships\"\n                    )\n\n                if remove_item.property:\n                    # Remove property: REMOVE n.age\n                    prop_name = remove_item.property\n\n                    # Check if property exists\n                    if prop_name not in obj.properties:\n                        # Property doesn't exist - silently continue (Neo4j behavior)\n                        continue\n\n                    # Remove from properties dict\n                    new_properties = obj.properties.copy()\n                    del new_properties[prop_name]\n\n                    # Update in database (direct SQL since update_node_properties does merge)\n                    properties_json = orjson.dumps(new_properties).decode('utf-8')\n                    self.db.conn.execute(\n                        \"UPDATE nodes SET properties = ? WHERE id = ?\",\n                        (properties_json, obj.id)\n                    )\n                    if not self.db._in_transaction:\n                        self.db.conn.commit()\n\n                    # Update object in memory\n                    obj.properties = new_properties\n\n                elif remove_item.label:\n                    # Remove label: REMOVE n:OldLabel\n                    label_name = remove_item.label\n\n                    # Check if label exists\n                    if label_name not in obj.labels:\n                        # Label doesn't exist - silently continue (Neo4j behavior)\n                        continue\n\n                    # Remove label using database API\n                    self.db.remove_labels(obj.id, [label_name])\n                    # Update object in memory\n                    obj.labels = [l for l in obj.labels if l != label_name]\n\n                else:\n                    raise CypherExecutionError(\n                        f\"REMOVE item must have either property or label\"\n                    )\n\n    def _apply_order_by(self, matches: list[dict], order_by_clause) -&gt; list[dict]:\n        \"\"\"Apply ORDER BY clause to sort results.\n\n        Args:\n            matches: List of result dictionaries\n            order_by_clause: OrderByClause AST node\n\n        Returns:\n            Sorted list of results\n        \"\"\"\n        def get_sort_key(match):\n            \"\"\"Generate sort key tuple for a match.\"\"\"\n            keys = []\n            for item in order_by_clause.items:\n                # Evaluate the expression for this match\n                evaluator = self._make_evaluator(match)\n                try:\n                    value = evaluator.evaluate(item.expression)\n                    # Handle None values (sort to end)\n                    if value is None:\n                        # Use a large value for None so it sorts to the end\n                        value = (float('inf'),)\n                    else:\n                        # For DESC, negate numeric values or use reverse wrapper\n                        if not item.ascending:\n                            # Wrap value so it sorts in reverse\n                            if isinstance(value, (int, float)):\n                                value = (-value,)\n                            else:\n                                # For strings, we can't easily negate, so use a wrapper\n                                value = (ReverseWrapper(value),)\n                        else:\n                            value = (value,)\n                    keys.append(value)\n                except:\n                    # If evaluation fails, treat as None (end of list)\n                    keys.append((float('inf'),))\n            return tuple(keys)\n\n        # Sort without reverse - direction is handled in the key\n        sorted_matches = sorted(matches, key=get_sort_key)\n\n        return sorted_matches\n\n    def _execute_with(self, clause: WithClause, input_results: list[dict]) -&gt; list[dict]:\n        \"\"\"Execute WITH clause as a pipeline stage.\n\n        Args:\n            clause: WithClause AST node\n            input_results: Results from previous stage\n\n        Returns:\n            Transformed/filtered results\n\n        The WITH clause:\n        1. Projects specific items from input (like RETURN)\n        2. Can apply WHERE filter\n        3. Can apply ORDER BY, SKIP, LIMIT\n        4. Results pass to next stage\n        \"\"\"\n        if not input_results:\n            return []\n\n        has_aggregation = any(\n            isinstance(item.expression, FunctionCall)\n            for item in clause.items\n        )\n\n        # Apply WHERE against the full input rows to allow aliases in WITH\n        if clause.where_clause:\n            filtered_input = []\n            for match in input_results:\n                evaluator = self._make_evaluator(match)\n                try:\n                    if evaluator.evaluate(clause.where_clause.condition):\n                        filtered_input.append(match)\n                except:\n                    pass\n            input_results = filtered_input\n\n        if has_aggregation:\n            result = {}\n            for item in clause.items:\n                if isinstance(item.expression, FunctionCall):\n                    value = self._calculate_aggregation(\n                        item.expression.function_name,\n                        item.expression.arguments,\n                        input_results,\n                        item.expression.distinct,\n                        item.expression.star\n                    )\n                else:\n                    evaluator = self._make_evaluator(input_results[0])\n                    value = evaluator.evaluate(item.expression)\n\n                if item.alias:\n                    result[item.alias] = value\n                elif isinstance(item.expression, FunctionCall):\n                    distinct_prefix = \"DISTINCT \" if item.expression.distinct else \"\"\n                    if item.expression.star:\n                        key = f\"{item.expression.function_name}({distinct_prefix}*)\"\n                    elif item.expression.arguments and isinstance(item.expression.arguments[0], PropertyAccess):\n                        arg = item.expression.arguments[0]\n                        key = f\"{item.expression.function_name}({distinct_prefix}{arg.variable}.{arg.property})\"\n                    else:\n                        key = f\"{item.expression.function_name}({distinct_prefix}...)\"\n                    result[key] = value\n                else:\n                    result[str(item.expression)] = value\n\n            projected_results = [result]\n        else:\n            projected_results = []\n            for match in input_results:\n                result = {}\n                for item in clause.items:\n                    evaluator = self._make_evaluator(match)\n\n                    if isinstance(item.expression, (PropertyAccess, PropertyLookup)):\n                        value = evaluator.evaluate(item.expression)\n                    elif isinstance(item.expression, Variable):\n                        var_name = item.expression.name\n                        value = match.get(var_name)\n                    else:\n                        value = evaluator.evaluate(item.expression)\n\n                    if item.alias:\n                        result[item.alias] = value\n                    elif isinstance(item.expression, (PropertyAccess, PropertyLookup)):\n                        key = self._format_property_key(item.expression)\n                        result[key] = value\n                    elif isinstance(item.expression, Variable):\n                        result[item.expression.name] = value\n                    else:\n                        result[str(item.expression)] = value\n\n                projected_results.append(result)\n\n        if clause.distinct:\n            projected_results = self._apply_distinct(projected_results)\n\n        if clause.order_by_clause:\n            projected_results = self._apply_order_by(projected_results, clause.order_by_clause)\n\n        if clause.skip_clause:\n            projected_results = projected_results[clause.skip_clause.count:]\n\n        if clause.limit_clause:\n            projected_results = projected_results[:clause.limit_clause.count]\n\n        if clause.return_clause:\n            projected_results = self._apply_normal_return(projected_results, clause.return_clause)\n\n        return projected_results\n\n    def _execute_create_index(self, clause: CreateIndexClause) -&gt; list[dict]:\n        \"\"\"Execute CREATE INDEX clause.\"\"\"\n        if clause.entity == \"node\":\n            name = self.db.create_node_index(clause.label_or_type, clause.property, unique=clause.unique)\n        else:\n            name = self.db.create_relationship_index(clause.label_or_type, clause.property, unique=clause.unique)\n        return [{\"name\": name}]\n\n    def _execute_drop_index(self, clause: DropIndexClause) -&gt; list[dict]:\n        \"\"\"Execute DROP INDEX clause.\"\"\"\n        self.db.drop_index(clause.name)\n        return []\n\n    def _execute_show_indexes(self, clause: ShowIndexesClause) -&gt; list[dict]:\n        \"\"\"Execute SHOW INDEXES clause.\"\"\"\n        indexes = self.db.list_indexes()\n        if clause.where_expr is None:\n            return indexes\n        filtered = []\n        for index in indexes:\n            evaluator = self._make_evaluator(index)\n            try:\n                if evaluator.evaluate(clause.where_expr):\n                    filtered.append(index)\n            except CypherExecutionError:\n                continue\n        return filtered\n\n    def _execute_create_constraint(self, clause: CreateConstraintClause) -&gt; list[dict]:\n        \"\"\"Execute CREATE CONSTRAINT clause.\"\"\"\n        if clause.constraint_type == \"UNIQUE\":\n            if clause.entity == \"node\":\n                name = self.db.create_node_uniqueness_constraint(\n                    clause.label_or_type, clause.property, clause.name, clause.if_not_exists\n                )\n            else:\n                name = self.db.create_relationship_uniqueness_constraint(\n                    clause.label_or_type, clause.property, clause.name, clause.if_not_exists\n                )\n        elif clause.constraint_type == \"EXISTS\":\n            if clause.entity == \"node\":\n                name = self.db.create_node_existence_constraint(\n                    clause.label_or_type, clause.property, clause.name, clause.if_not_exists\n                )\n            else:\n                name = self.db.create_relationship_existence_constraint(\n                    clause.label_or_type, clause.property, clause.name, clause.if_not_exists\n                )\n        else:\n            if clause.entity == \"node\":\n                name = self.db.create_node_type_constraint(\n                    clause.label_or_type, clause.property, clause.type_name or \"\", clause.name, clause.if_not_exists\n                )\n            else:\n                name = self.db.create_relationship_type_constraint(\n                    clause.label_or_type, clause.property, clause.type_name or \"\", clause.name, clause.if_not_exists\n                )\n        return [{\"name\": name}]\n\n    def _execute_drop_constraint(self, clause: DropConstraintClause) -&gt; list[dict]:\n        \"\"\"Execute DROP CONSTRAINT clause.\"\"\"\n        self.db.drop_constraint(clause.name, clause.if_exists)\n        return []\n\n    def _execute_show_constraints(self, clause: ShowConstraintsClause) -&gt; list[dict]:\n        \"\"\"Execute SHOW CONSTRAINTS clause.\"\"\"\n        constraints = self.db.list_constraints()\n        if clause.where_expr is None:\n            return constraints\n        filtered = []\n        for constraint in constraints:\n            evaluator = self._make_evaluator(constraint)\n            try:\n                if evaluator.evaluate(clause.where_expr):\n                    filtered.append(constraint)\n            except CypherExecutionError:\n                continue\n        return filtered\n\n    def _execute_foreach(self, clause: ForeachClause, input_results: list[dict]) -&gt; list[dict]:\n        \"\"\"Execute FOREACH clause for updates.\"\"\"\n        if not input_results:\n            input_results = [{}]\n\n        for row in input_results:\n            evaluator = self._make_evaluator(row)\n            values = evaluator.evaluate(clause.list_expr)\n            if values is None:\n                values = []\n            if not isinstance(values, (list, tuple)):\n                raise CypherExecutionError(\"FOREACH list expression must be a list\")\n            for item in values:\n                local_row = row.copy()\n                local_row[clause.variable] = item\n                for action in clause.actions:\n                    if isinstance(action, CreateClause):\n                        created = self._execute_create(action, context=[local_row])\n                        if created:\n                            local_row.update(created[0])\n                    elif isinstance(action, MergeClause):\n                        merged = self._execute_merge(action, context=[local_row])\n                        if merged:\n                            local_row.update(merged[0])\n                    elif isinstance(action, SetClause):\n                        self._execute_set([local_row], action)\n                    elif isinstance(action, RemoveClause):\n                        self._execute_remove([local_row], action)\n                    elif isinstance(action, DeleteClause):\n                        self._execute_delete([local_row], action)\n                    else:\n                        raise CypherExecutionError(\n                            f\"Unsupported FOREACH action: {type(action)}\"\n                        )\n\n        return input_results\n\n    # =========================================================================\n    # Dump / Restore\n    # =========================================================================\n\n    def dump(self, file_path: str) -&gt; None:\n        \"\"\"Dump the entire database to a Cypher script file.\n\n        The generated script uses a temporary `_dump_id` property on nodes\n        to link relationships during restore. This property is removed at\n        the end of the script.\n\n        Args:\n            file_path: Path to the output .cypher file.\n        \"\"\"\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"// Grafito Database Dump\\n\")\n            f.write(\"// Generated automatically - do not edit manually\\n\\n\")\n\n            # Constraints\n            constraints = self.db.list_constraints()\n            if constraints:\n                f.write(\"// Constraints\\n\")\n                for c in constraints:\n                    entity = c[\"entity\"]\n                    label_or_type = c[\"label_or_type\"]\n                    prop = c[\"property\"]\n                    ctype = c[\"type\"]\n                    type_name = c.get(\"type_name\")\n\n                    if entity == \"node\":\n                        pattern = f\"(n:{label_or_type})\"\n                        require_expr = f\"n.{prop}\"\n                    else:\n                        pattern = f\"()-[r:{label_or_type}]-()\"\n                        require_expr = f\"r.{prop}\"\n\n                    if ctype == \"UNIQUE\":\n                        f.write(f\"CREATE CONSTRAINT FOR {pattern} REQUIRE {require_expr} IS UNIQUE;\\n\")\n                    elif ctype == \"EXISTS\":\n                        f.write(f\"CREATE CONSTRAINT FOR {pattern} REQUIRE {require_expr} IS NOT NULL;\\n\")\n                    elif ctype == \"TYPE\" and type_name:\n                        f.write(f\"CREATE CONSTRAINT FOR {pattern} REQUIRE {require_expr} IS {type_name};\\n\")\n                f.write(\"\\n\")\n\n            # Indexes\n            indexes = self.db.list_indexes()\n            if indexes:\n                f.write(\"// Indexes\\n\")\n                for idx in indexes:\n                    entity = idx[\"entity\"]\n                    label_or_type = idx[\"label_or_type\"] or \"Node\"\n                    prop = idx[\"property\"]\n                    unique = idx.get(\"unique\", False)\n\n                    unique_kw = \"UNIQUE \" if unique else \"\"\n                    if entity == \"node\":\n                        f.write(f\"CREATE {unique_kw}INDEX FOR (n:{label_or_type}) ON (n.{prop});\\n\")\n                    else:\n                        f.write(f\"CREATE {unique_kw}INDEX FOR ()-[r:{label_or_type}]-() ON (r.{prop});\\n\")\n                f.write(\"\\n\")\n\n            # Nodes\n            all_nodes = self.db.match_nodes()\n            if all_nodes:\n                f.write(\"// Nodes\\n\")\n                for node in all_nodes:\n                    labels_str = \":\".join(node.labels) if node.labels else \"\"\n                    props = dict(node.properties)\n                    props[\"_dump_id\"] = node.id\n                    props_str = self._format_properties(props)\n                    if labels_str:\n                        f.write(f\"CREATE (:{labels_str} {props_str});\\n\")\n                    else:\n                        f.write(f\"CREATE ({props_str});\\n\")\n                f.write(\"\\n\")\n\n            # Relationships\n            all_rels = self.db.match_relationships()\n            if all_rels:\n                f.write(\"// Relationships\\n\")\n                for rel in all_rels:\n                    props_str = self._format_properties(rel.properties) if rel.properties else \"\"\n                    rel_part = f\"[:{rel.type}]\" if not props_str else f\"[:{rel.type} {props_str}]\"\n                    f.write(\n                        f\"MATCH (a), (b) WHERE a._dump_id = {rel.source_id} AND b._dump_id = {rel.target_id} \"\n                        f\"CREATE (a)-{rel_part}-&gt;(b);\\n\"\n                    )\n                f.write(\"\\n\")\n\n            # Cleanup _dump_id\n            if all_nodes:\n                f.write(\"// Cleanup\\n\")\n                f.write(\"MATCH (n) REMOVE n._dump_id;\\n\")\n\n    def restore(self, file_path: str, clear_existing: bool = True) -&gt; None:\n        \"\"\"Restore the database from a Cypher script file.\n\n        The script is fully parsed before any data is modified. If parsing\n        fails, the database remains unchanged.\n\n        Args:\n            file_path: Path to the .cypher file.\n            clear_existing: If True, delete all existing data before restore.\n\n        Raises:\n            CypherSyntaxError: If any statement in the script is invalid.\n        \"\"\"\n        from .lexer import Lexer\n        from .parser import Parser\n\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            script = f.read()\n\n        # Split statements\n        statements = self.db._split_cypher_statements(script)\n\n        # Parse all statements first (validation)\n        parsed = []\n        for stmt in statements:\n            # Remove comment lines from within the statement\n            lines = [line for line in stmt.split('\\n') if not line.strip().startswith('//')]\n            stmt = '\\n'.join(lines).strip()\n            if not stmt:\n                continue\n            lexer = Lexer(stmt)\n            tokens = lexer.tokenize()\n            parser = Parser(tokens)\n            ast = parser.parse()\n            parsed.append(ast)\n\n        # Clear existing data if requested\n        if clear_existing:\n            for rel in self.db.match_relationships():\n                self.db.delete_relationship(rel.id)\n            for node in self.db.match_nodes():\n                self.db.delete_node(node.id)\n            for constraint in self.db.list_constraints():\n                self.db.drop_constraint(constraint[\"name\"], if_exists=True)\n            for idx in self.db.list_indexes():\n                self.db.drop_index(idx[\"name\"])\n\n        # Execute parsed statements\n        for ast in parsed:\n            self.execute(ast)\n\n    def _format_properties(self, props: dict) -&gt; str:\n        \"\"\"Format a properties dict as a Cypher map literal.\"\"\"\n        if not props:\n            return \"{}\"\n        parts = []\n        for k, v in props.items():\n            parts.append(f\"{k}: {self._format_value(v)}\")\n        return \"{\" + \", \".join(parts) + \"}\"\n\n    def _format_value(self, value) -&gt; str:\n        \"\"\"Format a Python value as a Cypher literal.\"\"\"\n        if value is None:\n            return \"null\"\n        if isinstance(value, bool):\n            return \"true\" if value else \"false\"\n        if isinstance(value, str):\n            escaped = value.replace(\"\\\\\", \"\\\\\\\\\").replace(\"'\", \"\\\\'\")\n            return f\"'{escaped}'\"\n        if isinstance(value, (int, float)):\n            return repr(value)\n        if isinstance(value, list):\n            items = \", \".join(self._format_value(v) for v in value)\n            return f\"[{items}]\"\n        if isinstance(value, dict):\n            parts = [f\"{k}: {self._format_value(v)}\" for k, v in value.items()]\n            return \"{\" + \", \".join(parts) + \"}\"\n        return repr(value)\n</code></pre>"},{"location":"api/cypher/#grafito.cypher.executor.CypherExecutor.dump","title":"<code>dump(file_path)</code>","text":"<p>Dump the entire database to a Cypher script file.</p> <p>The generated script uses a temporary <code>_dump_id</code> property on nodes to link relationships during restore. This property is removed at the end of the script.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the output .cypher file.</p> required Source code in <code>grafito/cypher/executor.py</code> <pre><code>def dump(self, file_path: str) -&gt; None:\n    \"\"\"Dump the entire database to a Cypher script file.\n\n    The generated script uses a temporary `_dump_id` property on nodes\n    to link relationships during restore. This property is removed at\n    the end of the script.\n\n    Args:\n        file_path: Path to the output .cypher file.\n    \"\"\"\n    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"// Grafito Database Dump\\n\")\n        f.write(\"// Generated automatically - do not edit manually\\n\\n\")\n\n        # Constraints\n        constraints = self.db.list_constraints()\n        if constraints:\n            f.write(\"// Constraints\\n\")\n            for c in constraints:\n                entity = c[\"entity\"]\n                label_or_type = c[\"label_or_type\"]\n                prop = c[\"property\"]\n                ctype = c[\"type\"]\n                type_name = c.get(\"type_name\")\n\n                if entity == \"node\":\n                    pattern = f\"(n:{label_or_type})\"\n                    require_expr = f\"n.{prop}\"\n                else:\n                    pattern = f\"()-[r:{label_or_type}]-()\"\n                    require_expr = f\"r.{prop}\"\n\n                if ctype == \"UNIQUE\":\n                    f.write(f\"CREATE CONSTRAINT FOR {pattern} REQUIRE {require_expr} IS UNIQUE;\\n\")\n                elif ctype == \"EXISTS\":\n                    f.write(f\"CREATE CONSTRAINT FOR {pattern} REQUIRE {require_expr} IS NOT NULL;\\n\")\n                elif ctype == \"TYPE\" and type_name:\n                    f.write(f\"CREATE CONSTRAINT FOR {pattern} REQUIRE {require_expr} IS {type_name};\\n\")\n            f.write(\"\\n\")\n\n        # Indexes\n        indexes = self.db.list_indexes()\n        if indexes:\n            f.write(\"// Indexes\\n\")\n            for idx in indexes:\n                entity = idx[\"entity\"]\n                label_or_type = idx[\"label_or_type\"] or \"Node\"\n                prop = idx[\"property\"]\n                unique = idx.get(\"unique\", False)\n\n                unique_kw = \"UNIQUE \" if unique else \"\"\n                if entity == \"node\":\n                    f.write(f\"CREATE {unique_kw}INDEX FOR (n:{label_or_type}) ON (n.{prop});\\n\")\n                else:\n                    f.write(f\"CREATE {unique_kw}INDEX FOR ()-[r:{label_or_type}]-() ON (r.{prop});\\n\")\n            f.write(\"\\n\")\n\n        # Nodes\n        all_nodes = self.db.match_nodes()\n        if all_nodes:\n            f.write(\"// Nodes\\n\")\n            for node in all_nodes:\n                labels_str = \":\".join(node.labels) if node.labels else \"\"\n                props = dict(node.properties)\n                props[\"_dump_id\"] = node.id\n                props_str = self._format_properties(props)\n                if labels_str:\n                    f.write(f\"CREATE (:{labels_str} {props_str});\\n\")\n                else:\n                    f.write(f\"CREATE ({props_str});\\n\")\n            f.write(\"\\n\")\n\n        # Relationships\n        all_rels = self.db.match_relationships()\n        if all_rels:\n            f.write(\"// Relationships\\n\")\n            for rel in all_rels:\n                props_str = self._format_properties(rel.properties) if rel.properties else \"\"\n                rel_part = f\"[:{rel.type}]\" if not props_str else f\"[:{rel.type} {props_str}]\"\n                f.write(\n                    f\"MATCH (a), (b) WHERE a._dump_id = {rel.source_id} AND b._dump_id = {rel.target_id} \"\n                    f\"CREATE (a)-{rel_part}-&gt;(b);\\n\"\n                )\n            f.write(\"\\n\")\n\n        # Cleanup _dump_id\n        if all_nodes:\n            f.write(\"// Cleanup\\n\")\n            f.write(\"MATCH (n) REMOVE n._dump_id;\\n\")\n</code></pre>"},{"location":"api/cypher/#grafito.cypher.executor.CypherExecutor.execute","title":"<code>execute(query)</code>","text":"<p>Execute a query and return results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Query</code> <p>Parsed Query AST</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of result dictionaries</p> <p>Raises:</p> Type Description <code>CypherExecutionError</code> <p>If execution fails</p> Source code in <code>grafito/cypher/executor.py</code> <pre><code>def execute(self, query: Query) -&gt; list[dict]:\n    \"\"\"Execute a query and return results.\n\n    Args:\n        query: Parsed Query AST\n\n    Returns:\n        List of result dictionaries\n\n    Raises:\n        CypherExecutionError: If execution fails\n    \"\"\"\n    if query.union_clauses:\n        return self._execute_union(query)\n\n    if isinstance(query.clause, SubqueryClause):\n        return self._execute_subquery(query.clause, [])\n    if isinstance(query.clause, ProcedureCallClause):\n        return self._execute_procedure_call(query.clause, [])\n\n    # Check if multi-clause query (with WITH)\n    if query.clauses:\n        return self._execute_multi_clause(query.clauses, initial_results=None)\n\n    # Single clause query\n    if isinstance(query.clause, CreateClause):\n        return self._execute_create(query.clause)\n    elif isinstance(query.clause, MergeClause):\n        return self._execute_merge(query.clause)\n    elif isinstance(query.clause, MatchClause):\n        return self._execute_match(query.clause)\n    elif isinstance(query.clause, UnwindClause):\n        return self._execute_unwind(query.clause, [{}])\n    elif isinstance(query.clause, WithClause):\n        return self._execute_with(query.clause, [{}])\n    elif isinstance(query.clause, CreateIndexClause):\n        return self._execute_create_index(query.clause)\n    elif isinstance(query.clause, DropIndexClause):\n        return self._execute_drop_index(query.clause)\n    elif isinstance(query.clause, ShowIndexesClause):\n        return self._execute_show_indexes(query.clause)\n    elif isinstance(query.clause, CreateConstraintClause):\n        return self._execute_create_constraint(query.clause)\n    elif isinstance(query.clause, DropConstraintClause):\n        return self._execute_drop_constraint(query.clause)\n    elif isinstance(query.clause, ShowConstraintsClause):\n        return self._execute_show_constraints(query.clause)\n    elif isinstance(query.clause, ForeachClause):\n        return self._execute_foreach(query.clause, [{}])\n    else:\n        raise CypherExecutionError(f\"Unknown clause type: {type(query.clause)}\")\n</code></pre>"},{"location":"api/cypher/#grafito.cypher.executor.CypherExecutor.restore","title":"<code>restore(file_path, clear_existing=True)</code>","text":"<p>Restore the database from a Cypher script file.</p> <p>The script is fully parsed before any data is modified. If parsing fails, the database remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the .cypher file.</p> required <code>clear_existing</code> <code>bool</code> <p>If True, delete all existing data before restore.</p> <code>True</code> <p>Raises:</p> Type Description <code>CypherSyntaxError</code> <p>If any statement in the script is invalid.</p> Source code in <code>grafito/cypher/executor.py</code> <pre><code>def restore(self, file_path: str, clear_existing: bool = True) -&gt; None:\n    \"\"\"Restore the database from a Cypher script file.\n\n    The script is fully parsed before any data is modified. If parsing\n    fails, the database remains unchanged.\n\n    Args:\n        file_path: Path to the .cypher file.\n        clear_existing: If True, delete all existing data before restore.\n\n    Raises:\n        CypherSyntaxError: If any statement in the script is invalid.\n    \"\"\"\n    from .lexer import Lexer\n    from .parser import Parser\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        script = f.read()\n\n    # Split statements\n    statements = self.db._split_cypher_statements(script)\n\n    # Parse all statements first (validation)\n    parsed = []\n    for stmt in statements:\n        # Remove comment lines from within the statement\n        lines = [line for line in stmt.split('\\n') if not line.strip().startswith('//')]\n        stmt = '\\n'.join(lines).strip()\n        if not stmt:\n            continue\n        lexer = Lexer(stmt)\n        tokens = lexer.tokenize()\n        parser = Parser(tokens)\n        ast = parser.parse()\n        parsed.append(ast)\n\n    # Clear existing data if requested\n    if clear_existing:\n        for rel in self.db.match_relationships():\n            self.db.delete_relationship(rel.id)\n        for node in self.db.match_nodes():\n            self.db.delete_node(node.id)\n        for constraint in self.db.list_constraints():\n            self.db.drop_constraint(constraint[\"name\"], if_exists=True)\n        for idx in self.db.list_indexes():\n            self.db.drop_index(idx[\"name\"])\n\n    # Execute parsed statements\n    for ast in parsed:\n        self.execute(ast)\n</code></pre>"},{"location":"api/database/","title":"Database API","text":"<p>The <code>GrafitoDatabase</code> class is the main entry point for all graph operations.</p>"},{"location":"api/database/#initialization","title":"Initialization","text":"<pre><code>from grafito import GrafitoDatabase\n\n# In-memory database (data lost on close)\ndb = GrafitoDatabase(':memory:')\n\n# Persistent database\ndb = GrafitoDatabase('path/to/database.db')\n\n# With custom settings\ndb = GrafitoDatabase(\n    'graph.db',\n    cypher_max_hops=5,      # Default max hops for variable-length paths\n    default_top_k=20        # Default k for vector search\n)\n</code></pre>"},{"location":"api/database/#in-memory-vs-persistent","title":"In-Memory vs Persistent","text":"<ul> <li>In-memory (<code>:memory:</code>): Fast and ephemeral; data is lost on close. Great for tests and demos.</li> <li>Persistent (file path): Data is stored on disk. Use for production or large datasets.</li> </ul> <p>Tip: For larger datasets, prefer file-backed databases over <code>:memory:</code> to avoid RAM pressure and to benefit from SQLite\u2019s on-disk optimizations.</p>"},{"location":"api/database/#context-manager","title":"Context Manager","text":"<p>Use the database as a context manager for automatic transaction handling:</p> <pre><code>with db:\n    node = db.create_node(labels=['Person'], properties={'name': 'Alice'})\n    # Automatically commits on success\n# Automatically rolls back on exception\n</code></pre>"},{"location":"api/database/#core-operations","title":"Core Operations","text":""},{"location":"api/database/#node-operations","title":"Node Operations","text":"<pre><code># Create a node\nnode = db.create_node(\n    labels=['Person', 'Employee'],\n    properties={'name': 'Alice', 'age': 30}\n)\n\n# Get a node by ID\nnode = db.get_node(node_id)\n\n# Update properties (merges with existing)\ndb.update_node_properties(node_id, {'city': 'NYC'})\n\n# Add/remove labels\ndb.add_labels(node_id, ['Manager'])\ndb.remove_labels(node_id, ['Employee'])\n\n# Delete a node (cascades to relationships)\ndb.delete_node(node_id)\n</code></pre>"},{"location":"api/database/#relationship-operations","title":"Relationship Operations","text":"<pre><code># Create a relationship\nrel = db.create_relationship(\n    source_id=alice.id,\n    target_id=bob.id,\n    rel_type='KNOWS',\n    properties={'since': 2020}\n)\n\n# Get relationship by ID\nrel = db.get_relationship(rel_id)\n\n# Delete relationship\ndb.delete_relationship(rel_id)\n</code></pre>"},{"location":"api/database/#pattern-matching","title":"Pattern Matching","text":"<pre><code># Match nodes by labels\npersons = db.match_nodes(labels=['Person'])\n\n# Match with property filter\nengineers = db.match_nodes(\n    labels=['Employee'],\n    properties={'department': 'Engineering'}\n)\n\n# Match relationships\nrels = db.match_relationships(\n    source_id=alice.id,\n    rel_type='KNOWS'\n)\n</code></pre>"},{"location":"api/database/#neighbors-and-traversal","title":"Neighbors and Traversal","text":"<pre><code># Get neighbors\nneighbors = db.get_neighbors(\n    node_id=alice.id,\n    direction='outgoing',  # 'incoming', 'outgoing', or 'both'\n    rel_type='KNOWS'       # optional filter\n)\n\n# Find shortest path (BFS)\npath = db.find_shortest_path(alice.id, bob.id)\n\n# Find any path with depth limit (DFS)\npath = db.find_path(alice.id, bob.id, max_depth=5)\n</code></pre>"},{"location":"api/database/#cypher-queries","title":"Cypher Queries","text":"<p>Execute Cypher queries directly:</p> <pre><code># Create nodes and relationships\ndb.execute(\"CREATE (n:Person {name: 'Alice', age: 30})\")\n\n# Query with results\nresults = db.execute(\"MATCH (n:Person) RETURN n.name, n.age\")\nfor row in results:\n    print(f\"{row['n.name']}: {row['n.age']}\")\n\n# Pattern matching\nresults = db.execute(\"\"\"\n    MATCH (a:Person)-[:KNOWS]-&gt;(b:Person)\n    WHERE a.name = 'Alice'\n    RETURN b.name\n\"\"\")\n</code></pre>"},{"location":"api/database/#transactions","title":"Transactions","text":""},{"location":"api/database/#automatic-context-manager","title":"Automatic (Context Manager)","text":"<pre><code>with db:\n    node1 = db.create_node(labels=['A'])\n    node2 = db.create_node(labels=['B'])\n    db.create_relationship(node1.id, node2.id, 'LINKS')\n# Commits if no exception, rolls back otherwise\n</code></pre>"},{"location":"api/database/#manual-control","title":"Manual Control","text":"<pre><code>db.begin_transaction()\ntry:\n    # ... operations ...\n    db.commit()\nexcept Exception:\n    db.rollback()\n    raise\n</code></pre>"},{"location":"api/database/#metadata-queries","title":"Metadata Queries","text":"<pre><code># Counts\ntotal_nodes = db.get_node_count()\nperson_count = db.get_node_count(label='Person')\ntotal_rels = db.get_relationship_count()\nknows_count = db.get_relationship_count(rel_type='KNOWS')\n\n# Labels and types\nlabels = db.get_all_labels()\nrel_types = db.get_all_relationship_types()\n\n# Indexes\ndb.create_node_index('Person', 'name')\ndb.create_relationship_index('KNOWS', 'since')\ndb.list_indexes()\ndb.drop_index('idx_node_person_name')\n\n# Constraints (via Cypher)\ndb.execute(\"CREATE CONSTRAINT FOR (n:Person) REQUIRE n.email IS UNIQUE\")\ndb.execute(\"SHOW CONSTRAINTS\")\n</code></pre>"},{"location":"api/database/#vector-search","title":"Vector Search","text":"<pre><code># Create a vector index\ndb.create_vector_index(\n    name='people_vec',\n    dim=384,\n    backend='faiss',\n    method='flat',\n    options={'metric': 'l2'}\n)\n\n# Insert embeddings\ndb.upsert_embedding(\n    node_id=node.id,\n    vector=[0.1, 0.2, ...],  # 384 dimensions\n    index='people_vec'\n)\n\n# Semantic search\nresults = db.semantic_search(\n    query_vector=[0.1, 0.2, ...],\n    k=10,\n    index='people_vec'\n)\n</code></pre>"},{"location":"api/database/#full-text-search","title":"Full-Text Search","text":"<pre><code># Check FTS5 availability\nif db.has_fts5():\n    # Configure text index\n    db.create_text_index('node', 'Person', ['name', 'bio'])\n    db.rebuild_text_index()\n\n    # Search\n    results = db.text_search('engineer', k=10, labels=['Person'])\n</code></pre>"},{"location":"api/database/#importexport","title":"Import/Export","text":"<pre><code># NetworkX\ngraph = db.to_networkx()\ndb.from_networkx(graph)\n\n# Neo4j dump\ndb.import_neo4j_dump('path/to/dump.db')\n</code></pre>"},{"location":"api/database/#dump-and-restore-grafito-cypher","title":"Dump and Restore (Grafito Cypher)","text":"<p>Grafito can dump the entire database to a Cypher script and restore it later. This is not a Neo4j <code>.dump</code> file.</p> <pre><code># Dump to a Cypher script\ndb.dump('grafito_dump.cypher')\n\n# Restore from a Cypher script\ndb.restore('grafito_dump.cypher', clear_existing=True)\n</code></pre> <p>The dump script uses a temporary <code>_dump_id</code> property to link relationships and removes it at the end of the script.</p>"},{"location":"api/database/#cleanup","title":"Cleanup","text":"<pre><code># Close the database (important for persistent databases)\ndb.close()\n</code></pre>"},{"location":"api/nodes/","title":"Nodes API","text":"<p>Nodes are the primary entities in a property graph. This page covers all node-related operations.</p>"},{"location":"api/nodes/#creating-nodes","title":"Creating Nodes","text":""},{"location":"api/nodes/#basic-node-creation","title":"Basic Node Creation","text":"<pre><code>from grafito import GrafitoDatabase\n\ndb = GrafitoDatabase(':memory:')\n\n# Simple node with single label\nalice = db.create_node(\n    labels=['Person'],\n    properties={'name': 'Alice', 'age': 30}\n)\n\nprint(f\"Created node with ID: {alice.id}\")\nprint(f\"Labels: {alice.labels}\")  # ['Person']\nprint(f\"Properties: {alice.properties}\")  # {'name': 'Alice', 'age': 30}\n</code></pre>"},{"location":"api/nodes/#multiple-labels","title":"Multiple Labels","text":"<p>Nodes can have multiple labels, like implementing multiple interfaces:</p> <pre><code># Alice is a Person, an Employee, and a Manager\nalice = db.create_node(\n    labels=['Person', 'Employee', 'Manager'],\n    properties={\n        'name': 'Alice',\n        'age': 30,\n        'department': 'Engineering'\n    }\n)\n</code></pre> <p>Common patterns: - <code>['User', 'Admin']</code> - Role-based permissions - <code>['Product', 'Featured']</code> - Categorization - <code>['Document', 'Published']</code> - Lifecycle states</p>"},{"location":"api/nodes/#property-types","title":"Property Types","text":"<p>Nodes support various property types:</p> <pre><code>node = db.create_node(\n    labels=['Document'],\n    properties={\n        # Basic types\n        'title': 'Annual Report',\n        'year': 2024,\n        'rating': 4.5,\n        'published': True,\n\n        # Collections\n        'tags': ['finance', 'annual', '2024'],\n        'metadata': {\n            'author': 'John Doe',\n            'reviewers': ['Jane', 'Bob']\n        },\n\n        # Null values\n        'archived_at': None\n    }\n)\n</code></pre>"},{"location":"api/nodes/#retrieving-nodes","title":"Retrieving Nodes","text":""},{"location":"api/nodes/#get-by-id","title":"Get by ID","text":"<pre><code>node = db.get_node(alice.id)\n\nif node:\n    print(f\"Found: {node.properties['name']}\")\n    print(f\"Labels: {node.labels}\")\n    print(f\"Created at: {node.created_at}\")\nelse:\n    print(\"Node not found\")\n</code></pre>"},{"location":"api/nodes/#match-nodes","title":"Match Nodes","text":"<pre><code># Match by labels\nall_persons = db.match_nodes(labels=['Person'])\n\n# Match by multiple labels (AND logic)\nmanagers = db.match_nodes(labels=['Employee', 'Manager'])\n\n# Match with property filter\nengineers = db.match_nodes(\n    labels=['Employee'],\n    properties={'department': 'Engineering'}\n)\n\n# Iterate over results\nfor person in all_persons:\n    print(f\"{person.id}: {person.properties.get('name')}\")\n</code></pre>"},{"location":"api/nodes/#updating-nodes","title":"Updating Nodes","text":""},{"location":"api/nodes/#update-properties","title":"Update Properties","text":"<pre><code># Partial update (merges with existing properties)\ndb.update_node_properties(alice.id, {\n    'city': 'New York',\n    'country': 'USA'\n})\n\n# Existing properties are preserved\n# Now alice.properties includes: name, age, city, country\n</code></pre>"},{"location":"api/nodes/#add-labels","title":"Add Labels","text":"<pre><code># Add new labels to existing node\ndb.add_labels(alice.id, ['Senior', 'TeamLead'])\n\n# Labels are idempotent (adding existing label is a no-op)\ndb.add_labels(alice.id, ['Person'])  # Already exists, no error\n</code></pre>"},{"location":"api/nodes/#remove-labels","title":"Remove Labels","text":"<pre><code># Remove specific labels\ndb.remove_labels(alice.id, ['Manager'])\n\n# Node keeps other labels\ndb.remove_labels(alice.id, ['TeamLead', 'Senior'])\n</code></pre>"},{"location":"api/nodes/#deleting-nodes","title":"Deleting Nodes","text":"<pre><code># Delete a node (also deletes all its relationships)\ndb.delete_node(node_id)\n\n# Note: This is a permanent operation\n# Use transactions for safety\nwith db:\n    db.delete_node(node_id)\n</code></pre>"},{"location":"api/nodes/#node-object","title":"Node Object","text":"<p>When you retrieve a node, you get a <code>Node</code> object with these attributes:</p> <pre><code>node = db.get_node(node_id)\n\nnode.id              # Unique identifier (int)\nnode.labels          # List of labels (list[str])\nnode.properties      # Dictionary of properties (dict)\nnode.created_at      # Creation timestamp (datetime)\nnode.uri             # Optional URI identifier (str | None)\n</code></pre>"},{"location":"api/nodes/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"api/nodes/#conditional-updates","title":"Conditional Updates","text":"<pre><code># Get and update in one transaction\nwith db:\n    node = db.get_node(alice.id)\n    if node and 'age' in node.properties:\n        current_age = node.properties['age']\n        db.update_node_properties(alice.id, {'age': current_age + 1})\n</code></pre>"},{"location":"api/nodes/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Create multiple nodes efficiently\nwith db:\n    for i in range(100):\n        db.create_node(\n            labels=['User'],\n            properties={'username': f'user_{i}', 'index': i}\n        )\n</code></pre>"},{"location":"api/nodes/#property-validation","title":"Property Validation","text":"<pre><code>def create_validated_person(db, name, age):\n    if not name or len(name) &lt; 2:\n        raise ValueError(\"Invalid name\")\n    if age &lt; 0 or age &gt; 150:\n        raise ValueError(\"Invalid age\")\n\n    return db.create_node(\n        labels=['Person'],\n        properties={'name': name, 'age': age}\n    )\n</code></pre>"},{"location":"api/nodes/#common-workflows","title":"Common Workflows","text":""},{"location":"api/nodes/#user-management","title":"User Management","text":"<pre><code>def create_user(db, email, name):\n    \"\"\"Create a user with unique email constraint.\"\"\"\n    with db:\n        # Check if email already exists\n        existing = db.execute(\n            \"MATCH (n:User {email: $email}) RETURN n\",\n            {'email': email}\n        )\n        if existing:\n            raise ValueError(\"Email already exists\")\n\n        return db.create_node(\n            labels=['User'],\n            properties={'email': email, 'name': name, 'active': True}\n        )\n\ndef deactivate_user(db, user_id):\n    \"\"\"Soft-delete by marking inactive.\"\"\"\n    db.update_node_properties(user_id, {'active': False})\n</code></pre>"},{"location":"api/nodes/#document-versioning","title":"Document Versioning","text":"<pre><code>def create_document_version(db, doc_id, content, version):\n    \"\"\"Create a new version of a document.\"\"\"\n    return db.create_node(\n        labels=['Document', 'Version'],\n        properties={\n            'doc_id': doc_id,\n            'content': content,\n            'version': version,\n            'created_at': datetime.now().isoformat()\n        }\n    )\n</code></pre>"},{"location":"api/nodes/#best-practices","title":"Best Practices","text":"<ol> <li>Use Multiple Labels: Leverage labels for categorization and querying</li> <li>Keep Properties Flat: Avoid deeply nested structures when possible</li> <li>Use Transactions: Wrap multiple operations for consistency</li> <li>Index Common Properties: Create indexes on frequently queried properties</li> <li>Validate Input: Check property values before creating/updating</li> </ol>"},{"location":"api/nodes/#error-handling","title":"Error Handling","text":"<pre><code>from grafito.exceptions import NodeNotFoundError, ConstraintError\n\ntry:\n    node = db.get_node(9999)  # Non-existent ID\n    if node is None:\n        print(\"Node not found\")\n\n    db.delete_node(9999)  # Will raise or handle gracefully\nexcept NodeNotFoundError:\n    print(\"Node does not exist\")\nexcept ConstraintError as e:\n    print(f\"Constraint violation: {e}\")\n</code></pre>"},{"location":"api/relationships/","title":"Relationships API","text":"<p>Relationships connect nodes and represent how entities relate to each other.</p>"},{"location":"api/relationships/#creating-relationships","title":"Creating Relationships","text":""},{"location":"api/relationships/#basic-relationship","title":"Basic Relationship","text":"<pre><code># Create a directed relationship from Alice to Bob\nknows = db.create_relationship(\n    source_id=alice.id,    # From\n    target_id=bob.id,      # To\n    rel_type='KNOWS'       # Relationship type\n)\n\nprint(f\"Created relationship: {knows.id}\")\nprint(f\"Type: {knows.type}\")  # 'KNOWS'\nprint(f\"From: {knows.source_id} -&gt; To: {knows.target_id}\")\n</code></pre>"},{"location":"api/relationships/#relationship-with-properties","title":"Relationship with Properties","text":"<pre><code># Relationships can have properties just like nodes\nworks_at = db.create_relationship(\n    source_id=alice.id,\n    target_id=company.id,\n    rel_type='WORKS_AT',\n    properties={\n        'since': 2020,\n        'position': 'Senior Engineer',\n        'department': 'Engineering',\n        'salary_band': 'L5'\n    }\n)\n</code></pre>"},{"location":"api/relationships/#common-relationship-types","title":"Common Relationship Types","text":"Type Description Example Properties <code>KNOWS</code> Social connection <code>since</code>, <code>strength</code> <code>WORKS_AT</code> Employment <code>since</code>, <code>position</code>, <code>department</code> <code>MANAGES</code> Management <code>since</code>, <code>level</code> <code>CREATED</code> Authorship <code>date</code>, <code>role</code> <code>BELONGS_TO</code> Categorization <code>priority</code>, <code>weight</code> <code>LOCATED_IN</code> Geography <code>address_type</code>"},{"location":"api/relationships/#retrieving-relationships","title":"Retrieving Relationships","text":""},{"location":"api/relationships/#get-by-id","title":"Get by ID","text":"<pre><code>rel = db.get_relationship(rel_id)\n\nif rel:\n    print(f\"Type: {rel.type}\")\n    print(f\"Properties: {rel.properties}\")\n    print(f\"Created: {rel.created_at}\")\n</code></pre>"},{"location":"api/relationships/#match-relationships","title":"Match Relationships","text":"<pre><code># Find all relationships of a type\nall_knows = db.match_relationships(rel_type='KNOWS')\n\n# Find relationships from a specific node\nfrom_alice = db.match_relationships(source_id=alice.id)\n\n# Find relationships to a specific node\nto_bob = db.match_relationships(target_id=bob.id)\n\n# Combine filters\nalice_to_bob = db.match_relationships(\n    source_id=alice.id,\n    target_id=bob.id,\n    rel_type='KNOWS'\n)\n</code></pre>"},{"location":"api/relationships/#get-neighbors","title":"Get Neighbors","text":"<p>The most common pattern is getting connected nodes:</p> <pre><code># Get all outgoing connections\nfriends = db.get_neighbors(\n    node_id=alice.id,\n    direction='outgoing',\n    rel_type='KNOWS'\n)\n\n# Get all incoming connections (who knows Alice?)\nfollowers = db.get_neighbors(\n    node_id=alice.id,\n    direction='incoming',\n    rel_type='KNOWS'\n)\n\n# Get connections in both directions\nall_connected = db.get_neighbors(\n    node_id=alice.id,\n    direction='both'\n)\n\n# Get all neighbors regardless of relationship type\nall_neighbors = db.get_neighbors(alice.id, direction='outgoing')\n</code></pre>"},{"location":"api/relationships/#deleting-relationships","title":"Deleting Relationships","text":"<pre><code># Delete a specific relationship\ndb.delete_relationship(rel_id)\n\n# Note: Deleting a node automatically deletes all its relationships\n</code></pre>"},{"location":"api/relationships/#relationship-object","title":"Relationship Object","text":"<pre><code>rel = db.get_relationship(rel_id)\n\nrel.id              # Unique identifier (int)\nrel.type            # Relationship type (str)\nrel.source_id       # Source node ID (int)\nrel.target_id       # Target node ID (int)\nrel.properties      # Dictionary of properties (dict)\nrel.created_at      # Creation timestamp (datetime)\nrel.uri             # Optional URI identifier (str | None)\n</code></pre>"},{"location":"api/relationships/#direction-matters","title":"Direction Matters","text":"<p>Relationships are directed. Remember the arrow direction:</p> <pre><code># Alice WORKS_AT Company (correct direction)\ndb.create_relationship(alice.id, company.id, 'WORKS_AT')\n\n# This is different! Company WORKS_AT Alice\ndb.create_relationship(company.id, alice.id, 'WORKS_AT')\n\n# For bidirectional relationships, create two\ndb.create_relationship(alice.id, bob.id, 'KNOWS')\ndb.create_relationship(bob.id, alice.id, 'KNOWS')  # Mutual\n</code></pre>"},{"location":"api/relationships/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"api/relationships/#creating-linked-structures","title":"Creating Linked Structures","text":"<pre><code>def create_reporting_chain(db, manager, employees):\n    \"\"\"Create MANAGES relationships from manager to employees.\"\"\"\n    with db:\n        for emp in employees:\n            db.create_relationship(\n                source_id=manager.id,\n                target_id=emp.id,\n                rel_type='MANAGES',\n                properties={'since': datetime.now().year}\n            )\n</code></pre>"},{"location":"api/relationships/#updating-relationship-properties","title":"Updating Relationship Properties","text":"<p>Currently, relationships are updated via Cypher:</p> <pre><code># Update relationship properties\ndb.execute(\"\"\"\n    MATCH (a:Person {name: 'Alice'})-[r:WORKS_AT]-&gt;(c:Company)\n    SET r.position = 'Staff Engineer'\n\"\"\")\n</code></pre>"},{"location":"api/relationships/#finding-relationship-paths","title":"Finding Relationship Paths","text":"<pre><code># Find all paths between two nodes with specific relationship\nresults = db.execute(\"\"\"\n    MATCH path = (a:Person {name: 'Alice'})-[:KNOWS*1..3]-&gt;(b:Person {name: 'Carol'})\n    RETURN path\n\"\"\")\n</code></pre>"},{"location":"api/relationships/#best-practices","title":"Best Practices","text":"<ol> <li>Use Verbose Type Names: <code>WORKS_AT</code> is clearer than <code>WORKS</code></li> <li>Consider Direction: Always think about the natural direction</li> <li>Keep Properties Lean: Don't duplicate node data in relationships</li> <li>Use Transactions: For consistency when creating node + relationship</li> </ol>"},{"location":"api/relationships/#common-workflows","title":"Common Workflows","text":""},{"location":"api/relationships/#social-network","title":"Social Network","text":"<pre><code>def make_friends(db, person1_id, person2_id):\n    \"\"\"Create bidirectional friendship.\"\"\"\n    with db:\n        timestamp = datetime.now().isoformat()\n\n        db.create_relationship(\n            person1_id, person2_id, 'FRIEND',\n            properties={'since': timestamp, 'strength': 'strong'}\n        )\n        db.create_relationship(\n            person2_id, person1_id, 'FRIEND',\n            properties={'since': timestamp, 'strength': 'strong'}\n        )\n</code></pre>"},{"location":"api/relationships/#content-graph","title":"Content Graph","text":"<pre><code>def link_content(db, article_id, tag_ids):\n    \"\"\"Link an article to multiple tags.\"\"\"\n    with db:\n        for tag_id in tag_ids:\n            db.create_relationship(\n                article_id, tag_id, 'TAGGED_WITH',\n                properties={'auto': False}\n            )\n</code></pre>"},{"location":"api/relationships/#organization-hierarchy","title":"Organization Hierarchy","text":"<pre><code>def create_department_structure(db, dept_data):\n    \"\"\"Create department with manager and employees.\"\"\"\n    with db:\n        dept = db.create_node(\n            labels=['Department'],\n            properties={'name': dept_data['name']}\n        )\n\n        # Link manager\n        db.create_relationship(\n            dept_data['manager_id'], dept.id, 'MANAGES_DEPT'\n        )\n\n        # Link employees\n        for emp_id in dept_data['employee_ids']:\n            db.create_relationship(\n                emp_id, dept.id, 'BELONGS_TO',\n                properties={'type': 'member'}\n            )\n\n        return dept\n</code></pre>"},{"location":"api/relationships/#error-handling","title":"Error Handling","text":"<pre><code>from grafito.exceptions import RelationshipError, NodeNotFoundError\n\ntry:\n    rel = db.create_relationship(\n        source_id=9999,  # Non-existent node\n        target_id=bob.id,\n        rel_type='KNOWS'\n    )\nexcept NodeNotFoundError:\n    print(\"One or both nodes don't exist\")\nexcept RelationshipError as e:\n    print(f\"Relationship error: {e}\")\n</code></pre>"},{"location":"api/transactions/","title":"Transactions","text":"<p>Grafito provides full ACID transaction support through SQLite.</p>"},{"location":"api/transactions/#what-are-transactions","title":"What are Transactions?","text":"<p>A transaction groups multiple operations into a single atomic unit. Either all operations succeed (commit) or none do (rollback).</p> <pre><code>BEGIN TRANSACTION\n  Operation 1 \u2713\n  Operation 2 \u2713\n  Operation 3 \u2717 (fails)\nROLLBACK  \u2190 All undone\n\nBEGIN TRANSACTION\n  Operation 1 \u2713\n  Operation 2 \u2713\n  Operation 3 \u2713\nCOMMIT    \u2190 All persisted\n</code></pre>"},{"location":"api/transactions/#using-context-managers-recommended","title":"Using Context Managers (Recommended)","text":"<p>The simplest and safest way to use transactions:</p> <pre><code>from grafito import GrafitoDatabase\n\ndb = GrafitoDatabase(':memory:')\n\n# Use as context manager\nwith db:\n    alice = db.create_node(labels=['Person'], properties={'name': 'Alice'})\n    bob = db.create_node(labels=['Person'], properties={'name': 'Bob'})\n    db.create_relationship(alice.id, bob.id, 'KNOWS')\n\n# Automatically commits if no exception\n# Automatically rolls back if any exception occurs\n</code></pre>"},{"location":"api/transactions/#automatic-rollback-example","title":"Automatic Rollback Example","text":"<pre><code>def create_user_with_validation(db, username, email):\n    with db:\n        # Step 1: Create user node\n        user = db.create_node(\n            labels=['User'],\n            properties={'username': username, 'email': email}\n        )\n\n        # Step 2: This will fail (invalid email)\n        if '@' not in email:\n            raise ValueError(\"Invalid email\")\n\n        # Step 3: Create profile node\n        profile = db.create_node(\n            labels=['Profile'],\n            properties={'user_id': user.id}\n        )\n\n        db.create_relationship(user.id, profile.id, 'HAS_PROFILE')\n\n    # If email is invalid:\n    # - user node is NOT created\n    # - profile node is NOT created\n    # - relationship is NOT created\n</code></pre>"},{"location":"api/transactions/#manual-transaction-control","title":"Manual Transaction Control","text":"<p>For more control, use explicit methods:</p> <pre><code>db.begin_transaction()\n\ntry:\n    # Perform operations\n    node1 = db.create_node(labels=['A'])\n    node2 = db.create_node(labels=['B'])\n    db.create_relationship(node1.id, node2.id, 'LINKS')\n\n    # Verify before committing\n    if is_valid_structure(node1, node2):\n        db.commit()\n        print(\"Transaction committed\")\n    else:\n        db.rollback()\n        print(\"Transaction rolled back (validation failed)\")\n\nexcept Exception as e:\n    db.rollback()\n    print(f\"Transaction rolled back (error: {e})\")\n    raise\n</code></pre>"},{"location":"api/transactions/#nested-operations","title":"Nested Operations","text":"<p>Transactions can span multiple method calls:</p> <pre><code>def create_organization(db, org_data):\n    \"\"\"Create org structure in one transaction.\"\"\"\n    with db:\n        # Create organization\n        org = db.create_node(\n            labels=['Organization'],\n            properties={'name': org_data['name']}\n        )\n\n        # Create departments\n        for dept_data in org_data['departments']:\n            create_department(db, org.id, dept_data)\n\n        return org\n\ndef create_department(db, org_id, dept_data):\n    \"\"\"Helper function - runs in parent's transaction.\"\"\"\n    dept = db.create_node(\n        labels=['Department'],\n        properties={'name': dept_data['name']}\n    )\n    db.create_relationship(org_id, dept.id, 'HAS_DEPARTMENT')\n\n    # Add employees\n    for emp in dept_data['employees']:\n        employee = db.create_node(\n            labels=['Employee'],\n            properties=emp\n        )\n        db.create_relationship(employee.id, dept.id, 'WORKS_IN')\n\n# Usage - all or nothing:\nwith db:\n    create_organization(db, {\n        'name': 'TechCorp',\n        'departments': [\n            {\n                'name': 'Engineering',\n                'employees': [\n                    {'name': 'Alice', 'role': 'Developer'},\n                    {'name': 'Bob', 'role': 'Designer'}\n                ]\n            }\n        ]\n    })\n</code></pre>"},{"location":"api/transactions/#savepoints-nested-transactions","title":"Savepoints (Nested Transactions)","text":"<p>SQLite supports savepoints for partial rollback:</p> <pre><code>with db:\n    # Main transaction\n    user = db.create_node(labels=['User'], properties={'name': 'Alice'})\n\n    try:\n        # This could fail independently\n        with db:\n            profile = db.create_node(labels=['Profile'])\n            db.create_relationship(user.id, profile.id, 'HAS_PROFILE')\n    except Exception:\n        # Profile creation failed, but user is kept\n        pass\n\n    # This always runs if user was created\n    settings = db.create_node(labels=['Settings'])\n    db.create_relationship(user.id, settings.id, 'HAS_SETTINGS')\n</code></pre>"},{"location":"api/transactions/#best-practices","title":"Best Practices","text":""},{"location":"api/transactions/#1-keep-transactions-short","title":"1. Keep Transactions Short","text":"<pre><code># Good: Short, focused transaction\nwith db:\n    user = db.create_node(labels=['User'], properties=data)\n    db.create_relationship(user.id, org.id, 'MEMBER_OF')\n\n# Process outside transaction (no DB locks)\nsend_welcome_email(user.properties['email'])\n</code></pre>"},{"location":"api/transactions/#2-handle-errors-gracefully","title":"2. Handle Errors Gracefully","text":"<pre><code>def safe_create_user(db, user_data):\n    try:\n        with db:\n            # Check for existing user\n            existing = db.match_nodes(\n                labels=['User'],\n                properties={'email': user_data['email']}\n            )\n            if existing:\n                raise ValueError(\"User already exists\")\n\n            return db.create_node(labels=['User'], properties=user_data)\n\n    except ValueError as e:\n        # Expected error - user exists\n        logger.info(f\"User creation skipped: {e}\")\n        return None\n    except Exception as e:\n        # Unexpected error\n        logger.error(f\"Database error: {e}\")\n        raise\n</code></pre>"},{"location":"api/transactions/#3-validate-before-transaction","title":"3. Validate Before Transaction","text":"<pre><code>def create_product_with_validation(db, product_data):\n    # Validation outside transaction (no locks)\n    if not product_data.get('name'):\n        raise ValueError(\"Product name required\")\n    if product_data.get('price', 0) &lt;= 0:\n        raise ValueError(\"Invalid price\")\n\n    # Now do the transaction\n    with db:\n        product = db.create_node(\n            labels=['Product'],\n            properties=product_data\n        )\n\n        # Create inventory record\n        inventory = db.create_node(\n            labels=['Inventory'],\n            properties={'product_id': product.id, 'quantity': 0}\n        )\n        db.create_relationship(product.id, inventory.id, 'HAS_INVENTORY')\n\n        return product\n</code></pre>"},{"location":"api/transactions/#4-read-only-operations","title":"4. Read-Only Operations","text":"<p>Read operations don't need explicit transactions (SQLite handles consistency):</p> <pre><code># No transaction needed for reads\nuser = db.get_node(user_id)\nusers = db.match_nodes(labels=['User'])\n\n# Transaction needed for writes\nwith db:\n    db.update_node_properties(user_id, {'last_seen': now()})\n</code></pre>"},{"location":"api/transactions/#common-patterns","title":"Common Patterns","text":""},{"location":"api/transactions/#bulk-insert","title":"Bulk Insert","text":"<pre><code>def bulk_create_nodes(db, items):\n    \"\"\"Efficiently create many nodes.\"\"\"\n    with db:\n        created = []\n        for item in items:\n            node = db.create_node(\n                labels=item['labels'],\n                properties=item['properties']\n            )\n            created.append(node)\n        return created\n</code></pre>"},{"location":"api/transactions/#cascade-delete","title":"Cascade Delete","text":"<pre><code>def delete_user_with_data(db, user_id):\n    \"\"\"Delete user and all related data.\"\"\"\n    with db:\n        # Find related nodes (assuming specific structure)\n        results = db.execute(\"\"\"\n            MATCH (u:User {id: $user_id})-[:HAS_PROFILE|HAS_SETTINGS]-&gt;(related)\n            RETURN related.id as related_id\n        \"\"\", {'user_id': user_id})\n\n        # Delete related nodes first\n        for row in results:\n            db.delete_node(row['related_id'])\n\n        # Delete user (cascades relationships)\n        db.delete_node(user_id)\n</code></pre>"},{"location":"api/transactions/#conditional-updates","title":"Conditional Updates","text":"<pre><code>def transfer_funds(db, from_id, to_id, amount):\n    \"\"\"Transfer between accounts atomically.\"\"\"\n    with db:\n        from_acc = db.get_node(from_id)\n        to_acc = db.get_node(to_id)\n\n        if not from_acc or not to_acc:\n            raise ValueError(\"Account not found\")\n\n        current_balance = from_acc.properties.get('balance', 0)\n        if current_balance &lt; amount:\n            raise ValueError(\"Insufficient funds\")\n\n        # Update both accounts atomically\n        db.update_node_properties(\n            from_id,\n            {'balance': current_balance - amount}\n        )\n        db.update_node_properties(\n            to_id,\n            {'balance': to_acc.properties.get('balance', 0) + amount}\n        )\n</code></pre>"},{"location":"api/transactions/#error-types","title":"Error Types","text":"Exception When Raised <code>TransactionError</code> Invalid transaction state <code>Rollback</code> Explicit rollback requested <code>ConstraintError</code> Unique constraint violation <code>NodeNotFoundError</code> Referenced node doesn't exist"},{"location":"api/traversal/","title":"Graph Traversal","text":"<p>Graph traversal means navigating through the graph by following relationships.</p>"},{"location":"api/traversal/#neighbors","title":"Neighbors","text":"<p>Get directly connected nodes.</p>"},{"location":"api/traversal/#basic-neighbors","title":"Basic Neighbors","text":"<pre><code># Get all outgoing neighbors\nfriends = db.get_neighbors(alice.id, direction='outgoing')\n\n# Get all incoming neighbors (who points to Alice)\nfollowers = db.get_neighbors(alice.id, direction='incoming')\n\n# Get neighbors in both directions\nall_neighbors = db.get_neighbors(alice.id, direction='both')\n</code></pre>"},{"location":"api/traversal/#filtered-by-relationship-type","title":"Filtered by Relationship Type","text":"<pre><code># Only coworkers\ncoworkers = db.get_neighbors(\n    alice.id,\n    direction='outgoing',\n    rel_type='WORKS_WITH'\n)\n\n# Only direct reports\nreports = db.get_neighbors(\n    manager.id,\n    direction='outgoing',\n    rel_type='MANAGES'\n)\n\n# Only managers (incoming)\nmanagers = db.get_neighbors(\n    employee.id,\n    direction='incoming',\n    rel_type='MANAGES'\n)\n</code></pre>"},{"location":"api/traversal/#path-finding","title":"Path Finding","text":"<p>Find routes between nodes.</p>"},{"location":"api/traversal/#shortest-path-bfs","title":"Shortest Path (BFS)","text":"<p>Breadth-first search finds the shortest path in terms of number of hops:</p> <pre><code># Find shortest path\npath = db.find_shortest_path(alice.id, bob.id)\n\nif path:\n    print(f\"Path length: {len(path)} nodes\")\n    for node in path:\n        print(f\"  -&gt; {node.properties['name']}\")\nelse:\n    print(\"No path found\")\n\n# Example output:\n# Path length: 3 nodes\n#   -&gt; Alice\n#   -&gt; Charlie\n#   -&gt; Bob\n</code></pre>"},{"location":"api/traversal/#any-path-dfs","title":"Any Path (DFS)","text":"<p>Depth-first search finds any path with optional depth limit:</p> <pre><code># Find any path with max depth\npath = db.find_path(alice.id, bob.id, max_depth=5)\n\nif path:\n    names = [n.properties['name'] for n in path]\n    print(f\"Path: {' -&gt; '.join(names)}\")\n</code></pre>"},{"location":"api/traversal/#path-with-cypher","title":"Path with Cypher","text":"<p>More complex path queries using Cypher:</p> <pre><code># Shortest path with specific relationship type\nresults = db.execute(\"\"\"\n    MATCH p = shortestPath(\n        (a:Person {name: 'Alice'})-[:KNOWS*1..5]-&gt;(b:Person {name: 'Bob'})\n    )\n    RETURN p, length(p) as hops\n\"\"\")\n\n# All shortest paths\nresults = db.execute(\"\"\"\n    MATCH p = allShortestPaths(\n        (a:Person {name: 'Alice'})-[:KNOWS*1..5]-&gt;(b:Person {name: 'Bob'})\n    )\n    RETURN p\n\"\"\")\n</code></pre>"},{"location":"api/traversal/#variable-length-patterns","title":"Variable-Length Patterns","text":"<p>Match patterns with variable path lengths.</p>"},{"location":"api/traversal/#basic-variable-length","title":"Basic Variable Length","text":"<pre><code># Friends of friends (2 hops)\nfof = db.execute(\"\"\"\n    MATCH (a:Person {name: 'Alice'})-[:KNOWS*2]-&gt;(fof:Person)\n    WHERE fof &lt;&gt; a\n    RETURN DISTINCT fof.name\n\"\"\")\n\n# 1 to 3 hops\nnetwork = db.execute(\"\"\"\n    MATCH (a:Person {name: 'Alice'})-[:KNOWS*1..3]-&gt;(other:Person)\n    WHERE other &lt;&gt; a\n    RETURN other.name, length(p) as distance\n\"\"\")\n</code></pre>"},{"location":"api/traversal/#unbounded-paths","title":"Unbounded Paths","text":"<p>Use with caution - always configure a maximum:</p> <pre><code># Configure max hops when creating database\ndb = GrafitoDatabase(':memory:', cypher_max_hops=5)\n\n# This uses the configured max\ndb.execute(\"MATCH (a)-[:KNOWS*..]-&gt;(b) RETURN b\")\n</code></pre>"},{"location":"api/traversal/#traversal-strategies","title":"Traversal Strategies","text":""},{"location":"api/traversal/#top-down-hierarchy","title":"Top-Down Hierarchy","text":"<pre><code>def get_all_reports(db, manager_id, max_depth=5):\n    \"\"\"Get all employees in reporting chain.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (mgr:Person {id: $manager_id})&lt;-[:REPORTS_TO*1..$max_depth]-(emp:Person)\n        RETURN emp, length(p) as level\n    \"\"\", {'manager_id': manager_id, 'max_depth': max_depth})\n\n    return [(row['emp'], row['level']) for row in results]\n</code></pre>"},{"location":"api/traversal/#bottom-up-ancestry","title":"Bottom-Up Ancestry","text":"<pre><code>def get_management_chain(db, employee_id):\n    \"\"\"Get chain of command up to CEO.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (emp:Person {id: $employee_id})-[:REPORTS_TO*]-&gt;(manager:Person)\n        RETURN manager.name\n    \"\"\", {'employee_id': employee_id})\n\n    return [row['manager.name'] for row in results]\n</code></pre>"},{"location":"api/traversal/#circular-detection","title":"Circular Detection","text":"<pre><code>def has_circular_reference(db, node_id, rel_type):\n    \"\"\"Check if node participates in a cycle.\"\"\"\n    try:\n        results = db.execute(\"\"\"\n            MATCH (n {id: $node_id})-[:$rel_type*]-&gt;(n)\n            RETURN count(*) as cycles\n        \"\"\", {'node_id': node_id, 'rel_type': rel_type})\n        return results[0]['cycles'] &gt; 0\n    except:\n        return False\n</code></pre>"},{"location":"api/traversal/#common-algorithms","title":"Common Algorithms","text":""},{"location":"api/traversal/#degree-centrality","title":"Degree Centrality","text":"<pre><code>def get_most_connected(db, label='Person', limit=10):\n    \"\"\"Find nodes with most connections.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (n:$label)-[r]-()\n        RETURN n.name, count(r) as degree\n        ORDER BY degree DESC\n        LIMIT $limit\n    \"\"\", {'label': label, 'limit': limit})\n\n    return results\n</code></pre>"},{"location":"api/traversal/#common-neighbors","title":"Common Neighbors","text":"<pre><code>def common_neighbors(db, node1_id, node2_id):\n    \"\"\"Find nodes connected to both.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (n1 {id: $id1})--&gt;(common)&lt;--(n2 {id: $id2})\n        RETURN DISTINCT common\n    \"\"\", {'id1': node1_id, 'id2': node2_id})\n\n    return [row['common'] for row in results]\n</code></pre>"},{"location":"api/traversal/#graph-diameter","title":"Graph Diameter","text":"<pre><code>def estimate_diameter(db):\n    \"\"\"Estimate longest shortest path in graph.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (a:Person), (b:Person)\n        WHERE a &lt;&gt; b\n        MATCH p = shortestPath((a)-[:KNOWS*]-&gt;(b))\n        RETURN max(length(p)) as diameter\n    \"\"\")\n\n    return results[0]['diameter'] if results else 0\n</code></pre>"},{"location":"api/traversal/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/traversal/#1-limit-path-length","title":"1. Limit Path Length","text":"<pre><code># Good: Bounded search\nresults = db.execute(\"MATCH (a)-[:KNOWS*1..3]-&gt;(b) RETURN b\")\n\n# Risky: Unbounded\nresults = db.execute(\"MATCH (a)-[:KNOWS*..]-&gt;(b) RETURN b\")  # Uses default max\n</code></pre>"},{"location":"api/traversal/#2-use-indexes","title":"2. Use Indexes","text":"<pre><code># Create index for faster lookups\ndb.create_node_index('Person', 'name')\n\n# Query uses index\nresults = db.execute(\"MATCH (n:Person {name: 'Alice'})-[:KNOWS]-&gt;(b) RETURN b\")\n</code></pre>"},{"location":"api/traversal/#3-filter-early","title":"3. Filter Early","text":"<pre><code># Good: Filter before expanding\nresults = db.execute(\"\"\"\n    MATCH (n:Person {active: true})-[:KNOWS]-&gt;(b)\n    WHERE n.created_at &gt; $date\n    RETURN b\n\"\"\")\n\n# Less efficient: Expand then filter\nresults = db.execute(\"\"\"\n    MATCH (n)-[:KNOWS]-&gt;(b)\n    WHERE n:Person AND n.active = true AND n.created_at &gt; $date\n    RETURN b\n\"\"\")\n</code></pre>"},{"location":"api/traversal/#examples","title":"Examples","text":""},{"location":"api/traversal/#recommendation-engine","title":"Recommendation Engine","text":"<pre><code>def recommend_friends(db, user_id):\n    \"\"\"Friend of friends who aren't already friends.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (me:Person {id: $user_id})-[:KNOWS]-&gt;(friend)-[:KNOWS]-&gt;(fof)\n        WHERE fof &lt;&gt; me\n          AND NOT (me)-[:KNOWS]-&gt;(fof)\n        RETURN fof.name, count(friend) as mutual_friends\n        ORDER BY mutual_friends DESC\n        LIMIT 10\n    \"\"\", {'user_id': user_id})\n\n    return results\n</code></pre>"},{"location":"api/traversal/#supply-chain","title":"Supply Chain","text":"<pre><code>def get_suppliers(db, product_id, tier=2):\n    \"\"\"Get n-tier suppliers.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (p:Product {id: $product_id})-[:REQUIRES*1..$tier]-&gt;(s:Supplier)\n        RETURN DISTINCT s, min(length(p)) as tier\n    \"\"\", {'product_id': product_id, 'tier': tier})\n\n    return results\n</code></pre>"},{"location":"api/traversal/#content-navigation","title":"Content Navigation","text":"<pre><code>def related_content(db, article_id):\n    \"\"\"Find content through multiple relationship types.\"\"\"\n    results = db.execute(\"\"\"\n        MATCH (a:Article {id: $id})-[:TAGGED]-&gt;(tag)&lt;-[:TAGGED]-(related:Article)\n        WHERE related &lt;&gt; a\n        RETURN related, count(tag) as shared_tags\n        ORDER BY shared_tags DESC\n        LIMIT 5\n    \"\"\", {'id': article_id})\n\n    return results\n</code></pre>"},{"location":"apoc/collections/","title":"APOC: Collections, Maps, Text, Utilities","text":"<p>Grafito implements a small, useful subset of APOC functions for text, maps, and collections. These functions can be used in any Cypher query.</p>"},{"location":"apoc/collections/#text","title":"Text","text":""},{"location":"apoc/collections/#apoctextjoin","title":"apoc.text.join","text":"<pre><code>RETURN apoc.text.join(['a', 'b', 'c'], '-') AS value\n</code></pre> <ul> <li>Expects a list and a delimiter string.</li> <li>Returns <code>null</code> if any item in the list is <code>null</code>.</li> </ul>"},{"location":"apoc/collections/#apoctextsplit","title":"apoc.text.split","text":"<pre><code>RETURN apoc.text.split('a,b,c', ',') AS parts\n</code></pre> <ul> <li>Uses regex splitting.</li> </ul>"},{"location":"apoc/collections/#apoctextreplace","title":"apoc.text.replace","text":"<pre><code>RETURN apoc.text.replace('a-b-c', '-', '_') AS value\n</code></pre> <ul> <li>Uses regex replacement.</li> </ul>"},{"location":"apoc/collections/#maps","title":"Maps","text":""},{"location":"apoc/collections/#apocmapmerge","title":"apoc.map.merge","text":"<pre><code>RETURN apoc.map.merge({a: 1}, {b: 2}) AS merged\n</code></pre>"},{"location":"apoc/collections/#apocmapclean","title":"apoc.map.clean","text":"<pre><code>RETURN apoc.map.clean({a: 1, b: null, c: 'x'}, ['a'], [null]) AS cleaned\n</code></pre> <ul> <li>Removes keys in <code>remove_keys</code> and values in <code>remove_values</code>.</li> </ul>"},{"location":"apoc/collections/#apocmapfrompairs","title":"apoc.map.fromPairs","text":"<pre><code>RETURN apoc.map.fromPairs([['a', 1], ['b', 2]]) AS mapped\n</code></pre>"},{"location":"apoc/collections/#apocmapremovekey","title":"apoc.map.removeKey","text":"<pre><code>RETURN apoc.map.removeKey({a: 1, b: 2}, 'a') AS updated\n</code></pre>"},{"location":"apoc/collections/#apocmapget","title":"apoc.map.get","text":"<pre><code>RETURN apoc.map.get({a: 1}, 'b', 0) AS value\n</code></pre>"},{"location":"apoc/collections/#convert","title":"Convert","text":""},{"location":"apoc/collections/#apocconverttomap","title":"apoc.convert.toMap","text":"<pre><code>RETURN apoc.convert.toMap([['a', 1], ['b', 2]]) AS mapped\n</code></pre> <ul> <li>Accepts a map, list of pairs, or a node/relationship (uses its properties).</li> </ul>"},{"location":"apoc/collections/#collections","title":"Collections","text":""},{"location":"apoc/collections/#apoccollcontains","title":"apoc.coll.contains","text":"<pre><code>RETURN apoc.coll.contains([1, 2, 3], 2) AS value\n</code></pre> <ul> <li>Returns <code>null</code> if any element in the list is <code>null</code> and the target is not found.</li> </ul>"},{"location":"apoc/collections/#apoccolltoset","title":"apoc.coll.toSet","text":"<pre><code>RETURN apoc.coll.toSet([1, 2, 2, 3]) AS value\n</code></pre> <ul> <li>Returns unique values, preserving the original order.</li> </ul>"},{"location":"apoc/collections/#utilities","title":"Utilities","text":""},{"location":"apoc/collections/#apocutilcompress","title":"apoc.util.compress","text":"<pre><code>RETURN apoc.util.compress('hello', {compression: 'GZIP'}) AS bytes\n</code></pre> <p>Supported compressions: <code>DEFLATE</code>, <code>GZIP</code>, <code>BZ2</code>, <code>XZ</code>.</p>"},{"location":"apoc/import-export/","title":"APOC: Import / Export","text":"<p>Grafito currently supports JSON-based import via APOC-style procedures. Export procedures are not implemented yet.</p>"},{"location":"apoc/import-export/#import","title":"Import","text":"<p>See APOC: JSON / JSONL for the full <code>apoc.import.json</code> reference.</p>"},{"location":"apoc/import-export/#export","title":"Export","text":"<p>Export procedures are planned but not available in the current release.</p>"},{"location":"apoc/json/","title":"APOC: JSON / JSONL","text":"<p>Grafito provides JSON loading and import procedures inspired by APOC.</p>"},{"location":"apoc/json/#apocloadjson","title":"apoc.load.json","text":"<p>Load a JSON object or array from a file or URL.</p> <p>Signature</p> <pre><code>CALL apoc.load.json(source) YIELD value\n</code></pre> <p>Arguments</p> <ul> <li><code>source</code> (string): file path, <code>file://</code> URL, or HTTP(S) URL.</li> <li>You can also read from tar archives by using <code>path!member.json</code>.</li> </ul> <p>Return</p> <ul> <li>If the JSON is an object, returns a single row with <code>value</code> = object.</li> <li>If the JSON is an array, returns one row per element.</li> </ul> <p>Example</p> <pre><code>CALL apoc.load.json('data/users.json') YIELD value\nRETURN value.name, value.email\n</code></pre>"},{"location":"apoc/json/#apocloadjsonarray","title":"apoc.load.jsonArray","text":"<p>Ensure the JSON payload is an array.</p> <p>Signature</p> <pre><code>CALL apoc.load.jsonArray(source) YIELD value\n</code></pre> <p>If the payload is not an array, the procedure raises an error.</p>"},{"location":"apoc/json/#apocloadjsonparams","title":"apoc.load.jsonParams","text":"<p>Load JSON with query params, headers, and request options.</p> <p>Signature</p> <pre><code>CALL apoc.load.jsonParams(source, params, headers [, options]) YIELD value\n</code></pre> <p>Arguments</p> <ul> <li><code>source</code> (string): file path or HTTP(S) URL.</li> <li><code>params</code> (map): query parameters to append to the URL.</li> <li><code>headers</code> (map): HTTP headers.</li> <li><code>options</code> (map, optional):</li> <li><code>method</code> (string, default <code>GET</code>)</li> <li><code>payload</code> (string | bytes | map | list)</li> <li><code>timeout</code> (number)</li> <li><code>retry</code> (integer)</li> <li><code>failOnError</code> (boolean, default <code>true</code>)</li> <li><code>headers</code> (map) additional headers</li> <li><code>auth</code> (string or <code>{user, password}</code> map)</li> </ul> <p>Example</p> <pre><code>CALL apoc.load.jsonParams(\n  'https://api.example.com/users',\n  {limit: 10},\n  {Accept: 'application/json'},\n  {timeout: 5, retry: 2}\n) YIELD value\nRETURN value\n</code></pre>"},{"location":"apoc/json/#caching-http-get-only","title":"Caching (HTTP GET only)","text":"<p>If <code>GRAFITO_APOC_CACHE_DIR</code> is set and the request is a simple GET (no payload, headers, or auth), Grafito caches the response body on disk and reuses it.</p> <pre><code>export GRAFITO_APOC_CACHE_DIR=\"/tmp/grafito-apoc-cache\"\n</code></pre>"},{"location":"apoc/json/#apocimportjson","title":"apoc.import.json","text":"<p>Import nodes and relationships from JSON or JSONL.</p> <p>Signature</p> <pre><code>CALL apoc.import.json(source [, options]) YIELD nodes, relationships\n</code></pre> <p>Arguments</p> <ul> <li><code>source</code> (string | bytes): file path, URL, or raw bytes.</li> <li><code>options</code> (map, optional):</li> <li><code>compression</code>: <code>DEFLATE</code>, <code>GZIP</code>, <code>BZ2</code>, <code>XZ</code>, <code>ZIP</code></li> <li><code>path</code>: zip entry name (when <code>compression = \"ZIP\"</code>)</li> <li><code>idField</code> (default <code>id</code>)</li> <li><code>labelsField</code> (default <code>labels</code>)</li> <li><code>propertiesField</code> (default <code>properties</code>)</li> <li><code>relTypeField</code> (default <code>label</code>)</li> <li><code>startField</code> (default <code>start</code>)</li> <li><code>endField</code> (default <code>end</code>)</li> <li><code>typeField</code> (default <code>type</code>)</li> </ul> <p>Input Formats</p> <p>Grafito accepts:</p> <p>1) JSON array of entries 2) JSON object with <code>{nodes: [...], relationships: [...]}</code> 3) JSONL (one JSON object per line)</p> <p>Entries are treated as nodes unless one of the following is true:</p> <ul> <li><code>typeField</code> is set to <code>relationship</code> / <code>rel</code> / <code>edge</code></li> <li><code>startField</code> or <code>endField</code> is present</li> </ul> <p>Node entry example</p> <pre><code>{\"id\": \"u1\", \"labels\": [\"User\"], \"properties\": {\"name\": \"Ada\"}}\n</code></pre> <p>Relationship entry example</p> <pre><code>{\"type\": \"relationship\", \"label\": \"FOLLOWS\", \"start\": \"u1\", \"end\": \"u2\"}\n</code></pre> <p>Example import</p> <pre><code>CALL apoc.import.json('data/graph.json') YIELD nodes, relationships\nRETURN nodes, relationships\n</code></pre>"},{"location":"apoc/json/#notes","title":"Notes","text":"<ul> <li>Relationship references must point to existing node IDs in the same import.</li> <li>Invalid JSON raises an error; JSONL is parsed line by line.</li> </ul>"},{"location":"apoc/xml-html/","title":"APOC: XML / HTML","text":"<p>Grafito provides a subset of APOC loading procedures for XML and HTML. They accept local file paths or HTTP(S) URLs and return rows with a <code>value</code> field.</p>"},{"location":"apoc/xml-html/#apocloadxml","title":"apoc.load.xml","text":"<p>Load XML from a file or URL and extract matching elements via XPath.</p> <p>Signature</p> <pre><code>CALL apoc.load.xml(source, xpath [, options]) YIELD value\n</code></pre> <p>Arguments</p> <ul> <li><code>source</code> (string): file path, <code>file://</code> URL, or HTTP(S) URL.</li> <li><code>xpath</code> (string): XPath for matching elements.</li> <li><code>options</code> (map, optional):</li> <li><code>compression</code>: <code>gzip</code>, <code>bz2</code>, <code>xz</code>, <code>zip</code> (or <code>gz</code>, <code>bzip2</code>, <code>lzma</code>).</li> <li><code>path</code> / <code>fileName</code>: name of the XML file inside a ZIP archive.</li> <li>For HTTP(S) sources, you can also pass: <code>method</code>, <code>payload</code>, <code>timeout</code>,     <code>retry</code>, <code>failOnError</code>, <code>headers</code>, <code>auth</code> (same as <code>apoc.load.xmlParams</code>).</li> </ul> <p>Return</p> <p>Each row contains a map derived from the XML element. The map includes:</p> <ul> <li><code>_tag</code>: element name</li> <li><code>_attributes</code>: attributes map (if present)</li> <li><code>_text</code>: trimmed text content (if present)</li> <li>Nested children using their tag names; repeated tags become lists.</li> </ul> <p>Example</p> <pre><code>CALL apoc.load.xml('data/books.xml', '/catalog/book') YIELD value\nRETURN value._attributes.id AS id, value.title._text AS title\n</code></pre>"},{"location":"apoc/xml-html/#apocloadxmlparams","title":"apoc.load.xmlParams","text":"<p>Load XML with query params, headers, and request options.</p> <p>Signature</p> <pre><code>CALL apoc.load.xmlParams(source, xpath, params, headers [, options]) YIELD value\n</code></pre> <p>Arguments</p> <ul> <li><code>source</code> (string): file path or HTTP(S) URL.</li> <li><code>xpath</code> (string): XPath for matching elements.</li> <li><code>params</code> (map): query parameters to append to the URL.</li> <li><code>headers</code> (map): HTTP headers.</li> <li><code>options</code> (map, optional):</li> <li><code>method</code> (string, default <code>GET</code>)</li> <li><code>payload</code> (string | bytes | map | list)</li> <li><code>timeout</code> (number)</li> <li><code>retry</code> (integer)</li> <li><code>failOnError</code> (boolean, default <code>true</code>)</li> <li><code>headers</code> (map) additional headers</li> <li><code>auth</code> (string or <code>{user, password}</code> map)</li> <li><code>compression</code>, <code>path</code> / <code>fileName</code> (for compressed/ZIP sources)</li> </ul> <p>Example</p> <pre><code>CALL apoc.load.xmlParams(\n  'https://example.com/feed.xml',\n  '/feed/entry',\n  {limit: 10},\n  {Accept: 'application/xml'},\n  {timeout: 5}\n) YIELD value\nRETURN value.title._text AS title\n</code></pre>"},{"location":"apoc/xml-html/#apocloadhtml","title":"apoc.load.html","text":"<p>Load HTML and extract text content with a minimal selector engine.</p> <p>Signature</p> <pre><code>CALL apoc.load.html(source, selectors) YIELD value\n</code></pre> <p>Arguments</p> <ul> <li><code>source</code> (string): file path or HTTP(S) URL.</li> <li><code>selectors</code> (map): <code>alias -&gt; selector</code> pairs.</li> </ul> <p>Selector syntax</p> <p>Grafito implements a minimal descendant selector:</p> <ul> <li>Tag + optional classes: <code>div.card</code>, <code>a.link</code></li> <li>Descendant chains: <code>div.card h2</code></li> <li>Optional <code>:eq(n)</code> filter per segment: <code>li:eq(0)</code></li> </ul> <p>Return</p> <p><code>value</code> is a map where each key is the selector alias and each value is a list of <code>{text: ...}</code> entries for matched nodes.</p> <p>Example</p> <pre><code>CALL apoc.load.html(\n  'https://example.com',\n  {titles: 'article h2', links: 'article a.link'}\n) YIELD value\nRETURN value.titles\n</code></pre>"},{"location":"apoc/xml-html/#notes","title":"Notes","text":"<ul> <li>XML supports automatic compression detection by file extension (<code>.gz</code>, <code>.bz2</code>,   <code>.xz</code>, <code>.zip</code>).</li> <li>For ZIP XML, use <code>options.path</code> or <code>options.fileName</code> to pick the entry.</li> <li>HTML extraction returns text only (no attributes).</li> </ul>"},{"location":"cypher/collections/","title":"Lists and Maps","text":"<p>Working with collections in Cypher.</p>"},{"location":"cypher/collections/#lists","title":"Lists","text":""},{"location":"cypher/collections/#creating-lists","title":"Creating Lists","text":"<pre><code>// Literal list\nRETURN [1, 2, 3] as numbers\n\n// Mixed types\nRETURN ['Alice', 30, true] as mixed\n\n// Nested lists\nRETURN [[1, 2], [3, 4]] as matrix\n</code></pre>"},{"location":"cypher/collections/#list-operations","title":"List Operations","text":"<pre><code>// Concatenation\nWITH [1, 2] as a, [3, 4] as b\nRETURN a + b as combined  // [1, 2, 3, 4]\n\n// Index access (0-based)\nWITH ['Alice', 'Bob', 'Charlie'] as names\nRETURN names[0] as first, names[1] as second\n\n// Negative indexing (from end)\nWITH [1, 2, 3, 4, 5] as nums\nRETURN nums[-1] as last  // 5\n</code></pre>"},{"location":"cypher/collections/#list-slicing","title":"List Slicing","text":"<pre><code>WITH [1, 2, 3, 4, 5] as nums\nRETURN nums[1..3]  // [2, 3] (exclusive end)\nRETURN nums[2..]   // [3, 4, 5] (to end)\nRETURN nums[..3]   // [1, 2, 3] (from start)\n</code></pre>"},{"location":"cypher/collections/#list-functions","title":"List Functions","text":"<pre><code>// Size\nRETURN size([1, 2, 3])  // 3\n\n// Head, tail, last\nWITH [1, 2, 3, 4] as list\nRETURN head(list)  // 1\nRETURN last(list)  // 4\nRETURN tail(list)  // [2, 3, 4]\n\n// Reverse\nRETURN reverse([1, 2, 3])  // [3, 2, 1]\n</code></pre>"},{"location":"cypher/collections/#list-comprehensions","title":"List Comprehensions","text":"<pre><code>// Filter and transform\nWITH [1, 2, 3, 4, 5] as nums\nRETURN [x IN nums WHERE x &gt; 2 | x * 10] as result\n// [30, 40, 50]\n\n// Extract only\nRETURN [x IN [1, 2, 3] | x * 2]  // [2, 4, 6]\n\n// Filter only\nRETURN [x IN [1, 2, 3, 4, 5] WHERE x &gt; 2]  // [3, 4, 5]\n</code></pre>"},{"location":"cypher/collections/#list-predicates","title":"List Predicates","text":"<pre><code>// ALL\nWITH [1, 2, 3] as nums\nRETURN ALL(x IN nums WHERE x &gt; 0)  // true\n\n// ANY\nWITH [1, -1, 2] as nums\nRETURN ANY(x IN nums WHERE x &lt; 0)  // true\n\n// NONE\nWITH [1, 2, 3] as nums\nRETURN NONE(x IN nums WHERE x &lt; 0)  // true\n\n// SINGLE\nWITH [1, 2, 1] as nums\nRETURN SINGLE(x IN nums WHERE x = 2)  // true\n</code></pre>"},{"location":"cypher/collections/#reducing-lists","title":"Reducing Lists","text":"<pre><code>// Sum all elements\nWITH [1, 2, 3, 4, 5] as nums\nRETURN reduce(sum = 0, x IN nums | sum + x)  // 15\n\n// Build string\nWITH ['Alice', 'Bob', 'Charlie'] as names\nRETURN reduce(s = '', name IN names | s + ', ' + name)  // ', Alice, Bob, Charlie'\n</code></pre>"},{"location":"cypher/collections/#maps","title":"Maps","text":""},{"location":"cypher/collections/#creating-maps","title":"Creating Maps","text":"<pre><code>// Literal map\nRETURN {name: 'Alice', age: 30} as person\n\n// Nested maps\nRETURN {\n  name: 'Alice',\n  address: {city: 'NYC', zip: '10001'}\n} as data\n</code></pre>"},{"location":"cypher/collections/#map-access","title":"Map Access","text":"<pre><code>WITH {name: 'Alice', age: 30} as person\nRETURN person.name, person.age\n// Can also use: person['name']\n</code></pre>"},{"location":"cypher/collections/#map-functions","title":"Map Functions","text":"<pre><code>// keys() and values()\nWITH {a: 1, b: 2, c: 3} as m\nRETURN keys(m)    // ['a', 'b', 'c']\nRETURN values(m)  // [1, 2, 3]\n\n// Dynamic key access\nWITH {name: 'Alice'} as p, 'name' as key\nRETURN p[key]  // 'Alice'\n</code></pre>"},{"location":"cypher/collections/#working-with-properties","title":"Working with Properties","text":""},{"location":"cypher/collections/#dynamic-property-access","title":"Dynamic Property Access","text":"<pre><code>// Get all property values\nMATCH (p:Person)\nRETURN p.name, [key IN keys(p) | p[key]] as allValues\n</code></pre>"},{"location":"cypher/collections/#converting-to-map","title":"Converting to Map","text":"<pre><code>// Node to map\nMATCH (p:Person {name: 'Alice'})\nRETURN apoc.map.fromPairs([\n  key IN keys(p) | [key, p[key]]\n]) as personMap\n</code></pre>"},{"location":"cypher/collections/#unwind","title":"UNWIND","text":"<p>Expands lists into rows.</p> <pre><code>// Create nodes from list\nUNWIND ['Alice', 'Bob', 'Charlie'] as name\nCREATE (p:Person {name: name})\n</code></pre> <pre><code>// Process list property\nMATCH (p:Person)\nUNWIND p.tags as tag\nRETURN p.name, tag\n</code></pre> <pre><code>// With multiple properties\nMATCH (p:Person)\nUNWIND p.interests as interest\nWITH p, interest\nWHERE interest.category = 'tech'\nRETURN p.name, interest.name\n</code></pre>"},{"location":"cypher/create-match/","title":"CREATE and MATCH","text":"<p>The two most fundamental Cypher operations: creating data and finding data.</p>"},{"location":"cypher/create-match/#create","title":"CREATE","text":"<p>Creates nodes and relationships.</p>"},{"location":"cypher/create-match/#create-nodes","title":"Create Nodes","text":"<pre><code>// Simple node\nCREATE (n)\n\n// With label\nCREATE (p:Person)\n\n// With multiple labels\nCREATE (p:Person:Employee)\n\n// With properties\nCREATE (p:Person {name: 'Alice', age: 30})\n\n// With complex properties\nCREATE (p:Person {\n    name: 'Bob',\n    tags: ['developer', 'python'],\n    metadata: {joined: '2024-01-15'}\n})\n</code></pre>"},{"location":"cypher/create-match/#create-relationships","title":"Create Relationships","text":"<pre><code>// Create both nodes and relationship\nCREATE (a:Person {name: 'Alice'})-[:KNOWS]-&gt;(b:Person {name: 'Bob'})\n\n// Create relationship between existing nodes\nMATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'})\nCREATE (a)-[:KNOWS {since: 2020}]-&gt;(b)\n\n// Create multiple relationships\nCREATE (a)-[:KNOWS]-&gt;(b)-[:KNOWS]-&gt;(c)\n</code></pre>"},{"location":"cypher/create-match/#create-multiple-elements","title":"Create Multiple Elements","text":"<pre><code>// Separate with commas\nCREATE\n  (a:Person {name: 'Alice'}),\n  (b:Person {name: 'Bob'}),\n  (c:Company {name: 'TechCorp'}),\n  (a)-[:KNOWS]-&gt;(b),\n  (a)-[:WORKS_AT]-&gt;(c)\n</code></pre>"},{"location":"cypher/create-match/#create-and-return","title":"Create and Return","text":"<pre><code>CREATE (p:Person {name: 'Alice'})\nRETURN p\n</code></pre>"},{"location":"cypher/create-match/#match","title":"MATCH","text":"<p>Finds existing patterns in the graph.</p>"},{"location":"cypher/create-match/#match-nodes","title":"Match Nodes","text":"<pre><code>// Any node\nMATCH (n)\nRETURN n\n\n// By label\nMATCH (p:Person)\nRETURN p\n\n// By multiple labels\nMATCH (p:Person:Employee)\nRETURN p\n\n// By property\nMATCH (p:Person {name: 'Alice'})\nRETURN p\n\n// By multiple properties\nMATCH (p:Person {name: 'Alice', age: 30})\nRETURN p\n</code></pre>"},{"location":"cypher/create-match/#match-relationships","title":"Match Relationships","text":"<pre><code>// Any relationship\nMATCH ()-[r]-&gt;()\nRETURN r\n\n// By type\nMATCH ()-[r:KNOWS]-&gt;()\nRETURN r\n\n// With direction\nMATCH (a)-[r:KNOWS]-&gt;(b)\nRETURN a.name, b.name\n\n// Both directions\nMATCH (a)-[r:KNOWS]-(b)\nRETURN a.name, b.name\n\n// Specific nodes\nMATCH (a:Person)-[r:KNOWS]-&gt;(b:Person)\nRETURN a.name, b.name\n</code></pre>"},{"location":"cypher/create-match/#match-with-properties","title":"Match with Properties","text":"<pre><code>// Properties in pattern\nMATCH (p:Person {name: 'Alice'})-[:KNOWS]-&gt;(friend)\nRETURN friend.name\n\n// Properties on relationship\nMATCH (a)-[r:WORKS_AT {since: 2020}]-&gt;(b)\nRETURN a.name, b.name\n</code></pre>"},{"location":"cypher/create-match/#combining-create-and-match","title":"Combining CREATE and MATCH","text":""},{"location":"cypher/create-match/#connect-existing-nodes","title":"Connect Existing Nodes","text":"<pre><code># First create nodes\ndb.execute(\"\"\"\n    CREATE (a:Person {name: 'Alice'}),\n           (b:Person {name: 'Bob'})\n\"\"\")\n\n# Then connect them\ndb.execute(\"\"\"\n    MATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'})\n    CREATE (a)-[:KNOWS {since: 2020}]-&gt;(b)\n\"\"\")\n</code></pre>"},{"location":"cypher/create-match/#find-or-create-pattern","title":"Find or Create Pattern","text":"<p>Use <code>MERGE</code> for find-or-create (see Data Modification):</p> <pre><code>MERGE (p:Person {email: 'alice@example.com'})\nON CREATE SET p.name = 'Alice', p.created = datetime()\nON MATCH SET p.lastSeen = datetime()\nRETURN p\n</code></pre>"},{"location":"cypher/create-match/#variable-length-matching","title":"Variable-Length Matching","text":""},{"location":"cypher/create-match/#fixed-length","title":"Fixed Length","text":"<pre><code>// Exactly 2 hops (friends of friends)\nMATCH (a:Person {name: 'Alice'})-[:KNOWS*2]-&gt;(fof)\nRETURN fof\n</code></pre>"},{"location":"cypher/create-match/#range","title":"Range","text":"<pre><code>// 1 to 3 hops\nMATCH (a:Person {name: 'Alice'})-[:KNOWS*1..3]-&gt;(other)\nRETURN other\n</code></pre>"},{"location":"cypher/create-match/#unbounded","title":"Unbounded","text":"<p>Uses default max hops configured at database creation:</p> <pre><code>db = GrafitoDatabase(':memory:', cypher_max_hops=5)\n</code></pre> <pre><code>// Uses default max hops\nMATCH (a:Person)-[:KNOWS*..]-&gt;(other)\nRETURN other\n</code></pre>"},{"location":"cypher/create-match/#shortest-path","title":"Shortest Path","text":"<pre><code>// Single shortest path\nMATCH p = shortestPath(\n  (a:Person {name: 'Alice'})-[:KNOWS*1..5]-&gt;(b:Person {name: 'Bob'})\n)\nRETURN p, length(p) as hops\n\n// All shortest paths\nMATCH p = allShortestPaths(\n  (a:Person {name: 'Alice'})-[:KNOWS*1..5]-&gt;(b:Person {name: 'Bob'})\n)\nRETURN p\n</code></pre>"},{"location":"cypher/create-match/#pattern-comprehensions","title":"Pattern Comprehensions","text":"<p>Collect related nodes in a list:</p> <pre><code>// Get Alice's friends as a list\nMATCH (a:Person {name: 'Alice'})\nRETURN [(a)-[:KNOWS]-&gt;(b) | b.name] as friends\n\n// With filter\nMATCH (a:Person {name: 'Alice'})\nRETURN [(a)-[:KNOWS]-&gt;(b) WHERE b.active | b.name] as activeFriends\n</code></pre>"},{"location":"cypher/create-match/#common-patterns","title":"Common Patterns","text":""},{"location":"cypher/create-match/#social-network","title":"Social Network","text":"<pre><code>// Friends of friends\nMATCH (me:Person {name: 'Alice'})-[:KNOWS]-&gt;()-[:KNOWS]-&gt;(fof)\nWHERE fof &lt;&gt; me\nRETURN DISTINCT fof.name\n</code></pre>"},{"location":"cypher/create-match/#organization-hierarchy","title":"Organization Hierarchy","text":"<pre><code>// All reports to a manager\nMATCH (mgr:Person {name: 'Alice'})&lt;-[:REPORTS_TO*]-(emp)\nRETURN emp.name\n</code></pre>"},{"location":"cypher/create-match/#recommendation","title":"Recommendation","text":"<pre><code>// People with similar interests\nMATCH (me:Person)-[:INTERESTED_IN]-&gt;(interest)&lt;-[:INTERESTED_IN]-(other)\nWHERE me.name = 'Alice' AND other &lt;&gt; me\nRETURN other.name, count(interest) as common\nORDER BY common DESC\n</code></pre>"},{"location":"cypher/filtering/","title":"Filtering with WHERE","text":"<p>The WHERE clause filters results from MATCH operations.</p>"},{"location":"cypher/filtering/#basic-comparisons","title":"Basic Comparisons","text":""},{"location":"cypher/filtering/#comparison-operators","title":"Comparison Operators","text":"<pre><code>// Equal\nMATCH (p:Person)\nWHERE p.name = 'Alice'\nRETURN p\n\n// Not equal\nMATCH (p:Person)\nWHERE p.name &lt;&gt; 'Alice'\nRETURN p\n\n// Greater than\nMATCH (p:Person)\nWHERE p.age &gt; 25\nRETURN p.name\n\n// Greater or equal\nMATCH (p:Person)\nWHERE p.age &gt;= 18\nRETURN p.name\n\n// Less than\nMATCH (p:Person)\nWHERE p.age &lt; 65\nRETURN p.name\n\n// Less or equal\nMATCH (p:Person)\nWHERE p.age &lt;= 30\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#range-comparisons","title":"Range Comparisons","text":"<pre><code>// Chained comparisons\nMATCH (p:Person)\nWHERE 18 &lt;= p.age &lt;= 65\nRETURN p.name\n\n// Equivalent to:\nMATCH (p:Person)\nWHERE p.age &gt;= 18 AND p.age &lt;= 65\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#logical-operators","title":"Logical Operators","text":""},{"location":"cypher/filtering/#and","title":"AND","text":"<pre><code>MATCH (p:Person)\nWHERE p.age &gt; 25 AND p.city = 'NYC'\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#or","title":"OR","text":"<pre><code>MATCH (p:Person)\nWHERE p.city = 'NYC' OR p.city = 'LA'\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#not","title":"NOT","text":"<pre><code>MATCH (p:Person)\nWHERE NOT p.active\nRETURN p.name\n\n// Can also use for negation\nMATCH (p:Person)\nWHERE NOT (p.age &gt; 25)\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#combining-operators","title":"Combining Operators","text":"<pre><code>// Use parentheses for clarity\nMATCH (p:Person)\nWHERE (p.age &gt; 25 AND p.city = 'NYC') OR p.city = 'LA'\nRETURN p.name\n\n// Complex condition\nMATCH (p:Person)\nWHERE p.active = true\n  AND (p.age &lt; 25 OR p.age &gt; 65)\n  AND NOT p.name = 'Admin'\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#null-handling","title":"NULL Handling","text":""},{"location":"cypher/filtering/#is-null-is-not-null","title":"IS NULL / IS NOT NULL","text":"<pre><code>// Find persons without age\nMATCH (p:Person)\nWHERE p.age IS NULL\nRETURN p.name\n\n// Find persons with age set\nMATCH (p:Person)\nWHERE p.age IS NOT NULL\nRETURN p.name, p.age\n</code></pre>"},{"location":"cypher/filtering/#null-comparisons","title":"NULL Comparisons","text":"<pre><code>// NULL comparisons return NULL (falsy in WHERE)\nMATCH (p:Person)\nWHERE p.age = NULL  // This never matches!\nRETURN p\n\n// Correct way\nMATCH (p:Person)\nWHERE p.age IS NULL\nRETURN p\n</code></pre>"},{"location":"cypher/filtering/#string-matching","title":"String Matching","text":""},{"location":"cypher/filtering/#starts-with","title":"STARTS WITH","text":"<pre><code>// Names starting with 'Al'\nMATCH (p:Person)\nWHERE p.name STARTS WITH 'Al'\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#ends-with","title":"ENDS WITH","text":"<pre><code>// Emails ending with '@company.com'\nMATCH (p:Person)\nWHERE p.email ENDS WITH '@company.com'\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#contains","title":"CONTAINS","text":"<pre><code>// Names containing 'li'\nMATCH (p:Person)\nWHERE p.name CONTAINS 'li'\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#regular-expressions","title":"Regular Expressions","text":"<pre><code>// Regexp matching\nMATCH (p:Person)\nWHERE p.name =~ '^A.*e$'\nRETURN p.name\n\n// Case insensitive (with (?i))\nMATCH (p:Person)\nWHERE p.name =~ '(?i)^alice$'\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#list-operations","title":"List Operations","text":""},{"location":"cypher/filtering/#in-operator","title":"IN Operator","text":"<pre><code>// Match any of these names\nMATCH (p:Person)\nWHERE p.name IN ['Alice', 'Bob', 'Charlie']\nRETURN p.name\n\n// Check if value in list property\nMATCH (p:Person)\nWHERE 'developer' IN p.tags\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#list-predicates","title":"List Predicates","text":"<pre><code>// All elements satisfy condition\nWITH [1, 2, 3] as list\nWHERE ALL(x IN list WHERE x &gt; 0)\nRETURN list\n\n// Any element satisfies condition\nWITH [1, -1, 2] as list\nWHERE ANY(x IN list WHERE x &lt; 0)\nRETURN list\n\n// No element satisfies condition\nWITH [1, 2, 3] as list\nWHERE NONE(x IN list WHERE x &lt; 0)\nRETURN list\n\n// Exactly one element satisfies condition\nWITH [1, 2, 3] as list\nWHERE SINGLE(x IN list WHERE x = 2)\nRETURN list\n</code></pre>"},{"location":"cypher/filtering/#pattern-filtering","title":"Pattern Filtering","text":""},{"location":"cypher/filtering/#exists","title":"EXISTS","text":"<pre><code>// Persons who know someone\nMATCH (p:Person)\nWHERE EXISTS((p)-[:KNOWS]-&gt;())\nRETURN p.name\n\n// Persons who work at a company\nMATCH (p:Person)\nWHERE EXISTS((p)-[:WORKS_AT]-&gt;(:Company))\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#filtering-on-patterns","title":"Filtering on Patterns","text":"<pre><code>// Persons who know someone over 30\nMATCH (p:Person)\nWHERE EXISTS((p)-[:KNOWS]-&gt;({age: 30}))\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#property-existence","title":"Property Existence","text":"<pre><code>// Using EXISTS for property (alternate to IS NOT NULL)\nMATCH (p:Person)\nWHERE EXISTS(p.email)\nRETURN p.name\n\n// Combined with value check\nMATCH (p:Person)\nWHERE EXISTS(p.age) AND p.age &gt; 25\nRETURN p.name\n</code></pre>"},{"location":"cypher/filtering/#examples-by-use-case","title":"Examples by Use Case","text":""},{"location":"cypher/filtering/#user-management","title":"User Management","text":"<pre><code>// Active users with verified email\nMATCH (u:User)\nWHERE u.active = true\n  AND u.emailVerified = true\n  AND u.createdAt &gt; date('2024-01-01')\nRETURN u.email\n</code></pre>"},{"location":"cypher/filtering/#product-search","title":"Product Search","text":"<pre><code>// Available products in category\nMATCH (p:Product)\nWHERE p.category IN ['electronics', 'computers']\n  AND p.stock &gt; 0\n  AND (p.price &gt;= 100 AND p.price &lt;= 500)\nRETURN p.name, p.price\n</code></pre>"},{"location":"cypher/filtering/#social-network","title":"Social Network","text":"<pre><code>// Active friends in same city\nMATCH (me:Person {name: 'Alice'})-[:KNOWS]-&gt;(friend)\nWHERE friend.active = true\n  AND friend.city = me.city\n  AND NOT friend.name = me.name\nRETURN friend.name\n</code></pre>"},{"location":"cypher/indexes-constraints/","title":"Indexes and Constraints","text":"<p>Schema management for performance and data integrity.</p>"},{"location":"cypher/indexes-constraints/#property-indexes","title":"Property Indexes","text":""},{"location":"cypher/indexes-constraints/#creating-node-indexes","title":"Creating Node Indexes","text":"<p>Programmatic API:</p> <pre><code>db.create_node_index('Person', 'name')\ndb.create_node_index('Person', 'email')  # Can index same label different props\n</code></pre> <p>Cypher:</p> <pre><code>// Modern syntax\nCREATE INDEX FOR (n:Person) ON (n.name)\n\n// Alternative syntax\nCREATE INDEX FOR NODE :Person(name)\n\n// With explicit name\nCREATE INDEX person_email_idx FOR (n:Person) ON (n.email)\n</code></pre>"},{"location":"cypher/indexes-constraints/#creating-relationship-indexes","title":"Creating Relationship Indexes","text":"<p>Programmatic API:</p> <pre><code>db.create_relationship_index('KNOWS', 'since')\n</code></pre> <p>Cypher:</p> <pre><code>// Modern syntax\nCREATE INDEX FOR ()-[r:KNOWS]-() ON (r.since)\n\n// Alternative syntax\nCREATE INDEX FOR RELATIONSHIP :KNOWS(since)\n</code></pre>"},{"location":"cypher/indexes-constraints/#if-not-exists","title":"IF NOT EXISTS","text":"<pre><code>// Skip if already exists\nCREATE INDEX IF NOT EXISTS FOR (n:Person) ON (n.name)\n</code></pre>"},{"location":"cypher/indexes-constraints/#unique-indexes","title":"Unique Indexes","text":"<pre><code>CREATE UNIQUE INDEX FOR (n:User) ON (n.email)\n</code></pre>"},{"location":"cypher/indexes-constraints/#uri-indexes","title":"URI Indexes","text":"<p>For URI/URL-based lookups:</p> <pre><code># Programmatic\ndb.create_node_uri_index()\ndb.create_relationship_uri_index()\n</code></pre> <pre><code>// Cypher\nCALL db.uri_index.create('node')\nCALL db.uri_index.create('relationship')\n</code></pre>"},{"location":"cypher/indexes-constraints/#listing-indexes","title":"Listing Indexes","text":"<pre><code># Programmatic\nindexes = db.list_indexes()\nfor idx in indexes:\n    print(f\"{idx['name']}: {idx['entity']}:{idx['label_or_type']}({idx['property']})\")\n</code></pre> <pre><code>// All indexes\nSHOW INDEXES\n\n// Filtered\nSHOW INDEXES WHERE entity = 'node'\nSHOW INDEXES WHERE label_or_type = 'Person'\n</code></pre>"},{"location":"cypher/indexes-constraints/#dropping-indexes","title":"Dropping Indexes","text":"<pre><code>db.drop_index('idx_node_person_name')\n</code></pre> <pre><code>// By name\nDROP INDEX idx_node_person_name\n\n// If exists\nDROP INDEX IF EXISTS idx_node_person_name\n</code></pre>"},{"location":"cypher/indexes-constraints/#constraints","title":"Constraints","text":""},{"location":"cypher/indexes-constraints/#uniqueness-constraints","title":"Uniqueness Constraints","text":"<pre><code>// Node property must be unique (nulls allowed)\nCREATE CONSTRAINT FOR (n:User) REQUIRE n.email IS UNIQUE\n\n// With name\nCREATE CONSTRAINT user_email_unique FOR (n:User) REQUIRE n.email IS UNIQUE\n</code></pre>"},{"location":"cypher/indexes-constraints/#existence-constraints","title":"Existence Constraints","text":"<pre><code>// Property must exist on all nodes with label\nCREATE CONSTRAINT FOR (n:Person) REQUIRE n.name IS NOT NULL\n</code></pre>"},{"location":"cypher/indexes-constraints/#type-constraints","title":"Type Constraints","text":"<pre><code>// Property must be of specific type\nCREATE CONSTRAINT FOR (n:Person) REQUIRE n.age IS INTEGER\nCREATE CONSTRAINT FOR (n:User) REQUIRE n.active IS BOOLEAN\nCREATE CONSTRAINT FOR (n:Product) REQUIRE n.price IS FLOAT\nCREATE CONSTRAINT FOR (n:Document) REQUIRE n.tags IS LIST\nCREATE CONSTRAINT FOR (n:Config) REQUIRE n.settings IS MAP\nCREATE CONSTRAINT FOR (n:User) REQUIRE n.bio IS STRING\n</code></pre> <p>Supported types: <code>STRING</code>, <code>INTEGER</code>, <code>FLOAT</code>, <code>BOOLEAN</code>, <code>LIST</code>, <code>MAP</code></p>"},{"location":"cypher/indexes-constraints/#relationship-constraints","title":"Relationship Constraints","text":"<pre><code>// All work relationships must have 'since' property\nCREATE CONSTRAINT FOR ()-[r:WORKS_AT]-() REQUIRE r.since IS NOT NULL\n\n// Type constraint on relationship property\nCREATE CONSTRAINT FOR ()-[r:KNOWS]-() REQUIRE r.strength IS INTEGER\n</code></pre>"},{"location":"cypher/indexes-constraints/#neo4j-style-syntax","title":"Neo4j-Style Syntax","text":"<pre><code>// Alternative syntax for compatibility\nCREATE CONSTRAINT FOR (n:Person) ON (n.email) IS UNIQUE\nCREATE CONSTRAINT FOR (n:Person) ON (n.age) IS INTEGER\n</code></pre>"},{"location":"cypher/indexes-constraints/#listing-constraints","title":"Listing Constraints","text":"<pre><code>// All constraints\nSHOW CONSTRAINTS\n\n// Filtered\nSHOW CONSTRAINTS WHERE entity = 'node'\nSHOW CONSTRAINTS WHERE type = 'uniqueness'\n</code></pre>"},{"location":"cypher/indexes-constraints/#dropping-constraints","title":"Dropping Constraints","text":"<pre><code>// By auto-generated name\nDROP CONSTRAINT constraint_node_person_email_unique\n\n// By custom name\nDROP CONSTRAINT user_email_unique\n\n// If exists\nDROP CONSTRAINT IF EXISTS user_email_unique\n</code></pre>"},{"location":"cypher/indexes-constraints/#constraint-behavior","title":"Constraint Behavior","text":""},{"location":"cypher/indexes-constraints/#uniqueness-and-null","title":"Uniqueness and NULL","text":"<pre><code>// NULL values are not checked for uniqueness\nCREATE CONSTRAINT FOR (n:User) REQUIRE n.email IS UNIQUE\n\n// These are both valid:\nCREATE (u1:User {name: 'Alice'})  // email is null\nCREATE (u2:User {name: 'Bob'})    // email is null (also null, allowed!)\n\n// But this would fail:\nCREATE (u3:User {email: 'a@b.com'})\nCREATE (u4:User {email: 'a@b.com'})  // ERROR: duplicate\n</code></pre>"},{"location":"cypher/indexes-constraints/#type-constraints-require-non-null","title":"Type Constraints Require Non-NULL","text":"<pre><code>CREATE CONSTRAINT FOR (n:Person) REQUIRE n.age IS INTEGER\n\n// This fails - age is NULL\nCREATE (p:Person {name: 'Alice'})\n\n// This works\nCREATE (p:Person {name: 'Alice', age: 30})\n\n// This fails - wrong type\nCREATE (p:Person {name: 'Bob', age: 'thirty'})\n</code></pre>"},{"location":"cypher/indexes-constraints/#best-practices","title":"Best Practices","text":""},{"location":"cypher/indexes-constraints/#when-to-create-indexes","title":"When to Create Indexes","text":"<pre><code>-- Index properties used in:\n-- 1. MATCH lookups\nCREATE INDEX FOR (n:User) ON (n.email)\n\n-- 2. WHERE filters\nCREATE INDEX FOR (n:Product) ON (n.category)\n\n-- 3. ORDER BY\nCREATE INDEX FOR (n:Post) ON (n.created_at)\n</code></pre>"},{"location":"cypher/indexes-constraints/#index-strategy","title":"Index Strategy","text":"<pre><code># Don't index everything - each index has overhead\n# Index properties that are:\n# - Frequently queried\n# - High cardinality (many unique values)\n# - Used for sorting\n\n# Good candidates:\ndb.create_node_index('User', 'email')      # Unique lookup\ndb.create_node_index('Order', 'order_id')  # ID lookup\n\n# Poor candidates:\n# db.create_node_index('User', 'active')   # Low cardinality (true/false)\n# db.create_node_index('Log', 'message')   # Never queried directly\n</code></pre>"},{"location":"cypher/indexes-constraints/#constraints-first","title":"Constraints First","text":"<pre><code>-- Create constraints before importing data\n-- Data with violations will be rejected\n\nCREATE CONSTRAINT FOR (n:User) REQUIRE n.email IS UNIQUE;\nCREATE CONSTRAINT FOR (n:User) REQUIRE n.name IS NOT NULL;\n\n-- Now import data\nCREATE (u:User {email: 'alice@example.com', name: 'Alice'});\n</code></pre>"},{"location":"cypher/indexes-constraints/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cypher/indexes-constraints/#constraint-violation","title":"Constraint Violation","text":"<pre><code>ConstraintError: Node(123) already exists with label `User` and `email` = 'alice@example.com'\n</code></pre> <p>Solution: Use MERGE instead of CREATE for upsert semantics.</p>"},{"location":"cypher/indexes-constraints/#index-not-used","title":"Index Not Used","text":"<pre><code>-- Some queries can't use indexes\n-- Pattern expressions in WHERE\nWHERE (p)-[:KNOWS]-&gt;()  -- Can't use index on p\n\n-- Functions on indexed property\nWHERE toUpper(p.name) = 'ALICE'  -- Won't use index\n\n-- Instead, normalize on insert:\nSET p.name_lower = toLower(p.name)\n-- Then query:\nWHERE p.name_lower = 'alice'\n</code></pre>"},{"location":"cypher/modification/","title":"Data Modification","text":"<p>Modifying existing data with SET, DELETE, REMOVE, and MERGE.</p>"},{"location":"cypher/modification/#set","title":"SET","text":"<p>Updates properties on nodes and relationships.</p>"},{"location":"cypher/modification/#set-single-property","title":"Set Single Property","text":"<pre><code>// Set one property\nMATCH (p:Person {name: 'Alice'})\nSET p.age = 31\n</code></pre>"},{"location":"cypher/modification/#set-multiple-properties","title":"Set Multiple Properties","text":"<pre><code>// Set multiple properties\nMATCH (p:Person {name: 'Alice'})\nSET p.city = 'NYC', p.country = 'USA'\n</code></pre>"},{"location":"cypher/modification/#set-from-map","title":"Set from Map","text":"<pre><code>// Replace all properties using =\nMATCH (p:Person {name: 'Alice'})\nSET p = {name: 'Alice', age: 31, city: 'NYC'}\n\n// This removes all other properties!\n</code></pre>"},{"location":"cypher/modification/#addupdate-properties-with","title":"Add/Update Properties with +=","text":"<pre><code>// Merge properties (add new, update existing, keep others)\nMATCH (p:Person {name: 'Alice'})\nSET p += {city: 'NYC', department: 'Engineering'}\n</code></pre>"},{"location":"cypher/modification/#set-with-expression","title":"Set with Expression","text":"<pre><code>// Increment value\nMATCH (p:Person {name: 'Alice'})\nSET p.loginCount = p.loginCount + 1\n\n// Set from calculation\nMATCH (p:Person)\nSET p.ageNextYear = p.age + 1\n</code></pre>"},{"location":"cypher/modification/#set-with-creatematch","title":"Set with CREATE/MATCH","text":"<pre><code>// Create and set in one\nCREATE (p:Person)\nSET p.name = 'Bob', p.age = 25\n</code></pre>"},{"location":"cypher/modification/#delete","title":"DELETE","text":"<p>Removes nodes and relationships.</p>"},{"location":"cypher/modification/#delete-relationship","title":"Delete Relationship","text":"<pre><code>// Delete specific relationship\nMATCH (a:Person {name: 'Alice'})-[r:KNOWS]-&gt;(b:Person {name: 'Bob'})\nDELETE r\n</code></pre>"},{"location":"cypher/modification/#delete-node","title":"Delete Node","text":"<pre><code>// Delete node (must detach relationships first)\nMATCH (p:Person {name: 'Alice'})\nDELETE p\n</code></pre>"},{"location":"cypher/modification/#detach-delete","title":"DETACH DELETE","text":"<pre><code>// Delete node and all its relationships\nMATCH (p:Person {name: 'Alice'})\nDETACH DELETE p\n</code></pre>"},{"location":"cypher/modification/#delete-multiple","title":"Delete Multiple","text":"<pre><code>// Delete multiple items\nMATCH (p:Person {name: 'Alice'})-[r]-(), (p)\nDELETE r, p\n</code></pre>"},{"location":"cypher/modification/#remove","title":"REMOVE","text":"<p>Removes labels and properties.</p>"},{"location":"cypher/modification/#remove-property","title":"Remove Property","text":"<pre><code>// Remove single property\nMATCH (p:Person {name: 'Alice'})\nREMOVE p.temporary\n\n// Remove multiple properties\nMATCH (p:Person {name: 'Alice'})\nREMOVE p.temp1, p.temp2\n</code></pre>"},{"location":"cypher/modification/#remove-label","title":"Remove Label","text":"<pre><code>// Remove single label\nMATCH (p:Person:Employee {name: 'Alice'})\nREMOVE p:Employee\n\n// Remove multiple labels\nMATCH (p:Person:Employee:Manager {name: 'Alice'})\nREMOVE p:Employee, p:Manager\n// Now p only has :Person label\n</code></pre>"},{"location":"cypher/modification/#remove-all-labels","title":"Remove All Labels","text":"<pre><code>MATCH (p:Person {name: 'Alice'})\nREMOVE p:Person\n// Node now has no labels\n</code></pre>"},{"location":"cypher/modification/#merge","title":"MERGE","text":"<p>Finds existing patterns or creates them if not found.</p>"},{"location":"cypher/modification/#basic-merge","title":"Basic MERGE","text":"<pre><code>// Find or create node\nMERGE (p:Person {email: 'alice@example.com'})\nRETURN p\n</code></pre>"},{"location":"cypher/modification/#merge-with-on-create","title":"MERGE with ON CREATE","text":"<pre><code>// Set properties only when creating\nMERGE (p:Person {email: 'alice@example.com'})\nON CREATE SET\n  p.name = 'Alice',\n  p.createdAt = datetime(),\n  p.active = true\nRETURN p\n</code></pre>"},{"location":"cypher/modification/#merge-with-on-match","title":"MERGE with ON MATCH","text":"<pre><code>// Update properties only when existing\nMERGE (p:Person {email: 'alice@example.com'})\nON MATCH SET\n  p.lastSeen = datetime(),\n  p.visitCount = p.visitCount + 1\nRETURN p\n</code></pre>"},{"location":"cypher/modification/#combined-on-create-and-on-match","title":"Combined ON CREATE and ON MATCH","text":"<pre><code>MERGE (p:Person {email: 'alice@example.com'})\nON CREATE SET\n  p.name = 'Alice',\n  p.createdAt = datetime()\nON MATCH SET\n  p.lastSeen = datetime()\nRETURN p\n</code></pre>"},{"location":"cypher/modification/#merge-relationship","title":"MERGE Relationship","text":"<pre><code>// Find or create relationship\nMATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'})\nMERGE (a)-[r:KNOWS]-&gt;(b)\nRETURN r\n\n// With properties\nMATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'})\nMERGE (a)-[r:KNOWS]-&gt;(b)\nON CREATE SET r.since = 2020\nRETURN r\n</code></pre>"},{"location":"cypher/modification/#merge-path","title":"MERGE Path","text":"<pre><code>// Create entire path if not exists\nMERGE (a:Person {name: 'Alice'})-[:KNOWS]-&gt;(b:Person {name: 'Bob'})\nRETURN a, b\n</code></pre>"},{"location":"cypher/modification/#merge-with-multiple-patterns","title":"MERGE with Multiple Patterns","text":"<pre><code>// Match/create both nodes and relationship\nMERGE (a:Person {email: 'alice@example.com'})\nMERGE (b:Person {email: 'bob@example.com'})\nMERGE (a)-[:KNOWS]-&gt;(b)\n</code></pre>"},{"location":"cypher/modification/#foreach","title":"FOREACH","text":"<p>Iterate over a list and perform operations.</p> <pre><code>// Set property on each element\nMATCH (p:Person {name: 'Alice'})\nFOREACH (tag IN ['developer', 'python', 'database'] |\n  CREATE (t:Tag {name: tag})\n  MERGE (p)-[:INTERESTED_IN]-&gt;(t)\n)\n</code></pre>"},{"location":"cypher/modification/#common-patterns","title":"Common Patterns","text":""},{"location":"cypher/modification/#upsert-pattern","title":"Upsert Pattern","text":"<pre><code>// Update or insert (upsert)\nMERGE (p:Person {email: $email})\nON CREATE SET\n  p.name = $name,\n  p.createdAt = datetime(),\n  p.version = 1\nON MATCH SET\n  p.name = $name,\n  p.updatedAt = datetime(),\n  p.version = p.version + 1\nRETURN p\n</code></pre>"},{"location":"cypher/modification/#soft-delete","title":"Soft Delete","text":"<pre><code>// Instead of DELETE, mark as inactive\nMATCH (p:Person {name: 'Alice'})\nSET p.active = false, p.deletedAt = datetime()\nREMOVE p:Active\n</code></pre>"},{"location":"cypher/modification/#bulk-update","title":"Bulk Update","text":"<pre><code>// Update many nodes at once\nMATCH (p:Person)\nWHERE p.lastLogin &lt; datetime() - duration('P1Y')\nSET p.status = 'inactive'\n</code></pre>"},{"location":"cypher/modification/#property-migration","title":"Property Migration","text":"<pre><code>// Rename property\nMATCH (p:Person)\nWHERE EXISTS(p.oldName)\nSET p.newName = p.oldName\nREMOVE p.oldName\n</code></pre>"},{"location":"cypher/overview/","title":"Cypher Query Language","text":"<p>Grafito includes a complete Cypher parser and executor, allowing you to use Neo4j-style declarative queries.</p>"},{"location":"cypher/overview/#what-is-cypher","title":"What is Cypher?","text":"<p>Cypher is a declarative graph query language that describes patterns in graphs using ASCII-art notation.</p> <pre><code>// Find Alice's friends\nMATCH (a:Person {name: 'Alice'})-[:KNOWS]-&gt;(friend)\nRETURN friend.name\n</code></pre>"},{"location":"cypher/overview/#why-use-cypher","title":"Why Use Cypher?","text":"Approach Best For Programmatic API Simple CRUD, dynamic queries Cypher Complex patterns, analytics, reporting"},{"location":"cypher/overview/#basic-pattern-syntax","title":"Basic Pattern Syntax","text":""},{"location":"cypher/overview/#nodes","title":"Nodes","text":"<pre><code>// Any node\n(n)\n\n// Node with label\n(p:Person)\n\n// Node with multiple labels\n(p:Person:Employee)\n\n// Node with variable and label\n(a:Person)\n\n// Anonymous node\n(:Person)\n</code></pre>"},{"location":"cypher/overview/#relationships","title":"Relationships","text":"<pre><code>// Directed relationship\n(a)-[:KNOWS]-&gt;(b)\n\n// Relationship with properties\n(a)-[:KNOWS {since: 2020}]-&gt;(b)\n\n// Anonymous relationship\n(a)--&gt;(b)\n\n// Bidirectional (matches both directions)\n(a)-[:KNOWS]-(b)\n</code></pre>"},{"location":"cypher/overview/#paths","title":"Paths","text":"<pre><code>// Two-hop path\n(a)-[:KNOWS]-&gt;()-[:WORKS_AT]-&gt;(c)\n\n// Variable-length path\n(a)-[:KNOWS*1..3]-&gt;(b)\n\n// Named path\npath = (a)-[:KNOWS*]-&gt;(b)\n</code></pre>"},{"location":"cypher/overview/#executing-cypher-in-grafito","title":"Executing Cypher in Grafito","text":"<pre><code>from grafito import GrafitoDatabase\n\ndb = GrafitoDatabase(':memory:')\n\n# Execute without results\ndb.execute(\"CREATE (n:Person {name: 'Alice'})\")\n\n# Execute with results\nresults = db.execute(\"MATCH (n:Person) RETURN n.name\")\nfor row in results:\n    print(row['n.name'])\n</code></pre>"},{"location":"cypher/overview/#query-structure","title":"Query Structure","text":"<p>A typical Cypher query has this structure:</p> <pre><code>[USE]           // Graph selection (not in Grafito)\n[READING]       // MATCH, OPTIONAL MATCH\n[PROJECTING]    // WITH\n[READING]       // Additional MATCH\n[WHERE]         // Filters\n[PROJECTING]    // RETURN\n[ORDER BY]      // Sorting\n[SKIP]          // Pagination\n[LIMIT]         // Pagination\n</code></pre>"},{"location":"cypher/overview/#clauses-overview","title":"Clauses Overview","text":"Clause Purpose Example <code>MATCH</code> Find patterns <code>MATCH (n:Person)</code> <code>CREATE</code> Create nodes/relationships <code>CREATE (n:Person)</code> <code>MERGE</code> Find or create <code>MERGE (n:Person {email: 'a@b'})</code> <code>SET</code> Update properties <code>SET n.name = 'Alice'</code> <code>DELETE</code> Remove nodes/relationships <code>DELETE n</code> <code>REMOVE</code> Remove labels/properties <code>REMOVE n:OldLabel</code> <code>RETURN</code> Define output <code>RETURN n.name</code> <code>WHERE</code> Filter results <code>WHERE n.age &gt; 25</code> <code>ORDER BY</code> Sort results <code>ORDER BY n.name ASC</code> <code>SKIP</code> Skip N results <code>SKIP 10</code> <code>LIMIT</code> Limit results <code>LIMIT 10</code> <code>UNION</code> Combine results <code>... UNION ...</code> <code>CALL</code> Execute procedures <code>CALL db.vector.search(...)</code>"},{"location":"cypher/overview/#quick-examples","title":"Quick Examples","text":""},{"location":"cypher/overview/#create-data","title":"Create Data","text":"<pre><code>db.execute(\"\"\"\n    CREATE (a:Person {name: 'Alice', age: 30}),\n           (b:Person {name: 'Bob', age: 25}),\n           (a)-[:KNOWS {since: 2020}]-&gt;(b)\n\"\"\")\n</code></pre>"},{"location":"cypher/overview/#query-patterns","title":"Query Patterns","text":"<pre><code># Find all persons\nresults = db.execute(\"MATCH (n:Person) RETURN n.name\")\n\n# Find specific person\nresults = db.execute(\"MATCH (n:Person {name: 'Alice'}) RETURN n\")\n\n# Find relationships\nresults = db.execute(\"\"\"\n    MATCH (a:Person)-[r:KNOWS]-&gt;(b:Person)\n    RETURN a.name, b.name, r.since\n\"\"\")\n</code></pre>"},{"location":"cypher/overview/#update-data","title":"Update Data","text":"<pre><code># Update property\ndb.execute(\"\"\"\n    MATCH (n:Person {name: 'Alice'})\n    SET n.age = 31\n\"\"\")\n\n# Add label\ndb.execute(\"\"\"\n    MATCH (n:Person {name: 'Alice'})\n    SET n:Employee\n\"\"\")\n\n# Remove property\ndb.execute(\"\"\"\n    MATCH (n:Person)\n    REMOVE n.temporary\n\"\"\")\n</code></pre>"},{"location":"cypher/overview/#delete-data","title":"Delete Data","text":"<pre><code># Delete relationship\ndb.execute(\"\"\"\n    MATCH (a)-[r:KNOWS]-&gt;(b)\n    WHERE a.name = 'Alice'\n    DELETE r\n\"\"\")\n\n# Delete node (and its relationships)\ndb.execute(\"\"\"\n    MATCH (n:Person {name: 'Alice'})\n    DELETE n\n\"\"\")\n\n# Delete everything (careful!)\ndb.execute(\"MATCH (n) DETACH DELETE n\")\n</code></pre>"},{"location":"cypher/overview/#variable-length-paths","title":"Variable-Length Paths","text":"<p>Configure default max hops when creating the database:</p> <pre><code>db = GrafitoDatabase(':memory:', cypher_max_hops=5)\n\n# Unbounded uses default max\ndb.execute(\"MATCH (a)-[:KNOWS*..]-&gt;(b) RETURN b\")\n\n# Explicit bounds\ndb.execute(\"MATCH (a)-[:KNOWS*1..3]-&gt;(b) RETURN b\")\n</code></pre>"},{"location":"cypher/overview/#result-format","title":"Result Format","text":"<p>Query results are returned as a list of dictionaries:</p> <pre><code>results = db.execute(\"\"\"\n    MATCH (n:Person)\n    RETURN n.name, n.age\n\"\"\")\n\nfor row in results:\n    print(f\"Name: {row['n.name']}\")\n    print(f\"Age: {row['n.age']}\")\n</code></pre> <p>With aliases:</p> <pre><code>results = db.execute(\"\"\"\n    MATCH (n:Person)\n    RETURN n.name AS name, n.age AS age\n\"\"\")\n\nfor row in results:\n    print(f\"{row['name']}: {row['age']}\")\n</code></pre>"},{"location":"cypher/overview/#hybrid-usage","title":"Hybrid Usage","text":"<p>Mix Cypher with the programmatic API:</p> <pre><code># Create with API\nalice = db.create_node(labels=['Person'], properties={'name': 'Alice'})\n\n# Query with Cypher\nresults = db.execute(\"MATCH (n:Person) RETURN n\")\n\n# Update with Cypher\ndb.execute(f\"MATCH (n) WHERE id(n) = {alice.id} SET n.active = true\")\n\n# Verify with API\nupdated = db.get_node(alice.id)\nprint(updated.properties['active'])  # True\n</code></pre>"},{"location":"cypher/overview/#next-steps","title":"Next Steps","text":"<ul> <li>CREATE and MATCH</li> <li>Filtering with WHERE</li> <li>Return and Aggregation</li> <li>Data Modification</li> <li>Complex Patterns</li> </ul>"},{"location":"cypher/patterns/","title":"Complex Patterns","text":"<p>Advanced pattern matching techniques.</p>"},{"location":"cypher/patterns/#multiple-patterns","title":"Multiple Patterns","text":""},{"location":"cypher/patterns/#matching-separate-patterns","title":"Matching Separate Patterns","text":"<pre><code>// Match multiple independent patterns\nMATCH\n  (a:Person {name: 'Alice'}),\n  (b:Person {name: 'Bob'})\nRETURN a, b\n</code></pre>"},{"location":"cypher/patterns/#connecting-patterns","title":"Connecting Patterns","text":"<pre><code>// Alice knows someone who knows Bob\nMATCH\n  (a:Person {name: 'Alice'})-[:KNOWS]-&gt;(friend),\n  (friend)-[:KNOWS]-&gt;(b:Person {name: 'Bob'})\nRETURN friend.name\n</code></pre>"},{"location":"cypher/patterns/#multiple-path-patterns","title":"Multiple Path Patterns","text":"<pre><code>// Find common connections through different paths\nMATCH\n  (a:Person)-[:WORKS_AT]-&gt;(c:Company),\n  (a)-[:LIVES_IN]-&gt;(city:City)\nRETURN a.name, c.name, city.name\n</code></pre>"},{"location":"cypher/patterns/#optional-match","title":"OPTIONAL MATCH","text":"<p>Returns NULL for missing parts instead of filtering out.</p>"},{"location":"cypher/patterns/#basic-optional-match","title":"Basic Optional Match","text":"<pre><code>// Get all persons, with their company if they have one\nMATCH (p:Person)\nOPTIONAL MATCH (p)-[:WORKS_AT]-&gt;(c:Company)\nRETURN p.name, c.name  // c.name is NULL if no company\n</code></pre>"},{"location":"cypher/patterns/#multiple-optionals","title":"Multiple Optionals","text":"<pre><code>// Person with optional company and optional location\nMATCH (p:Person)\nOPTIONAL MATCH (p)-[:WORKS_AT]-&gt;(c:Company)\nOPTIONAL MATCH (p)-[:LIVES_IN]-&gt;(city:City)\nRETURN p.name, c.name, city.name\n</code></pre>"},{"location":"cypher/patterns/#optional-with-where","title":"Optional with WHERE","text":"<pre><code>MATCH (p:Person)\nOPTIONAL MATCH (p)-[:KNOWS]-&gt;(friend)\nWHERE friend.active = true\nRETURN p.name, friend.name\n</code></pre>"},{"location":"cypher/patterns/#cyclic-patterns","title":"Cyclic Patterns","text":""},{"location":"cypher/patterns/#self-referencing","title":"Self-Referencing","text":"<pre><code>// Find mutual relationships\nMATCH (a:Person)-[:KNOWS]-&gt;(b:Person)-[:KNOWS]-&gt;(a)\nRETURN a.name, b.name\n</code></pre>"},{"location":"cypher/patterns/#triangles","title":"Triangles","text":"<pre><code>// Find friend triangles (A knows B, B knows C, C knows A)\nMATCH\n  (a)-[:KNOWS]-&gt;(b),\n  (b)-[:KNOWS]-&gt;(c),\n  (c)-[:KNOWS]-&gt;(a)\nRETURN a.name, b.name, c.name\n</code></pre>"},{"location":"cypher/patterns/#named-paths","title":"Named Paths","text":""},{"location":"cypher/patterns/#capturing-paths","title":"Capturing Paths","text":"<pre><code>// Capture entire path\nMATCH p = (a:Person)-[:KNOWS*1..3]-&gt;(b:Person)\nWHERE a.name = 'Alice' AND b.name = 'Bob'\nRETURN p, length(p) as hops\n</code></pre>"},{"location":"cypher/patterns/#path-functions","title":"Path Functions","text":"<pre><code>// Analyze paths\nMATCH p = (a)-[:KNOWS*]-&gt;(b)\nRETURN\n  nodes(p) as pathNodes,\n  relationships(p) as pathRels,\n  length(p) as numHops\n</code></pre>"},{"location":"cypher/patterns/#pattern-comprehensions","title":"Pattern Comprehensions","text":""},{"location":"cypher/patterns/#basic-comprehension","title":"Basic Comprehension","text":"<pre><code>// Collect friends into a list\nMATCH (a:Person {name: 'Alice'})\nRETURN [(a)-[:KNOWS]-&gt;(b) | b.name] as friends\n</code></pre>"},{"location":"cypher/patterns/#with-filter","title":"With Filter","text":"<pre><code>// Only active friends\nMATCH (a:Person {name: 'Alice'})\nRETURN [(a)-[:KNOWS]-&gt;(b) WHERE b.active | b.name] as activeFriends\n</code></pre>"},{"location":"cypher/patterns/#multi-element-patterns","title":"Multi-Element Patterns","text":"<pre><code>// Get friends and their companies\nMATCH (a:Person {name: 'Alice'})\nRETURN [(a)-[:KNOWS]-&gt;(b)-[:WORKS_AT]-&gt;(c) | {friend: b.name, company: c.name}] as connections\n</code></pre>"},{"location":"cypher/return-aggregation/","title":"RETURN and Aggregation","text":"<p>Transform and aggregate query results.</p>"},{"location":"cypher/return-aggregation/#return-clause","title":"RETURN Clause","text":""},{"location":"cypher/return-aggregation/#returning-nodes","title":"Returning Nodes","text":"<pre><code>MATCH (p:Person)\nRETURN p\n</code></pre>"},{"location":"cypher/return-aggregation/#returning-properties","title":"Returning Properties","text":"<pre><code>// Single property\nMATCH (p:Person)\nRETURN p.name\n\n// Multiple properties\nMATCH (p:Person)\nRETURN p.name, p.age, p.email\n</code></pre>"},{"location":"cypher/return-aggregation/#aliases","title":"Aliases","text":"<pre><code>// Using AS keyword\nMATCH (p:Person)\nRETURN p.name AS personName, p.age AS years\n\n// Implicit alias (without AS - not recommended)\nMATCH (p:Person)\nRETURN p.name personName\n</code></pre>"},{"location":"cypher/return-aggregation/#distinct-results","title":"Distinct Results","text":"<pre><code>// Remove duplicates\nMATCH (p:Person)-[:KNOWS]-&gt;(friend)\nRETURN DISTINCT friend.name\n</code></pre>"},{"location":"cypher/return-aggregation/#expressions","title":"Expressions","text":"<pre><code>// Computed values\nMATCH (p:Person)\nRETURN p.name, p.age + 1 AS nextYearAge\n\n// String concatenation\nMATCH (p:Person)\nRETURN p.firstName + ' ' + p.lastName AS fullName\n</code></pre>"},{"location":"cypher/return-aggregation/#aggregation-functions","title":"Aggregation Functions","text":""},{"location":"cypher/return-aggregation/#count","title":"COUNT","text":"<pre><code>// Count all matches\nMATCH (p:Person)\nRETURN COUNT(p) AS personCount\n\n// Count non-NULL values\nMATCH (p:Person)\nRETURN COUNT(p.email) AS withEmail\n\n// Count all rows (including NULLs)\nMATCH (p:Person)\nRETURN COUNT(*) AS total\n\n// Count distinct\nMATCH (p:Person)-[:WORKS_AT]-&gt;(c:Company)\nRETURN COUNT(DISTINCT c.name) AS companyCount\n</code></pre>"},{"location":"cypher/return-aggregation/#sum","title":"SUM","text":"<pre><code>// Total of all ages\nMATCH (p:Person)\nRETURN SUM(p.age) AS totalAge\n\n// Total salary by department\nMATCH (e:Employee)\nRETURN e.department, SUM(e.salary) AS totalSalary\n</code></pre>"},{"location":"cypher/return-aggregation/#avg","title":"AVG","text":"<pre><code>// Average age\nMATCH (p:Person)\nRETURN AVG(p.age) AS averageAge\n\n// Average by group\nMATCH (p:Person)\nRETURN p.city, AVG(p.age) AS avgAge\n</code></pre>"},{"location":"cypher/return-aggregation/#min-max","title":"MIN / MAX","text":"<pre><code>// Minimum and maximum\nMATCH (p:Person)\nRETURN MIN(p.age) AS youngest, MAX(p.age) AS oldest\n\n// By city\nMATCH (p:Person)\nRETURN p.city, MIN(p.age), MAX(p.age)\n</code></pre>"},{"location":"cypher/return-aggregation/#collect","title":"COLLECT","text":"<pre><code>// Collect into list\nMATCH (p:Person)\nRETURN COLLECT(p.name) AS allNames\n\n// Collect with filter\nMATCH (p:Person)\nWHERE p.city = 'NYC'\nRETURN COLLECT(p.name) AS nyNames\n\n// Nested collect\nMATCH (p:Person)-[:WORKS_AT]-&gt;(c:Company)\nRETURN c.name, COLLECT(p.name) AS employees\n</code></pre>"},{"location":"cypher/return-aggregation/#standard-deviation","title":"Standard Deviation","text":"<pre><code>// Sample standard deviation\nMATCH (p:Person)\nRETURN stdDev(p.age) AS ageStdDev\n\n// Population standard deviation\nMATCH (p:Person)\nRETURN stdDevP(p.age) AS agePopulationStdDev\n</code></pre>"},{"location":"cypher/return-aggregation/#percentiles","title":"Percentiles","text":"<pre><code>// Continuous percentile (interpolated)\nMATCH (p:Person)\nRETURN percentileCont(p.age, 0.5) AS medianAge\n\n// Discrete percentile (actual value)\nMATCH (p:Person)\nRETURN percentileDisc(p.age, 0.9) AS p90Age\n</code></pre>"},{"location":"cypher/return-aggregation/#grouping-results","title":"Grouping Results","text":""},{"location":"cypher/return-aggregation/#implicit-grouping","title":"Implicit Grouping","text":"<pre><code>// Group by company\nMATCH (p:Person)-[:WORKS_AT]-&gt;(c:Company)\nRETURN c.name, AVG(p.age) AS avgAge\n\n// Multiple group keys\nMATCH (p:Person)\nRETURN p.city, p.department, COUNT(*) AS count\n</code></pre>"},{"location":"cypher/return-aggregation/#with-for-pre-aggregation","title":"WITH for Pre-aggregation","text":"<pre><code>// Filter after aggregation\nMATCH (p:Person)\nWITH p.city AS city, COUNT(*) AS cityCount\nWHERE cityCount &gt; 10\nRETURN city, cityCount\n</code></pre>"},{"location":"cypher/return-aggregation/#advanced-return-patterns","title":"Advanced Return Patterns","text":""},{"location":"cypher/return-aggregation/#conditional-values","title":"Conditional Values","text":"<pre><code>// Using CASE\nMATCH (p:Person)\nRETURN p.name,\nCASE\n  WHEN p.age &lt; 18 THEN 'minor'\n  WHEN p.age &lt; 65 THEN 'adult'\n  ELSE 'senior'\nEND AS category\n</code></pre>"},{"location":"cypher/return-aggregation/#complex-expressions","title":"Complex Expressions","text":"<pre><code>// Computed columns\nMATCH (p:Person)\nRETURN\n  p.name,\n  p.age,\n  p.age * 12 AS ageInMonths,\n  date().year - p.birthYear AS calculatedAge\n</code></pre>"},{"location":"cypher/return-aggregation/#returning-maps","title":"Returning Maps","text":"<pre><code>// Create map from properties\nMATCH (p:Person)\nRETURN {\n  name: p.name,\n  age: p.age,\n  city: p.city\n} AS personMap\n</code></pre>"},{"location":"cypher/return-aggregation/#returning-paths","title":"Returning Paths","text":"<pre><code>// Return full path\nMATCH p = (a:Person)-[:KNOWS*1..3]-&gt;(b:Person)\nRETURN p, length(p) AS hops\n\n// Path nodes and relationships\nMATCH p = (a:Person)-[:KNOWS]-&gt;(b:Person)\nRETURN nodes(p) AS pathNodes, relationships(p) AS pathRels\n</code></pre>"},{"location":"cypher/return-aggregation/#common-use-cases","title":"Common Use Cases","text":""},{"location":"cypher/return-aggregation/#dashboard-metrics","title":"Dashboard Metrics","text":"<pre><code>// User statistics\nMATCH (u:User)\nRETURN\n  COUNT(*) AS totalUsers,\n  COUNT(u.verifiedEmail) AS verifiedUsers,\n  AVG(u.loginCount) AS avgLogins,\n  MAX(u.lastLogin) AS mostRecentLogin\n</code></pre>"},{"location":"cypher/return-aggregation/#reports","title":"Reports","text":"<pre><code>// Monthly signups\nMATCH (u:User)\nWITH date.truncate('month', u.createdAt) AS month, COUNT(*) AS signups\nRETURN month, signups\nORDER BY month\n</code></pre>"},{"location":"cypher/return-aggregation/#network-analysis","title":"Network Analysis","text":"<pre><code>// Most connected people\nMATCH (p:Person)\nWITH p, COUNT { (p)-[:KNOWS]-() } AS connections\nRETURN p.name, connections\nORDER BY connections DESC\nLIMIT 10\n</code></pre>"},{"location":"cypher/string-functions/","title":"String Functions","text":"<p>String manipulation functions in Cypher.</p>"},{"location":"cypher/string-functions/#case-conversion","title":"Case Conversion","text":""},{"location":"cypher/string-functions/#toupper","title":"toUpper()","text":"<pre><code>// Convert to uppercase\nRETURN toUpper('hello')  // 'HELLO'\n\n// With null\nRETURN toUpper(null)  // null\n</code></pre>"},{"location":"cypher/string-functions/#tolower","title":"toLower()","text":"<pre><code>// Convert to lowercase\nRETURN toLower('HELLO')  // 'hello'\n\n// Mixed case\nRETURN toLower('Hello World')  // 'hello world'\n</code></pre>"},{"location":"cypher/string-functions/#trimming","title":"Trimming","text":""},{"location":"cypher/string-functions/#trim","title":"trim()","text":"<pre><code>// Remove leading and trailing whitespace\nRETURN trim('  hello  ')  // 'hello'\nRETURN trim('\\thello\\n')  // 'hello'\n</code></pre>"},{"location":"cypher/string-functions/#substring-extraction","title":"Substring Extraction","text":""},{"location":"cypher/string-functions/#substring","title":"substring()","text":"<pre><code>// substring(text, start, length?)\n\n// From position 0, length 3\nRETURN substring('Hello', 0, 3)  // 'Hel'\n\n// From position 1, length 3\nRETURN substring('Hello', 1, 3)  // 'ell'\n\n// From position to end (no length)\nRETURN substring('Hello', 2)  // 'llo'\n\n// Negative start is not allowed\n// substring('Hello', -1)  // ERROR\n</code></pre>"},{"location":"cypher/string-functions/#string-splitting","title":"String Splitting","text":""},{"location":"cypher/string-functions/#split","title":"split()","text":"<pre><code>// Split by delimiter\nRETURN split('a,b,c', ',')  // ['a', 'b', 'c']\n\n// Split by space\nRETURN split('hello world', ' ')  // ['hello', 'world']\n\n// Split with empty strings\nRETURN split('a,,c', ',')  // ['a', '', 'c']\n\n// Wrong type raises error\n// RETURN split(123, ',')  // CypherExecutionError\n</code></pre>"},{"location":"cypher/string-functions/#regular-expressions","title":"Regular Expressions","text":""},{"location":"cypher/string-functions/#regex","title":"regex()","text":"<p>Returns boolean if pattern matches anywhere in string.</p> <pre><code>// Simple match\nRETURN regex('abc', 'a.c')  // true\n\n// Any character\nRETURN regex('hello', 'h.*o')  // true\n\n// Character class\nRETURN regex('abc', '[aeiou]')  // true\n\n// No match\nRETURN regex('abc', '^d')  // false\n\n// Invalid pattern raises error\n// RETURN regex('abc', '[')  // CypherExecutionError\n</code></pre>"},{"location":"cypher/string-functions/#matches","title":"matches()","text":"<p>Returns boolean for full string match (implied ^ and $).</p> <pre><code>// Full match\nRETURN matches('abc', 'abc')  // true\n\n// Pattern must match entire string\nRETURN matches('abc', 'a')  // false\nRETURN matches('abc', 'a.*')  // true\n\n// Digit pattern\nRETURN matches('123', '\\\\d+')  // true\n</code></pre>"},{"location":"cypher/string-functions/#string-concatenation","title":"String Concatenation","text":""},{"location":"cypher/string-functions/#using-operator","title":"Using + Operator","text":"<pre><code>// Concatenate with +\nWITH 'Hello' as a, 'World' as b\nRETURN a + ' ' + b  // 'Hello World'\n\n// With numbers (converted to string)\nRETURN 'Count: ' + 42  // 'Count: 42'\n</code></pre>"},{"location":"cypher/string-functions/#apoctextjoin","title":"apoc.text.join()","text":"<pre><code>// Join list with separator\nRETURN apoc.text.join(['a', 'b', 'c'], ',')  // 'a,b,c'\nRETURN apoc.text.join(['2024', '01', '15'], '-')  // '2024-01-15'\n</code></pre>"},{"location":"cypher/string-functions/#text-cleanup-functions","title":"Text Cleanup Functions","text":""},{"location":"cypher/string-functions/#deaccent","title":"deaccent()","text":"<p>Remove accents from characters.</p> <pre><code>// Remove accents\nRETURN deaccent('caf\u00e9')  // 'cafe'\nRETURN deaccent('na\u00efve')  // 'naive'\nRETURN deaccent('r\u00e9sum\u00e9')  // 'resume'\n\n// No accents = no change\nRETURN deaccent('hello')  // 'hello'\n\n// Null handling\nRETURN deaccent(null)  // null\n</code></pre>"},{"location":"cypher/string-functions/#strip_html","title":"strip_html()","text":"<p>Remove HTML tags from text.</p> <pre><code>// Strip HTML tags\nRETURN strip_html('&lt;p&gt;Hello &lt;b&gt;World&lt;/b&gt;&lt;/p&gt;')  // 'Hello World'\nRETURN strip_html('&lt;div&gt;Text&lt;/div&gt;')  // 'Text'\n\n// Already plain text = no change\nRETURN strip_html('plain text')  // 'plain text'\n\n// Null handling\nRETURN strip_html(null)  // null\n</code></pre>"},{"location":"cypher/string-functions/#strip_emoji","title":"strip_emoji()","text":"<p>Remove emoji characters from text.</p> <pre><code>// Remove emojis\nRETURN strip_emoji('Hello \ud83d\ude00 World \ud83c\udf0d')  // 'Hello  World '\nRETURN strip_emoji('Great job \ud83d\udc4d\ud83d\udc4d')  // 'Great job '\n\n// No emojis = no change\nRETURN strip_emoji('Hello World')  // 'Hello World'\n\n// Null handling\nRETURN strip_emoji(null)  // null\n</code></pre>"},{"location":"cypher/string-functions/#snake_case","title":"snake_case()","text":"<p>Convert text to snake_case format.</p> <pre><code>// Convert to snake_case\nRETURN snake_case('Hello World')  // 'hello_world'\nRETURN snake_case('helloWorld')  // 'hello_world'\nRETURN snake_case('HelloWorld')  // 'hello_world'\nRETURN snake_case('hello-world')  // 'hello_world'\nRETURN snake_case('hello_world')  // 'hello_world'\n\n// Multiple words\nRETURN snake_case('The Quick Brown Fox')  // 'the_quick_brown_fox'\n\n// Null handling\nRETURN snake_case(null)  // null\n</code></pre>"},{"location":"cypher/string-functions/#text-similarity-functions","title":"Text Similarity Functions","text":""},{"location":"cypher/string-functions/#levenshtein","title":"levenshtein()","text":"<p>Calculate Levenshtein (edit) distance between two strings.</p> <pre><code>// Exact match\nRETURN levenshtein('hello', 'hello')  // 0\n\n// One character different\nRETURN levenshtein('hello', 'hallo')  // 1\n\n// Two edits needed\nRETURN levenshtein('kitten', 'sitting')  // 3\n\n// Case sensitive\nRETURN levenshtein('Hello', 'hello')  // 1\n\n// Use with deaccent for fuzzy matching\nRETURN levenshtein(deaccent('caf\u00e9'), 'cafe')  // 0\n\n// Null handling\nRETURN levenshtein(null, 'hello')  // null\nRETURN levenshtein('hello', null)  // null\n</code></pre> <p>Common use case - fuzzy search:</p> <pre><code>// Find similar names\nMATCH (p:Person)\nWHERE levenshtein(deaccent(p.name), 'john') &lt;= 2\nRETURN p.name\n</code></pre>"},{"location":"cypher/string-functions/#jaccard","title":"jaccard()","text":"<p>Calculate Jaccard similarity coefficient between two strings (based on character bigrams).</p> <pre><code>// Similar strings\nRETURN jaccard('hello', 'hello')  // 1.0\nRETURN jaccard('hello', 'hallo')  // ~0.6\n\n// Different strings\nRETURN jaccard('hello', 'world')  // 0.0\n\n// Partial similarity\nRETURN jaccard('night', 'nacht')  // ~0.3\n\n// Null handling\nRETURN jaccard(null, 'hello')  // null\n</code></pre> <p>Use for similarity matching:</p> <pre><code>// Find potential duplicates\nMATCH (p1:Person), (p2:Person)\nWHERE p1.id &lt; p2.id\n  AND jaccard(p1.name, p2.name) &gt; 0.8\nRETURN p1.name, p2.name, jaccard(p1.name, p2.name) as similarity\n</code></pre>"},{"location":"cypher/string-functions/#string-inspection","title":"String Inspection","text":""},{"location":"cypher/string-functions/#size-with-strings","title":"size() with Strings","text":"<pre><code>// String length\nRETURN size('Hello')  // 5\nRETURN size('')  // 0\n</code></pre>"},{"location":"cypher/string-functions/#starts-with-ends-with-contains","title":"starts WITH / ends WITH / contains","text":"<p>In WHERE clause:</p> <pre><code>// Starts with\nMATCH (p:Person)\nWHERE p.name STARTS WITH 'Al'\nRETURN p.name\n\n// Ends with\nMATCH (p:Person)\nWHERE p.email ENDS WITH '@company.com'\nRETURN p.name\n\n// Contains\nMATCH (p:Person)\nWHERE p.bio CONTAINS 'engineer'\nRETURN p.name\n</code></pre>"},{"location":"cypher/string-functions/#apoc-string-functions","title":"APOC String Functions","text":""},{"location":"cypher/string-functions/#replace","title":"Replace","text":"<pre><code>RETURN apoc.text.replace('hello-world', '-', '_')  // 'hello_world'\n</code></pre>"},{"location":"cypher/string-functions/#error-handling","title":"Error Handling","text":"<p>All string functions return <code>null</code> for <code>null</code> input:</p> <pre><code>RETURN toUpper(null)      // null\nRETURN trim(null)         // null\nRETURN substring(null, 0) // null\nRETURN split(null, ',')   // null\nRETURN deaccent(null)     // null\nRETURN strip_html(null)   // null\nRETURN strip_emoji(null)  // null\nRETURN snake_case(null)   // null\nRETURN levenshtein(null, 'a')  // null\nRETURN jaccard(null, 'a')    // null\n</code></pre> <p>Invalid argument types raise <code>CypherExecutionError</code>:</p> <pre><code>// These raise errors:\nRETURN substring('abc', 0, -1)  // Negative length\nRETURN split(123, ',')          // Number instead of string\nRETURN regex('abc', '[')        // Invalid regex pattern\n</code></pre>"},{"location":"cypher/string-functions/#common-use-cases","title":"Common Use Cases","text":""},{"location":"cypher/string-functions/#normalizing-input","title":"Normalizing Input","text":"<pre><code>// Clean user input for search\nWITH '  John DOE  ' as raw\nRETURN snake_case(deaccent(trim(raw))) as clean\n// 'john_doe'\n</code></pre>"},{"location":"cypher/string-functions/#email-domain-extraction","title":"Email Domain Extraction","text":"<pre><code>WITH 'alice@company.com' as email\nRETURN split(email, '@')[1] as domain\n// 'company.com'\n</code></pre>"},{"location":"cypher/string-functions/#name-formatting","title":"Name Formatting","text":"<pre><code>// Format: Last, First\nMATCH (p:Person)\nRETURN substring(p.lastName, 0, 1) + '. ' + p.firstName as display\n</code></pre>"},{"location":"cypher/string-functions/#fuzzy-matching","title":"Fuzzy Matching","text":"<pre><code>// Find similar names with multiple strategies\nMATCH (p:Person)\nWITH p, deaccent(p.name) as normalized\nWHERE levenshtein(normalized, 'johnson') &lt;= 2\n   OR jaccard(normalized, 'johnson') &gt; 0.7\nRETURN p.name\n</code></pre>"},{"location":"cypher/string-functions/#content-cleaning","title":"Content Cleaning","text":"<pre><code>// Clean article content for indexing\nMATCH (a:Article)\nSET a.clean_content = strip_emoji(strip_html(a.raw_content))\n</code></pre>"},{"location":"cypher/string-functions/#duplicate-detection","title":"Duplicate Detection","text":"<pre><code>// Find potential duplicate companies\nMATCH (c1:Company), (c2:Company)\nWHERE c1.id &lt; c2.id\n  AND jaccard(\n    snake_case(deaccent(c1.name)),\n    snake_case(deaccent(c2.name))\n  ) &gt; 0.85\nRETURN c1.name, c2.name\n</code></pre>"},{"location":"cypher/temporal-spatial/","title":"Temporal and Spatial Types","text":"<p>Working with time and space in Cypher.</p>"},{"location":"cypher/temporal-spatial/#temporal-types","title":"Temporal Types","text":""},{"location":"cypher/temporal-spatial/#date","title":"Date","text":"<pre><code>// Create date\nRETURN date('2024-01-15') as d\n\n// From components\nRETURN date({year: 2024, month: 1, day: 15}) as d\n\n// Current date\nRETURN date() as today\n</code></pre>"},{"location":"cypher/temporal-spatial/#time","title":"Time","text":"<pre><code>// Create time\nRETURN time('14:30:00') as t\nRETURN time('14:30:00.123') as t\nRETURN time('14:30:00+01:00') as t  // with timezone\n</code></pre>"},{"location":"cypher/temporal-spatial/#datetime","title":"DateTime","text":"<pre><code>// Full datetime\nRETURN datetime('2024-01-15T14:30:00') as dt\n\n// With timezone\nRETURN datetime('2024-01-15T14:30:00Z') as dt  // UTC\nRETURN datetime('2024-01-15T14:30:00+05:00') as dt\n\n// Current datetime\nRETURN datetime() as now\n</code></pre>"},{"location":"cypher/temporal-spatial/#localdatetime","title":"LocalDateTime","text":"<pre><code>// Without timezone\nRETURN localdatetime('2024-01-15T14:30:00') as ldt\n</code></pre>"},{"location":"cypher/temporal-spatial/#duration","title":"Duration","text":"<pre><code>// ISO duration format\nRETURN duration('P1Y2M3DT4H5M6S') as dur  // 1 year, 2 months, 3 days, 4 hours...\nRETURN duration('P1D') as oneDay\nRETURN duration('PT2H30M') as twoHalfHours\n\n// From components\nRETURN duration({days: 1, hours: 2}) as dur\n</code></pre>"},{"location":"cypher/temporal-spatial/#temporal-operations","title":"Temporal Operations","text":""},{"location":"cypher/temporal-spatial/#comparisons","title":"Comparisons","text":"<pre><code>// Compare dates\nWITH date('2024-01-15') as d1, date('2024-01-20') as d2\nRETURN d1 &lt; d2  // true\n\n// Range queries\nMATCH (p:Person)\nWHERE p.birthday &gt;= date('1990-01-01')\n  AND p.birthday &lt;= date('1999-12-31')\nRETURN p.name\n</code></pre>"},{"location":"cypher/temporal-spatial/#arithmetic","title":"Arithmetic","text":"<pre><code>// Add duration to date\nRETURN date('2024-01-15') + duration('P1M')  // 2024-02-15\n\n// Subtract from datetime\nRETURN datetime() - duration('P7D')  // 1 week ago\n\n// Duration between dates\nRETURN duration.between(\n  date('2024-01-01'),\n  date('2024-01-15')\n)  // P14D\n</code></pre>"},{"location":"cypher/temporal-spatial/#truncation","title":"Truncation","text":"<pre><code>// Truncate to year/month/day\nRETURN date.truncate('year', date('2024-06-15'))   // 2024-01-01\nRETURN date.truncate('month', date('2024-06-15'))  // 2024-06-01\n\n// Truncate datetime\nRETURN datetime.truncate('hour', datetime())  // Current hour, minute=0, second=0\n</code></pre>"},{"location":"cypher/temporal-spatial/#accessing-components","title":"Accessing Components","text":"<pre><code>WITH date('2024-01-15') as d\nRETURN d.year   // 2024\nRETURN d.month  // 1\nRETURN d.day    // 15\nRETURN d.week   // 3 (week of year)\nRETURN d.dayOfWeek  // 1 (Monday)\nRETURN d.quarter    // 1\n</code></pre>"},{"location":"cypher/temporal-spatial/#converting-between-types","title":"Converting Between Types","text":"<pre><code>// Date to datetime\nRETURN datetime(date('2024-01-15'))  // 2024-01-15T00:00:00\n\n// Datetime to date\nRETURN date(datetime('2024-01-15T14:30:00'))  // 2024-01-15\n\n// String to temporal\nRETURN date('2024-01-15')\nRETURN time('14:30:00')\n</code></pre>"},{"location":"cypher/temporal-spatial/#spatial-types","title":"Spatial Types","text":""},{"location":"cypher/temporal-spatial/#point-2d","title":"Point (2D)","text":"<pre><code>// Create point with x, y\nRETURN point({x: 10, y: 20}) as p\n\n// Create geographic point\nRETURN point({longitude: -74.006, latitude: 40.7128}) as nyc\n</code></pre>"},{"location":"cypher/temporal-spatial/#distance","title":"Distance","text":"<pre><code>// Euclidean distance\nWITH point({x: 0, y: 0}) as p1, point({x: 3, y: 4}) as p2\nRETURN distance(p1, p2)  // 5.0\n\n// Geographic distance (in meters)\nWITH\n  point({longitude: -74.006, latitude: 40.7128}) as nyc,\n  point({longitude: -118.2437, latitude: 34.0522}) as la\nRETURN distance(nyc, la) as meters\n</code></pre>"},{"location":"cypher/temporal-spatial/#accessing-components_1","title":"Accessing Components","text":"<pre><code>WITH point({x: 10, y: 20}) as p\nRETURN p.x, p.y\n\nWITH point({longitude: -74.006, latitude: 40.7128}) as p\nRETURN p.longitude, p.latitude\n</code></pre>"},{"location":"cypher/temporal-spatial/#common-use-cases","title":"Common Use Cases","text":""},{"location":"cypher/temporal-spatial/#age-calculation","title":"Age Calculation","text":"<pre><code>MATCH (p:Person)\nRETURN p.name,\n       duration.between(p.birthday, date()).years as age\n</code></pre>"},{"location":"cypher/temporal-spatial/#recent-activity","title":"Recent Activity","text":"<pre><code>// Users active in last 7 days\nMATCH (u:User)\nWHERE u.lastLogin &gt; datetime() - duration('P7D')\nRETURN u.name\n</code></pre>"},{"location":"cypher/temporal-spatial/#geographic-search","title":"Geographic Search","text":"<pre><code>// Find locations within radius\nMATCH (store:Store)\nWITH store, point({longitude: store.lon, latitude: store.lat}) as storePoint\nWITH store, storePoint,\n     point({longitude: -74.006, latitude: 40.7128}) as center\nWHERE distance(storePoint, center) &lt; 5000  // within 5km\nRETURN store.name\n</code></pre>"},{"location":"cypher/temporal-spatial/#time-based-aggregation","title":"Time-Based Aggregation","text":"<pre><code>// Group by month\nMATCH (o:Order)\nWITH date.truncate('month', o.createdAt) as month, count(*) as orders\nRETURN month, orders\nORDER BY month\n</code></pre>"},{"location":"cypher/vector-search/","title":"Vector Search in Cypher","text":"<p>Perform semantic search using Cypher procedures.</p>"},{"location":"cypher/vector-search/#vector-search-procedure","title":"Vector Search Procedure","text":"<pre><code>CALL db.vector.search(\n    index_name,      // Name of vector index\n    query_vector,    // Vector to search for\n    k,               // Number of results\n    options          // Optional configuration\n)\nYIELD node, score\n</code></pre>"},{"location":"cypher/vector-search/#basic-vector-search","title":"Basic Vector Search","text":"<pre><code>from grafito.cypher import format_vector_literal\n\n# Prepare query vector\nquery_vec = model.encode(\"python graph database\").tolist()\nvector_literal = format_vector_literal(query_vec, precision=8)\n\n# Run vector search\ncypher = f\"\"\"\n    CALL db.vector.search('articles_vec', {vector_literal}, 10)\n    YIELD node, score\n    RETURN node.title, node.content, score\n    ORDER BY score DESC\n\"\"\"\n\nresults = db.execute(cypher)\n</code></pre>"},{"location":"cypher/vector-search/#with-label-filters","title":"With Label Filters","text":"<pre><code>// Search only within specific labels\nCALL db.vector.search(\n    'articles_vec',\n    [0.123, -0.456, ...],\n    10,\n    {labels: ['Article', 'Tutorial']}\n)\nYIELD node, score\nRETURN node.title, score\n</code></pre>"},{"location":"cypher/vector-search/#with-property-filters","title":"With Property Filters","text":"<pre><code>// Search with property constraints\nCALL db.vector.search(\n    'articles_vec',\n    [0.123, -0.456, ...],\n    10,\n    {\n        labels: ['Article'],\n        properties: {published: true, language: 'en'}\n    }\n)\nYIELD node, score\nRETURN node.title, score\n</code></pre>"},{"location":"cypher/vector-search/#with-reranking","title":"With Reranking","text":"<pre><code>// Enable reranking with stored vectors\nCALL db.vector.search(\n    'articles_vec',\n    [0.123, -0.456, ...],\n    10,\n    {rerank: true, candidate_multiplier: 3}\n)\nYIELD node, score\nRETURN node.title, score\n</code></pre>"},{"location":"cypher/vector-search/#custom-reranker","title":"Custom Reranker","text":"<pre><code># Register custom reranker\ndef my_reranker(query_vector, candidates):\n    # candidates: [{\"id\": int, \"vector\": [...], \"score\": float, \"node\": Node}, ...]\n    re_ranked = []\n    for c in candidates:\n        # Custom scoring logic\n        boost = 1.0\n        if 'featured' in c['node'].labels:\n            boost = 1.2\n        re_ranked.append({\n            'id': c['id'],\n            'score': c['score'] * boost\n        })\n    return re_ranked\n\ndb.register_reranker('featured_boost', my_reranker)\n</code></pre> <pre><code>// Use in Cypher\nCALL db.vector.search(\n    'articles_vec',\n    [0.123, -0.456, ...],\n    10,\n    {reranker: 'featured_boost'}\n)\nYIELD node, score\nRETURN node.title, score\n</code></pre>"},{"location":"cypher/vector-search/#combining-with-graph-patterns","title":"Combining with Graph Patterns","text":"<pre><code># Hybrid: vector search + graph traversal\nquery_vec = model.encode(\"machine learning tutorials\").tolist()\nvector_literal = format_vector_literal(query_vec)\n\ncypher = f\"\"\"\n    // Stage 1: Vector search for candidates\n    CALL db.vector.search('articles_vec', {vector_literal}, 20)\n    YIELD node, score\n\n    // Stage 2: Expand to authors\n    MATCH (node)&lt;-[:AUTHORED]-(author:Person)\n\n    // Stage 3: Get author's other content\n    OPTIONAL MATCH (author)-[:AUTHORED]-&gt;(other:Article)\n    WHERE other &lt;&gt; node\n\n    RETURN \n        node.title as matched_article,\n        score,\n        author.name as author,\n        collect(DISTINCT other.title)[0..3] as other_works\n    ORDER BY score DESC\n    LIMIT 10\n\"\"\"\n\nresults = db.execute(cypher)\n</code></pre>"},{"location":"cypher/vector-search/#with-path-expansion","title":"With Path Expansion","text":"<pre><code>// Vector search + related content\nCALL db.vector.search('articles_vec', $query_vec, 5)\nYIELD node, score\n\n// Find related articles through shared tags\nMATCH (node)-[:TAGGED]-&gt;(tag)&lt;-[:TAGGED]-(related)\nWHERE related &lt;&gt; node\n\nRETURN \n    node.title as main_result,\n    score,\n    collect(DISTINCT related.title)[0..5] as related_articles\nORDER BY score DESC\n</code></pre>"},{"location":"cypher/vector-search/#aggregating-vector-results","title":"Aggregating Vector Results","text":"<pre><code>// Cluster search results by category\nCALL db.vector.search('articles_vec', $query_vec, 50)\nYIELD node, score\n\nWITH node.category as category, \n     collect({node: node, score: score}) as items,\n     avg(score) as avg_score\n\nRETURN \n    category,\n    count(*) as count,\n    avg_score,\n    items[0..3] as top_items\nORDER BY avg_score DESC\n</code></pre>"},{"location":"cypher/vector-search/#dynamic-vector-queries","title":"Dynamic Vector Queries","text":"<pre><code># Build vector queries dynamically\ndef vector_search_with_context(db, query, user_id, k=10):\n    # Get user's interests\n    interests = db.execute(\"\"\"\n        MATCH (u:User {id: $user_id})-[:INTERESTED_IN]-&gt;(topic)\n        RETURN collect(topic.name) as interests\n    \"\"\", {'user_id': user_id})\n\n    # Build enriched query\n    enriched_query = query + ' ' + ' '.join(interests[0]['interests'])\n    query_vec = model.encode(enriched_query).tolist()\n\n    # Search with personalization boost\n    return db.execute(\"\"\"\n        CALL db.vector.search('articles_vec', $vec, $k)\n        YIELD node, score\n\n        // Boost if matches user interests\n        OPTIONAL MATCH (node)-[:ABOUT]-&gt;(topic)\n        WHERE topic.name IN $interests\n\n        WITH node, score, count(topic) as interest_matches\n        ORDER BY score + (interest_matches * 0.1) DESC\n\n        RETURN node.title, node.summary, score\n        LIMIT $k\n    \"\"\", {'vec': query_vec, 'k': k, 'interests': interests[0]['interests']})\n</code></pre>"},{"location":"cypher/vector-search/#error-handling","title":"Error Handling","text":""},{"location":"cypher/vector-search/#unknown-index","title":"Unknown Index","text":"<pre><code>DatabaseError: Vector index 'unknown_idx' not found\n</code></pre> <p>Solution: Check index name with <code>SHOW INDEXES</code> or <code>db.list_vector_indexes()</code>.</p>"},{"location":"cypher/vector-search/#dimension-mismatch","title":"Dimension Mismatch","text":"<pre><code>DatabaseError: Query vector dimension 768 does not match index dimension 384\n</code></pre> <p>Solution: Ensure query vector has same dimension as index.</p>"},{"location":"cypher/vector-search/#unknown-reranker","title":"Unknown Reranker","text":"<pre><code>CypherExecutionError: Unknown reranker 'invalid_name'\n</code></pre> <p>Solution: Register reranker first with <code>db.register_reranker()</code>.</p>"},{"location":"cypher/vector-search/#best-practices","title":"Best Practices","text":""},{"location":"cypher/vector-search/#use-precision-parameter","title":"Use Precision Parameter","text":"<pre><code># Format vector for Cypher with appropriate precision\nvector_literal = format_vector_literal(query_vec, precision=6)\n# Higher precision = more accurate but longer query string\n</code></pre>"},{"location":"cypher/vector-search/#limit-initial-results","title":"Limit Initial Results","text":"<pre><code>// Get more candidates than needed for reranking\nCALL db.vector.search('idx', $vec, 50)  // Get 50\nYIELD node, score\n// ... filter/process ...\nRETURN ...\nLIMIT 10  // Return top 10\n</code></pre>"},{"location":"cypher/vector-search/#combine-with-property-indexes","title":"Combine with Property Indexes","text":"<pre><code># Create property index for common filters\ndb.create_node_index('Article', 'published')\ndb.create_node_index('Article', 'language')\n\n# Vector search will use these for pre-filtering\n</code></pre>"},{"location":"cypher/vector-search/#cache-query-embeddings","title":"Cache Query Embeddings","text":"<pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=1000)\ndef get_query_embedding(query):\n    return model.encode(query).tolist()\n\n# Reuse embeddings for repeated queries\nvec = get_query_embedding(\"python graphql\")\n</code></pre>"},{"location":"embeddings/cloud-providers/","title":"Cloud Provider Embeddings","text":"<p>Grafito supports multiple managed embedding APIs. Each provider has its own SDK or HTTP requirements, but all integrate via <code>EmbeddingFunction</code>.</p>"},{"location":"embeddings/cloud-providers/#aws-bedrock","title":"AWS Bedrock","text":""},{"location":"embeddings/cloud-providers/#installation","title":"Installation","text":"<pre><code>pip install boto3\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import AmazonBedrockEmbeddingFunction\n\nembed_fn = AmazonBedrockEmbeddingFunction(\n    model_name=\"amazon.titan-embed-text-v1\",\n    region_name=\"us-east-1\"\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#configuration","title":"Configuration","text":"<p>You can pass AWS credentials directly or rely on the standard AWS credential chain. Extra client arguments are forwarded to <code>boto3.Session(...).client(...)</code>.</p> <pre><code>embed_fn = AmazonBedrockEmbeddingFunction(\n    model_name=\"amazon.titan-embed-text-v1\",\n    profile_name=\"default\",\n    region_name=\"us-east-1\",\n    retries={\"max_attempts\": 5}\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#google-genai","title":"Google GenAI","text":""},{"location":"embeddings/cloud-providers/#installation_1","title":"Installation","text":"<pre><code>pip install google-genai\n</code></pre>"},{"location":"embeddings/cloud-providers/#api-key","title":"API Key","text":"<pre><code>export GOOGLE_API_KEY=\"...\"\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import GoogleGenAIEmbeddingFunction\n\nembed_fn = GoogleGenAIEmbeddingFunction(\n    model_name=\"text-embedding-004\"\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#vertex-ai-configuration","title":"Vertex AI Configuration","text":"<pre><code>embed_fn = GoogleGenAIEmbeddingFunction(\n    model_name=\"text-embedding-004\",\n    vertexai=True,\n    project=\"my-gcp-project\",\n    location=\"us-central1\"\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#cohere","title":"Cohere","text":""},{"location":"embeddings/cloud-providers/#installation_2","title":"Installation","text":"<pre><code>pip install httpx\n</code></pre>"},{"location":"embeddings/cloud-providers/#api-key_1","title":"API Key","text":"<pre><code>export COHERE_API_KEY=\"...\"\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage_2","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import CohereEmbeddingFunction\n\nembed_fn = CohereEmbeddingFunction(\n    model=\"embed-english-v3.0\",\n    input_type=\"search_document\"\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#notes","title":"Notes","text":"<ul> <li><code>input_type</code> can be adjusted depending on whether you're embedding documents   or queries.</li> </ul>"},{"location":"embeddings/cloud-providers/#jina-ai","title":"Jina AI","text":""},{"location":"embeddings/cloud-providers/#installation_3","title":"Installation","text":"<pre><code>pip install httpx\n</code></pre>"},{"location":"embeddings/cloud-providers/#api-key_2","title":"API Key","text":"<pre><code>export JINA_API_KEY=\"...\"\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage_3","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import JinaEmbeddingFunction\n\nembed_fn = JinaEmbeddingFunction(\n    model_name=\"jina-embeddings-v2-base-en\",\n    task=\"retrieval.passage\",\n    normalized=True\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#query-embeddings","title":"Query Embeddings","text":"<p>Jina supports a separate query embedding path:</p> <pre><code>query_vecs = embed_fn.embed_query([\"graph database performance\"])  # type: ignore[attr-defined]\n</code></pre>"},{"location":"embeddings/cloud-providers/#mistral","title":"Mistral","text":""},{"location":"embeddings/cloud-providers/#installation_4","title":"Installation","text":"<pre><code>pip install mistralai\n</code></pre>"},{"location":"embeddings/cloud-providers/#api-key_3","title":"API Key","text":"<pre><code>export MISTRAL_API_KEY=\"...\"\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage_4","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import MistralEmbeddingFunction\n\nembed_fn = MistralEmbeddingFunction(model=\"mistral-embed\")\n</code></pre>"},{"location":"embeddings/cloud-providers/#together-ai","title":"Together AI","text":""},{"location":"embeddings/cloud-providers/#installation_5","title":"Installation","text":"<pre><code>pip install httpx\n</code></pre>"},{"location":"embeddings/cloud-providers/#api-key_4","title":"API Key","text":"<pre><code>export TOGETHER_API_KEY=\"...\"\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage_5","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import TogetherAIEmbeddingFunction\n\nembed_fn = TogetherAIEmbeddingFunction(\n    model_name=\"togethercomputer/m2-bert-80M-8k-retrieval\"\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#voyage-ai","title":"Voyage AI","text":""},{"location":"embeddings/cloud-providers/#installation_6","title":"Installation","text":"<pre><code>pip install voyageai\n</code></pre>"},{"location":"embeddings/cloud-providers/#api-key_5","title":"API Key","text":"<pre><code>export VOYAGE_API_KEY=\"...\"\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage_6","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import VoyageAIEmbeddingFunction\n\nembed_fn = VoyageAIEmbeddingFunction(\n    model_name=\"voyage-large-2\",\n    input_type=\"document\",\n    truncation=True\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#tensorflow-hub","title":"TensorFlow Hub","text":"<p>TensorFlow Hub models can be used through a local embedding function.</p>"},{"location":"embeddings/cloud-providers/#installation_7","title":"Installation","text":"<pre><code>pip install tensorflow_hub\n</code></pre>"},{"location":"embeddings/cloud-providers/#basic-usage_7","title":"Basic Usage","text":"<pre><code>from grafito.embedding_functions import TensorFlowHubEmbeddingFunction\n\nembed_fn = TensorFlowHubEmbeddingFunction(\n    model_url=\"https://tfhub.dev/google/universal-sentence-encoder/4\"\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#using-any-provider-with-grafito","title":"Using Any Provider with Grafito","text":"<pre><code>from grafito import GrafitoDatabase\n\n# embed_fn = ...\n\ndb = GrafitoDatabase(\":memory:\")\ndb.create_vector_index(\n    name=\"content_vec\",\n    dim=768,\n    embedding_function=embed_fn\n)\n</code></pre>"},{"location":"embeddings/cloud-providers/#next-steps","title":"Next Steps","text":"<ul> <li>Overview - Embedding concepts and workflows</li> <li>OpenAI - OpenAI embeddings</li> <li>Hugging Face - HF Inference API and local models</li> <li>Ollama - Local embeddings with Ollama</li> </ul>"},{"location":"embeddings/huggingface/","title":"Hugging Face Embeddings","text":"<p>Grafito supports Hugging Face embeddings through two paths:</p> <ul> <li>Hugging Face Inference API: hosted models via HTTP.</li> <li>Sentence Transformers (Local): run models locally with <code>sentence-transformers</code>.</li> </ul> <p>Both integrate with Grafito's vector indexes in the same way.</p>"},{"location":"embeddings/huggingface/#hugging-face-inference-api","title":"Hugging Face Inference API","text":""},{"location":"embeddings/huggingface/#installation","title":"Installation","text":"<pre><code>pip install httpx\n</code></pre>"},{"location":"embeddings/huggingface/#api-token","title":"API Token","text":"<p>Grafito will read the API token from any of the following environment variables (in order):</p> <ul> <li><code>HF_TOKEN</code></li> <li><code>HUGGINGFACE_HUB_TOKEN</code></li> <li><code>HUGGINGFACEHUB_API_TOKEN</code></li> <li><code>HUGGINGFACE_API_KEY</code></li> </ul> <pre><code>export HF_TOKEN=\"hf_...\"\n</code></pre>"},{"location":"embeddings/huggingface/#basic-usage","title":"Basic Usage","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.embedding_functions import HuggingFaceEmbeddingFunction\n\nembed_fn = HuggingFaceEmbeddingFunction(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n)\n\ndb = GrafitoDatabase(\":memory:\")\ndb.create_vector_index(\n    name=\"docs_vec\",\n    dim=384,\n    embedding_function=embed_fn\n)\n\nnode = db.create_node(labels=[\"Doc\"], properties={\"text\": \"Graph search\"})\ndb.upsert_embedding(node_id=node.id, text=\"Graph search\", index=\"docs_vec\")\n</code></pre>"},{"location":"embeddings/huggingface/#configuration","title":"Configuration","text":"<pre><code>embed_fn = HuggingFaceEmbeddingFunction(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    api_key_env_var=\"MY_HF_TOKEN\"\n)\n</code></pre>"},{"location":"embeddings/huggingface/#sentence-transformers-local","title":"Sentence Transformers (Local)","text":"<p>Use local inference with the <code>sentence_transformers</code> library.</p>"},{"location":"embeddings/huggingface/#installation_1","title":"Installation","text":"<pre><code>pip install sentence_transformers\n</code></pre>"},{"location":"embeddings/huggingface/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.embedding_functions import SentenceTransformerEmbeddingFunction\n\nembed_fn = SentenceTransformerEmbeddingFunction(\n    model_name=\"all-MiniLM-L6-v2\",\n    device=\"cpu\",\n    normalize_embeddings=False\n)\n\ndb = GrafitoDatabase(\":memory:\")\ndb.create_vector_index(\n    name=\"docs_vec\",\n    dim=384,\n    embedding_function=embed_fn\n)\n</code></pre>"},{"location":"embeddings/huggingface/#advanced-configuration","title":"Advanced Configuration","text":"<p><code>SentenceTransformerEmbeddingFunction</code> accepts extra keyword arguments passed to <code>SentenceTransformer(...)</code> (only primitive JSON-like types are allowed):</p> <pre><code>embed_fn = SentenceTransformerEmbeddingFunction(\n    model_name=\"all-MiniLM-L6-v2\",\n    device=\"cpu\",\n    normalize_embeddings=True,\n    trust_remote_code=False\n)\n</code></pre>"},{"location":"embeddings/huggingface/#notes","title":"Notes","text":"<ul> <li>The embedding dimension is derived from the model if available.</li> <li><code>normalize_embeddings=True</code> is useful when you rely on cosine similarity.</li> </ul>"},{"location":"embeddings/huggingface/#next-steps","title":"Next Steps","text":"<ul> <li>Cloud Providers - Managed embedding APIs</li> <li>Ollama - Local embeddings via Ollama</li> <li>Overview - General embedding concepts</li> </ul>"},{"location":"embeddings/ollama/","title":"Ollama Embeddings (Local)","text":"<p>Grafito can generate embeddings locally using the Ollama embeddings API. This is ideal for offline or privacy-sensitive workloads.</p>"},{"location":"embeddings/ollama/#requirements","title":"Requirements","text":"<ul> <li>Ollama installed and running on your machine</li> <li>An embeddings-capable model pulled locally (for example: <code>nomic-embed-text</code>)</li> </ul>"},{"location":"embeddings/ollama/#installation","title":"Installation","text":"<pre><code>pip install httpx\n</code></pre>"},{"location":"embeddings/ollama/#basic-usage","title":"Basic Usage","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.embedding_functions import OllamaEmbeddingFunction\n\nembed_fn = OllamaEmbeddingFunction(\n    model=\"nomic-embed-text\"\n)\n\ndb = GrafitoDatabase(\":memory:\")\ndb.create_vector_index(\n    name=\"docs_vec\",\n    dim=768,\n    embedding_function=embed_fn\n)\n\nnode = db.create_node(labels=[\"Doc\"], properties={\"text\": \"Local embeddings\"})\ndb.upsert_embedding(node_id=node.id, text=\"Local embeddings\", index=\"docs_vec\")\n</code></pre>"},{"location":"embeddings/ollama/#custom-host-remote-ollama","title":"Custom Host / Remote Ollama","text":"<p>By default, Grafito uses <code>http://localhost:11434</code> or the <code>OLLAMA_HOST</code> environment variable if set.</p> <pre><code>export OLLAMA_HOST=\"http://localhost:11434\"\n</code></pre> <pre><code>embed_fn = OllamaEmbeddingFunction(\n    model=\"nomic-embed-text\",\n    base_url=\"http://localhost:11434\"\n)\n</code></pre>"},{"location":"embeddings/ollama/#notes","title":"Notes","text":"<ul> <li>The embedding dimension depends on the model you choose.</li> <li>Ollama generates embeddings one input at a time; batch large datasets carefully.</li> </ul>"},{"location":"embeddings/ollama/#next-steps","title":"Next Steps","text":"<ul> <li>Overview - Embedding concepts and workflows</li> <li>Hugging Face - Local Sentence Transformers</li> <li>Cloud Providers - Managed embedding APIs</li> </ul>"},{"location":"embeddings/openai/","title":"OpenAI Embeddings","text":"<p>Grafito integrates with OpenAI's embedding API to generate high-quality vector representations of text.</p>"},{"location":"embeddings/openai/#overview","title":"Overview","text":"<p>OpenAI provides state-of-the-art embedding models that are: - High quality: Trained on diverse internet text - Multilingual: Support for 100+ languages - Cost-effective: Competitive pricing per token - Well-documented: Extensive community support</p>"},{"location":"embeddings/openai/#supported-models","title":"Supported Models","text":"Model Dimensions Context Window Best For <code>text-embedding-3-small</code> 1536 8192 General use, cost-effective <code>text-embedding-3-large</code> 3072 8192 Maximum quality <code>text-embedding-ada-002</code> 1536 8192 Legacy model"},{"location":"embeddings/openai/#setup","title":"Setup","text":""},{"location":"embeddings/openai/#installation","title":"Installation","text":"<pre><code>pip install grafito[openai]\n# or\npip install httpx\n</code></pre>"},{"location":"embeddings/openai/#api-key-configuration","title":"API Key Configuration","text":"<pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre> <p>Or provide explicitly:</p> <pre><code>from grafito.embedding_functions import OpenAIEmbeddingFunction\n\nembed_fn = OpenAIEmbeddingFunction(\n    api_key=\"sk-...\"\n)\n</code></pre>"},{"location":"embeddings/openai/#basic-usage","title":"Basic Usage","text":""},{"location":"embeddings/openai/#initialize-embedding-function","title":"Initialize Embedding Function","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.embedding_functions import OpenAIEmbeddingFunction\n\n# Using default model (text-embedding-3-small)\nembed_fn = OpenAIEmbeddingFunction()\n\n# Or specify a model\nembed_fn = OpenAIEmbeddingFunction(\n    model=\"text-embedding-3-large\"\n)\n</code></pre>"},{"location":"embeddings/openai/#create-vector-index","title":"Create Vector Index","text":"<pre><code>db = GrafitoDatabase(\":memory:\")\n\n# Create index with OpenAI embedding function\ndb.create_vector_index(\n    name=\"documents_vec\",\n    dim=1536,  # text-embedding-3-small\n    embedding_function=embed_fn\n)\n</code></pre>"},{"location":"embeddings/openai/#generate-embeddings","title":"Generate Embeddings","text":"<pre><code># Create a document\ndoc = db.create_node(\n    labels=[\"Document\"],\n    properties={\"title\": \"Getting Started with Graph Databases\"}\n)\n\n# Generate embedding from text\ndb.upsert_embedding(\n    node_id=doc.id,\n    text=\"Getting Started with Graph Databases\",\n    index=\"documents_vec\"\n)\n</code></pre>"},{"location":"embeddings/openai/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"embeddings/openai/#custom-environment-variable","title":"Custom Environment Variable","text":"<pre><code># Use a custom environment variable for the API key\nembed_fn = OpenAIEmbeddingFunction(\n    api_key_env_var=\"MY_OPENAI_KEY\"\n)\n</code></pre> <p>Then set: <pre><code>export MY_OPENAI_KEY=\"sk-...\"\n</code></pre></p>"},{"location":"embeddings/openai/#custom-base-url","title":"Custom Base URL","text":"<p>For using a proxy or Azure OpenAI:</p> <pre><code>embed_fn = OpenAIEmbeddingFunction(\n    model=\"text-embedding-3-small\",\n    base_url=\"https://your-proxy.com/v1/embeddings\"\n)\n</code></pre>"},{"location":"embeddings/openai/#complete-example","title":"Complete Example","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.embedding_functions import OpenAIEmbeddingFunction\n\n# Initialize embedding function\nembed_fn = OpenAIEmbeddingFunction(\n    model=\"text-embedding-3-small\"\n)\n\n# Create database and index\ndb = GrafitoDatabase(\":memory:\")\ndb.create_vector_index(\n    name=\"articles_vec\",\n    dim=1536,\n    embedding_function=embed_fn,\n    options={\"store_embeddings\": True}\n)\n\n# Add documents with embeddings\narticles = [\n    \"Introduction to Python programming\",\n    \"Graph databases vs relational databases\",\n    \"Machine learning fundamentals\",\n    \"Natural language processing techniques\",\n    \"Data structures and algorithms\"\n]\n\nfor i, text in enumerate(articles):\n    node = db.create_node(\n        labels=[\"Article\"],\n        properties={\"id\": i, \"content\": text}\n    )\n    db.upsert_embedding(\n        node_id=node.id,\n        text=text,\n        index=\"articles_vec\"\n    )\n\n# Perform semantic search\nresults = db.execute(\"\"\"\n    CALL db.vector.search('articles_vec', 'Python coding basics', 3)\n    YIELD node, score\n    RETURN node.content AS content, score\n\"\"\")\n\nfor result in results:\n    print(f\"{result['score']:.3f}: {result['content']}\")\n</code></pre>"},{"location":"embeddings/openai/#distance-metrics","title":"Distance Metrics","text":"<p>OpenAI embeddings work well with multiple distance metrics:</p> <pre><code># Cosine similarity (default)\nembed_fn.default_space()  # Returns: \"cosine\"\n\n# All supported spaces\nembed_fn.supported_spaces()  # Returns: [\"cosine\", \"l2\", \"ip\"]\n</code></pre>"},{"location":"embeddings/openai/#error-handling","title":"Error Handling","text":"<pre><code>from grafito.embedding_functions import OpenAIEmbeddingFunction\n\ntry:\n    embed_fn = OpenAIEmbeddingFunction()\nexcept ValueError as e:\n    print(f\"Missing API key: {e}\")\n\ntry:\n    embeddings = embed_fn([\"text to embed\"])\nexcept ValueError as e:\n    if \"API error\" in str(e):\n        print(f\"OpenAI API error: {e}\")\n</code></pre>"},{"location":"embeddings/openai/#pricing-considerations","title":"Pricing Considerations","text":"<p>OpenAI charges per token: - text-embedding-3-small: ~$0.02 per 1M tokens - text-embedding-3-large: ~$0.13 per 1M tokens</p> <p>Tips to reduce costs: 1. Batch multiple texts in a single call 2. Cache embeddings for frequently used texts 3. Use text-embedding-3-small for most use cases</p>"},{"location":"embeddings/openai/#comparison-with-other-providers","title":"Comparison with Other Providers","text":"Feature OpenAI Cohere Hugging Face Quality Excellent Excellent Good Speed Fast Fast Varies Cost Moderate Moderate Low/Free Multilingual Yes Yes Model-dependent Custom models No No Yes"},{"location":"embeddings/openai/#next-steps","title":"Next Steps","text":"<ul> <li>Hugging Face - Open-source alternatives</li> <li>Cloud Providers - Other cloud options</li> <li>Ollama - Local embedding models</li> </ul>"},{"location":"embeddings/overview/","title":"Embeddings Overview","text":"<p>Grafito provides seamless integration with multiple embedding providers, allowing you to convert text into vector representations for semantic search, clustering, and similarity analysis.</p>"},{"location":"embeddings/overview/#what-are-embeddings","title":"What are Embeddings?","text":"<p>Embeddings are dense vector representations of text (or other data) that capture semantic meaning. Similar texts have vectors that are close together in the embedding space, enabling:</p> <ul> <li>Semantic search: Find content with similar meaning</li> <li>Clustering: Group similar items automatically</li> <li>Recommendation: Suggest similar items</li> <li>Classification: Categorize content based on similarity</li> </ul>"},{"location":"embeddings/overview/#supported-providers","title":"Supported Providers","text":"<p>Grafito includes built-in support for 12+ embedding providers:</p>"},{"location":"embeddings/overview/#cloud-apis","title":"Cloud APIs","text":"Provider Description Best For OpenAI text-embedding-3-small, text-embedding-3-large High-quality embeddings Hugging Face Inference API with thousands of models Flexibility, open-source models Google GenAI text-embedding-004 Google Cloud integration AWS Bedrock Titan embeddings AWS ecosystem Cohere Embed models Enterprise use Jina Jina embeddings Specialized models Mistral Mistral embeddings European AI VoyageAI Voyage embeddings Domain-specific Together AI Together embeddings Open-source models"},{"location":"embeddings/overview/#localon-premise","title":"Local/On-Premise","text":"Provider Description Best For Ollama Local LLM inference Privacy, offline use Sentence Transformers Local embedding models Cost-effective TensorFlow Hub Google ML models TensorFlow ecosystem"},{"location":"embeddings/overview/#quick-start","title":"Quick Start","text":""},{"location":"embeddings/overview/#1-create-an-embedding-function","title":"1. Create an Embedding Function","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.embedding_functions import OpenAIEmbeddingFunction\n\n# Initialize embedding function\nembed_fn = OpenAIEmbeddingFunction(\n    model=\"text-embedding-3-small\",\n    api_key_env_var=\"OPENAI_API_KEY\"\n)\n</code></pre>"},{"location":"embeddings/overview/#2-create-a-vector-index","title":"2. Create a Vector Index","text":"<pre><code>db = GrafitoDatabase(\":memory:\")\n\n# Create vector index with embedding function\ndb.create_vector_index(\n    name=\"articles_vec\",\n    dim=1536,  # Match your embedding model\n    embedding_function=embed_fn\n)\n</code></pre>"},{"location":"embeddings/overview/#3-add-data-with-embeddings","title":"3. Add Data with Embeddings","text":"<pre><code># Create nodes\narticle = db.create_node(\n    labels=[\"Article\"],\n    properties={\"title\": \"Introduction to Graph Databases\"}\n)\n\n# Generate embeddings automatically or manually\ndb.upsert_embedding(\n    node_id=article.id,\n    text=\"Introduction to Graph Databases\",\n    index=\"articles_vec\"\n)\n</code></pre>"},{"location":"embeddings/overview/#4-perform-semantic-search","title":"4. Perform Semantic Search","text":"<pre><code># Search for similar content\nresults = db.vector_search(\n    index=\"articles_vec\",\n    query=\"graph database basics\",\n    k=5\n)\n\nfor node, score in results:\n    print(f\"{node.properties['title']}: {score}\")\n</code></pre>"},{"location":"embeddings/overview/#embedding-function-base-interface","title":"Embedding Function Base Interface","text":"<p>All embedding functions implement a common interface:</p> <pre><code>class EmbeddingFunction:\n    \"\"\"Abstract embedding function interface.\"\"\"\n\n    def __call__(self, input: list[str]) -&gt; list[list[float]]:\n        \"\"\"Generate embeddings for the given input texts.\"\"\"\n        ...\n\n    def name(self) -&gt; str:\n        \"\"\"Return the registry name for this embedding function.\"\"\"\n        ...\n\n    def default_space(self) -&gt; str:\n        \"\"\"Return default distance space (cosine, l2, ip).\"\"\"\n        ...\n\n    def supported_spaces(self) -&gt; list[str]:\n        \"\"\"Return supported distance spaces.\"\"\"\n        ...\n\n    def dimension(self) -&gt; int | None:\n        \"\"\"Return embedding dimension if known.\"\"\"\n        ...\n</code></pre>"},{"location":"embeddings/overview/#distance-spaces","title":"Distance Spaces","text":"<p>Different embedding models work best with different distance metrics:</p> Space Description Best For <code>cosine</code> Cosine similarity Most text embeddings <code>l2</code> Euclidean distance Image embeddings <code>ip</code> Inner product OpenAI embeddings"},{"location":"embeddings/overview/#configuration-management","title":"Configuration Management","text":"<p>Embedding functions can be serialized for persistence:</p> <pre><code># Get configuration\nconfig = embed_fn.get_config()\n# {'model': 'text-embedding-3-small'}\n\n# Recreate from configuration\nfrom grafito.embedding_functions import create_embedding_function\n\nembed_fn = create_embedding_function(\"openai\", config)\n</code></pre>"},{"location":"embeddings/overview/#choosing-a-provider","title":"Choosing a Provider","text":""},{"location":"embeddings/overview/#for-production-use","title":"For Production Use","text":"<ul> <li>OpenAI: Best quality embeddings, reliable API</li> <li>Cohere: Enterprise features, good multilingual support</li> <li>AWS Bedrock: If already using AWS infrastructure</li> </ul>"},{"location":"embeddings/overview/#for-cost-effective-solutions","title":"For Cost-Effective Solutions","text":"<ul> <li>Hugging Face Inference API: Pay-per-use, many free models</li> <li>Sentence Transformers: Run locally, no API costs</li> </ul>"},{"location":"embeddings/overview/#for-privacyoffline","title":"For Privacy/Offline","text":"<ul> <li>Ollama: Run models locally on your hardware</li> <li>Sentence Transformers: Local inference</li> </ul>"},{"location":"embeddings/overview/#for-experimentation","title":"For Experimentation","text":"<ul> <li>Ollama: Easy to try different models</li> <li>Hugging Face: Largest selection of models</li> </ul>"},{"location":"embeddings/overview/#environment-variables","title":"Environment Variables","text":"<p>Most providers support environment variables for API keys:</p> <pre><code># OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Hugging Face\nexport HF_TOKEN=\"hf_...\"\n\n# Google GenAI\nexport GOOGLE_API_KEY=\"...\"\n\n# AWS Bedrock (uses boto3 credential chain)\nexport AWS_ACCESS_KEY_ID=\"...\"\nexport AWS_SECRET_ACCESS_KEY=\"...\"\n</code></pre>"},{"location":"embeddings/overview/#error-handling","title":"Error Handling","text":"<pre><code>from grafito.embedding_functions import OpenAIEmbeddingFunction\n\ntry:\n    embed_fn = OpenAIEmbeddingFunction()\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n\ntry:\n    embeddings = embed_fn([\"text to embed\"])\nexcept Exception as e:\n    print(f\"API error: {e}\")\n</code></pre>"},{"location":"embeddings/overview/#next-steps","title":"Next Steps","text":"<ul> <li>OpenAI Integration - OpenAI's embedding models</li> <li>Hugging Face - Open-source models</li> <li>Cloud Providers - Google, AWS, Cohere, etc.</li> <li>Ollama - Local embedding models</li> </ul>"},{"location":"examples/company-structure/","title":"Example: Company Structure","text":"<p>This example models an organization with departments, employees, reporting lines, skills, and management hierarchy.</p> <p>Source: <code>examples/company_structure.py</code>.</p>"},{"location":"examples/company-structure/#data-model","title":"Data Model","text":"<p>Nodes:</p> <ul> <li><code>(:Company {name, founded, industry, size})</code></li> <li><code>(:Department {name, budget})</code></li> <li><code>(:Person:Employee {name, title, email, hire_date, salary})</code></li> <li><code>(:Skill {name})</code></li> </ul> <p>Relationships:</p> <ul> <li><code>(:Department)-[:PART_OF]-&gt;(:Company)</code></li> <li><code>(:Employee)-[:WORKS_IN {since}]-&gt;(:Department)</code></li> <li><code>(:Employee)-[:WORKS_AT {since}]-&gt;(:Company)</code></li> <li><code>(:Employee)-[:REPORTS_TO]-&gt;(:Employee)</code></li> <li><code>(:Department)-[:MANAGES]-&gt;(:Department)</code></li> <li><code>(:Employee)-[:HAS_SKILL {years}]-&gt;(:Skill)</code></li> </ul>"},{"location":"examples/company-structure/#build-the-graph","title":"Build the Graph","text":"<pre><code>from grafito import GrafitoDatabase\n\ndb = GrafitoDatabase(\":memory:\")\n\ntechcorp = db.create_node(\n    labels=[\"Company\"],\n    properties={\"name\": \"TechCorp\", \"founded\": 2010, \"industry\": \"Technology\", \"size\": \"large\"},\n)\n\nengineering = db.create_node(labels=[\"Department\"], properties={\"name\": \"Engineering\", \"budget\": 5_000_000})\n\ndb.create_relationship(engineering.id, techcorp.id, \"PART_OF\")\n</code></pre>"},{"location":"examples/company-structure/#queries","title":"Queries","text":""},{"location":"examples/company-structure/#organizational-hierarchy","title":"Organizational Hierarchy","text":"<pre><code>ceo_reports = db.get_neighbors(ceo.id, direction=\"incoming\", rel_type=\"REPORTS_TO\")\n</code></pre>"},{"location":"examples/company-structure/#department-headcount","title":"Department Headcount","text":"<pre><code>eng_employees = db.get_neighbors(engineering.id, direction=\"incoming\", rel_type=\"WORKS_IN\")\n</code></pre>"},{"location":"examples/company-structure/#employees-with-a-skill","title":"Employees with a Skill","text":"<pre><code>python_rels = db.match_relationships(target_id=python_skill.id, rel_type=\"HAS_SKILL\")\n</code></pre>"},{"location":"examples/company-structure/#reporting-chain","title":"Reporting Chain","text":"<pre><code>current = engineer1\nwhile True:\n    managers = db.get_neighbors(current.id, direction=\"outgoing\", rel_type=\"REPORTS_TO\")\n    if not managers:\n        break\n    current = managers[0]\n</code></pre>"},{"location":"examples/company-structure/#try-it","title":"Try It","text":"<p>Run the full example:</p> <pre><code>python examples/company_structure.py\n</code></pre>"},{"location":"examples/northwind/","title":"Example: Northwind","text":"<p>This example loads the classic Northwind dataset and runs verification checks.</p> <p>Source: <code>examples/northwind.py</code> and <code>examples/northwind.cypher</code>.</p>"},{"location":"examples/northwind/#what-it-loads","title":"What It Loads","text":"<p>Labels:</p> <ul> <li><code>Product</code> (77)</li> <li><code>Category</code> (8)</li> <li><code>Supplier</code> (29)</li> <li><code>Customer</code> (91)</li> <li><code>Order</code> (830)</li> </ul> <p>Relationship types:</p> <ul> <li><code>PART_OF</code> (Product -&gt; Category)</li> <li><code>SUPPLIES</code> (Supplier -&gt; Product)</li> <li><code>PURCHASED</code> (Customer -&gt; Order)</li> <li><code>ORDERS</code> (Order -&gt; Product)</li> </ul>"},{"location":"examples/northwind/#run-the-loader","title":"Run the Loader","text":"<pre><code>python examples/northwind.py\n</code></pre> <p>By default, the loader uses an in-memory database. You can also use a file:</p> <pre><code>python examples/northwind.py --db northwind.db --clean\n</code></pre>"},{"location":"examples/northwind/#what-it-checks","title":"What It Checks","text":"<p>The loader validates:</p> <ul> <li>Node counts for each label</li> <li>Relationship counts for each type</li> <li>Field types (e.g., <code>unitPrice</code> is a float, <code>discontinued</code> is a boolean)</li> </ul>"},{"location":"examples/northwind/#inspect-the-data","title":"Inspect the Data","text":"<p>You can open a database and run Cypher queries:</p> <pre><code>from grafito import GrafitoDatabase\n\ndb = GrafitoDatabase(\"northwind.db\")\n\nresults = db.execute(\"MATCH (p:Product) RETURN p.productName AS name LIMIT 5\")\nprint(results)\n</code></pre>"},{"location":"examples/social-network/","title":"Example: Social Network","text":"<p>This example builds a small social graph with users, interests, friendships, followers, and simple recommendations.</p> <p>Source: <code>examples/social_network.py</code>.</p>"},{"location":"examples/social-network/#data-model","title":"Data Model","text":"<p>Nodes:</p> <ul> <li><code>(:Person:User {username, name, age, city, joined})</code></li> <li><code>(:Topic {name, category})</code></li> </ul> <p>Relationships:</p> <ul> <li><code>(:User)-[:FRIENDS_WITH {since}]-&gt;(:User)</code> (bidirectional)</li> <li><code>(:User)-[:FOLLOWS]-&gt;(:User)</code></li> <li><code>(:User)-[:INTERESTED_IN {level}]-&gt;(:Topic)</code></li> </ul>"},{"location":"examples/social-network/#build-the-graph","title":"Build the Graph","text":"<pre><code>from grafito import GrafitoDatabase\n\ndb = GrafitoDatabase(\":memory:\")\n\nalice = db.create_node(\n    labels=[\"Person\", \"User\"],\n    properties={\n        \"username\": \"alice_wonder\",\n        \"name\": \"Alice\",\n        \"age\": 28,\n        \"city\": \"San Francisco\",\n        \"joined\": \"2020-01-15\",\n    },\n)\n\npython_topic = db.create_node(\n    labels=[\"Topic\"],\n    properties={\"name\": \"Python\", \"category\": \"Programming\"},\n)\n\ndb.create_relationship(alice.id, python_topic.id, \"INTERESTED_IN\", {\"level\": \"expert\"})\n</code></pre>"},{"location":"examples/social-network/#queries","title":"Queries","text":""},{"location":"examples/social-network/#friends-of-a-user","title":"Friends of a User","text":"<pre><code>friends = db.get_neighbors(alice.id, direction=\"outgoing\", rel_type=\"FRIENDS_WITH\")\n</code></pre>"},{"location":"examples/social-network/#users-interested-in-a-topic","title":"Users Interested in a Topic","text":"<pre><code>python_rels = db.match_relationships(target_id=python_topic.id, rel_type=\"INTERESTED_IN\")\nusers = [db.get_node(rel.source_id) for rel in python_rels]\n</code></pre>"},{"location":"examples/social-network/#shortest-path-between-users","title":"Shortest Path Between Users","text":"<pre><code>path = db.find_shortest_path(alice.id, emma.id)\n</code></pre>"},{"location":"examples/social-network/#followers-of-a-user","title":"Followers of a User","text":"<pre><code>followers = db.get_neighbors(alice.id, direction=\"incoming\", rel_type=\"FOLLOWS\")\n</code></pre>"},{"location":"examples/social-network/#friend-recommendations-friends-of-friends","title":"Friend Recommendations (Friends of Friends)","text":"<pre><code>alice_friends = db.get_neighbors(alice.id, direction=\"outgoing\", rel_type=\"FRIENDS_WITH\")\nknown = {f.id for f in alice_friends}\nknown.add(alice.id)\n\npotential = set()\nfor friend in alice_friends:\n    for fof in db.get_neighbors(friend.id, direction=\"outgoing\", rel_type=\"FRIENDS_WITH\"):\n        if fof.id not in known:\n            potential.add(fof.id)\n</code></pre>"},{"location":"examples/social-network/#try-it","title":"Try It","text":"<p>Run the full example:</p> <pre><code>python examples/social_network.py\n</code></pre>"},{"location":"getting-started/concepts/","title":"Core Concepts","text":"<p>Understanding the Property Graph Model used by Grafito.</p>"},{"location":"getting-started/concepts/#what-is-a-property-graph","title":"What is a Property Graph?","text":"<p>A Property Graph is a graph data model where:</p> <ul> <li>Nodes (also called vertices) represent entities</li> <li>Relationships (also called edges) connect nodes and represent how entities relate</li> <li>Both nodes and relationships can have properties (key-value pairs)</li> <li>Nodes can have labels that categorize them</li> </ul>"},{"location":"getting-started/concepts/#nodes","title":"Nodes","text":"<p>Nodes are the primary entities in your graph.</p>"},{"location":"getting-started/concepts/#labels","title":"Labels","text":"<p>Nodes can have multiple labels, similar to how an object can implement multiple interfaces:</p> <pre><code># Alice is both a Person and an Employee\nalice = db.create_node(\n    labels=['Person', 'Employee'],\n    properties={'name': 'Alice'}\n)\n</code></pre> <p>Common use cases for multiple labels: - <code>Person</code> + <code>Employee</code> + <code>Manager</code> (role hierarchy) - <code>Product</code> + <code>Featured</code> (categorization) - <code>User</code> + <code>Admin</code> (permissions)</p>"},{"location":"getting-started/concepts/#properties","title":"Properties","text":"<p>Properties are JSON-serializable key-value pairs:</p> <pre><code>node = db.create_node(\n    labels=['Person'],\n    properties={\n        'name': 'Alice',\n        'age': 30,\n        'active': True,\n        'tags': ['developer', 'python'],\n        'metadata': {'joined': '2024-01-15'}\n    }\n)\n</code></pre> <p>Supported property types: - <code>int</code> - Integer numbers - <code>float</code> - Floating point numbers - <code>str</code> - Strings - <code>bool</code> - Boolean values - <code>list</code> - Arrays (must contain supported types) - <code>dict</code> - Maps/objects (keys must be strings) - <code>None</code> - Null values</p> <p>Temporal types (stored as ISO 8601 strings): - <code>date</code> - ISO date: <code>'2024-01-15'</code> - <code>datetime</code> - ISO datetime: <code>'2024-01-15T10:30:00'</code> - <code>time</code> - ISO time: <code>'10:30:00'</code> - <code>duration</code> - ISO duration: <code>'P1D'</code> (1 day)</p>"},{"location":"getting-started/concepts/#relationships","title":"Relationships","text":"<p>Relationships are directed connections between nodes.</p>"},{"location":"getting-started/concepts/#direction","title":"Direction","text":"<p>Relationships have a direction (from source to target):</p> <pre><code># Alice KNOWS Bob (direction matters)\ndb.create_relationship(alice.id, bob.id, 'KNOWS')\n\n# Bob is not necessarily knowing Alice in this model\n</code></pre>"},{"location":"getting-started/concepts/#type","title":"Type","text":"<p>Relationship types describe the nature of the connection:</p> <pre><code>db.create_relationship(alice.id, company.id, 'WORKS_AT')\ndb.create_relationship(alice.id, bob.id, 'KNOWS')\ndb.create_relationship(alice.id, project.id, 'MANAGES')\n</code></pre>"},{"location":"getting-started/concepts/#properties_1","title":"Properties","text":"<p>Like nodes, relationships can have properties:</p> <pre><code>db.create_relationship(\n    alice.id, company.id, 'WORKS_AT',\n    properties={\n        'since': 2020,\n        'position': 'Senior Engineer',\n        'department': 'Engineering'\n    }\n)\n</code></pre>"},{"location":"getting-started/concepts/#graph-patterns","title":"Graph Patterns","text":"<p>Graph patterns describe the structure you're looking for:</p>"},{"location":"getting-started/concepts/#basic-pattern","title":"Basic Pattern","text":"<pre><code>(a:Person)-[:KNOWS]-&gt;(b:Person)\n</code></pre> <p>This pattern matches: - A node labeled <code>Person</code> (bound to variable <code>a</code>) - A <code>KNOWS</code> relationship (direction: <code>a</code> \u2192 <code>b</code>) - Another node labeled <code>Person</code> (bound to variable <code>b</code>)</p>"},{"location":"getting-started/concepts/#variable-length-patterns","title":"Variable-Length Patterns","text":"<p>Match paths of variable length:</p> <pre><code># 1 to 3 hops\n(a:Person)-[:KNOWS*1..3]-&gt;(b:Person)\n\n# Any number of hops (uses default max limit)\n(a:Person)-[:KNOWS*..]-&gt;(b:Person)\n</code></pre>"},{"location":"getting-started/concepts/#multiple-patterns","title":"Multiple Patterns","text":"<p>Combine multiple patterns in one query:</p> <pre><code>MATCH\n  (a:Person)-[:KNOWS]-&gt;(b:Person),\n  (b)-[:WORKS_AT]-&gt;(c:Company)\nRETURN a.name, b.name, c.name\n</code></pre>"},{"location":"getting-started/concepts/#traversal","title":"Traversal","text":"<p>Graph traversal means navigating through the graph by following relationships.</p>"},{"location":"getting-started/concepts/#direction_1","title":"Direction","text":"<p>When traversing, you can specify direction:</p> <pre><code># Outgoing: Alice \u2192 ?\noutgoing = db.get_neighbors(alice.id, direction='outgoing')\n\n# Incoming: ? \u2192 Alice\nincoming = db.get_neighbors(alice.id, direction='incoming')\n\n# Both directions\nall_neighbors = db.get_neighbors(alice.id, direction='both')\n</code></pre>"},{"location":"getting-started/concepts/#path-finding","title":"Path Finding","text":"<p>Find paths between nodes:</p> <pre><code># Shortest path (BFS algorithm)\npath = db.find_shortest_path(alice.id, bob.id)\n\n# Any path with depth limit (DFS algorithm)\npath = db.find_path(alice.id, bob.id, max_depth=5)\n</code></pre>"},{"location":"getting-started/concepts/#indexes-and-constraints","title":"Indexes and Constraints","text":""},{"location":"getting-started/concepts/#property-indexes","title":"Property Indexes","text":"<p>Speed up queries on frequently accessed properties:</p> <pre><code># Create index on Person.name\ndb.create_node_index('Person', 'name')\n\n# Or via Cypher\ndb.execute(\"CREATE INDEX FOR (n:Person) ON (n.name)\")\n</code></pre>"},{"location":"getting-started/concepts/#constraints","title":"Constraints","text":"<p>Enforce data integrity:</p> <pre><code># Unique constraint\ndb.execute(\"CREATE CONSTRAINT FOR (n:User) REQUIRE n.email IS UNIQUE\")\n\n# Type constraint\ndb.execute(\"CREATE CONSTRAINT FOR (n:Person) REQUIRE n.age IS INTEGER\")\n\n# Existence constraint\ndb.execute(\"CREATE CONSTRAINT FOR (n:Person) REQUIRE n.name IS NOT NULL\")\n</code></pre>"},{"location":"getting-started/concepts/#storage-model","title":"Storage Model","text":"<p>Grafito uses a normalized SQLite schema:</p> <pre><code>-- Nodes table\nCREATE TABLE nodes (\n    id INTEGER PRIMARY KEY,\n    properties TEXT,  -- JSON\n    created_at REAL\n);\n\n-- Labels (normalized)\nCREATE TABLE labels (\n    id INTEGER PRIMARY KEY,\n    name TEXT UNIQUE\n);\n\n-- Node-Label junction\nCREATE TABLE node_labels (\n    node_id INTEGER,\n    label_id INTEGER\n);\n\n-- Relationships\nCREATE TABLE relationships (\n    id INTEGER PRIMARY KEY,\n    source_node_id INTEGER,\n    target_node_id INTEGER,\n    type TEXT,\n    properties TEXT  -- JSON\n);\n</code></pre> <p>Benefits of this design: - Efficient queries via indexes on labels and types - Flexible properties via JSON storage - ACID compliance via SQLite transactions - Small footprint suitable for embedding</p>"},{"location":"getting-started/concepts/#comparison-with-other-models","title":"Comparison with Other Models","text":""},{"location":"getting-started/concepts/#vs-relational-sql","title":"vs. Relational (SQL)","text":"Aspect Relational Property Graph Schema Rigid tables Flexible labels/properties Relationships Foreign keys First-class entities Traversal JOINs Direct navigation Best for Structured data Connected data"},{"location":"getting-started/concepts/#vs-document-mongodb","title":"vs. Document (MongoDB)","text":"Aspect Document Property Graph Structure Nested documents Nodes + edges Relationships Embedded references Native connections Queries Document-based Pattern-based Best for Content management Relationship analysis"},{"location":"getting-started/concepts/#vs-rdf-triple-stores","title":"vs. RDF (Triple Stores)","text":"Aspect RDF Property Graph Model Subject-Predicate-Object Nodes + labeled relationships Schema Ontologies Labels + properties Standards W3C standards De facto (Neo4j) Best for Semantic web Application graphs"},{"location":"getting-started/concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Learn the Core API</li> <li>Explore Cypher queries</li> <li>See examples in action</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>SQLite 3 with FTS5 support (for full-text search features)</li> </ul>"},{"location":"getting-started/installation/#basic-installation","title":"Basic Installation","text":"<p>Install Grafito from PyPI:</p> <pre><code>pip install grafito\n</code></pre> <p>Or using <code>uv</code>:</p> <pre><code>uv pip install grafito\n</code></pre>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>To install Grafito in development mode with all test dependencies:</p> <pre><code>git clone &lt;repository-url&gt;\ncd grafito\npip install -e \".[dev]\"\n</code></pre> <p>Or with <code>uv</code>:</p> <pre><code>uv pip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Grafito has a modular design with optional extras for specific features:</p>"},{"location":"getting-started/installation/#all-extras","title":"All Extras","text":"<pre><code>pip install grafito[all]\n</code></pre> <p>Note</p> <p><code>grafito[all]</code> may fail on some OS/Python combinations depending on native wheels for optional backends. In that case, install only the extras you need.</p>"},{"location":"getting-started/installation/#vector-search-backends","title":"Vector Search Backends","text":"<p>Choose one or more ANN (Approximate Nearest Neighbors) backends:</p> Backend Installation Best For FAISS <code>pip install grafito[faiss]</code> CPU-optimized, most features Annoy <code>pip install grafito[annoy]</code> Memory-mapped large indexes LEANN <code>pip install grafito[leann]</code> Lightweight, fast builds HNSWlib <code>pip install grafito[hnswlib]</code> High-recall search USearch <code>pip install grafito[usearch]</code> Modern alternative to FAISS Voyager <code>pip install grafito[voyager]</code> Spotify's ANN library"},{"location":"getting-started/installation/#other-integrations","title":"Other Integrations","text":"<pre><code># RDF/Turtle support\npip install grafito[rdf]\n\n# Visualization with PyVis\npip install grafito[viz]\n\n# BM25 text search enhancements\npip install grafito[bm25s]\n</code></pre>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>Test your installation:</p> <pre><code>from grafito import GrafitoDatabase\n\n# Create an in-memory database\ndb = GrafitoDatabase(':memory:')\n\n# Create a test node\nnode = db.create_node(labels=['Test'], properties={'message': 'Hello, Grafito!'})\nprint(f\"Created node: {node.id}\")\n\n# Check FTS5 availability\nprint(f\"FTS5 available: {db.has_fts5()}\")\n\ndb.close()\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#fts5-not-available","title":"FTS5 Not Available","text":"<p>If <code>db.has_fts5()</code> returns <code>False</code>, your SQLite build doesn't include FTS5:</p> <p>macOS: <pre><code>brew install sqlite3\n# Or use Python from conda:\nconda install sqlite\n</code></pre></p> <p>Ubuntu/Debian: <pre><code>sudo apt-get install libsqlite3-dev\n</code></pre></p> <p>Windows: Use Python from python.org or Conda, which typically include FTS5.</p>"},{"location":"getting-started/installation/#faiss-installation-issues","title":"FAISS Installation Issues","text":"<p>FAISS requires native compilation. If installation fails:</p> <pre><code># Use conda instead\nconda install -c pytorch faiss-cpu\n\n# Then install grafito without the faiss extra\npip install grafito\n</code></pre>"},{"location":"getting-started/installation/#import-errors-with-optional-dependencies","title":"Import Errors with Optional Dependencies","text":"<p>If you get import errors for optional features:</p> <pre><code># Check available backends\nfrom grafito.integrations import available_viz_backends, available_vector_backends\n\nprint(\"Visualization:\", available_viz_backends())\nprint(\"Vector:\", available_vector_backends())\n</code></pre>"},{"location":"getting-started/introduction/","title":"Introduction","text":"<p>Grafito is a fast, embeddable property graph database for Python \u2014 no server required, SQLite-backed, Cypher-powered, with optional semantic search capabilities.</p>"},{"location":"getting-started/introduction/#what-is-grafito","title":"What is Grafito?","text":"<p>Grafito implements the Property Graph Model (Neo4j-compatible concepts) on top of SQLite, providing a lightweight yet powerful graph database that runs directly in your Python application.</p>"},{"location":"getting-started/introduction/#key-features","title":"Key Features","text":"Feature Description No Server Required Embeddable database that runs in-process with your application SQLite-Backed Reliable storage with ACID transactions Cypher Query Language Full Cypher parser and executor for declarative queries Multi-Labeled Nodes Nodes can have multiple labels (e.g., <code>Person</code>, <code>Employee</code>, <code>Manager</code>) Rich Properties JSON-serializable properties on nodes and relationships Full-Text Search BM25-ranked keyword search via SQLite FTS5 Semantic Search Vector similarity search with multiple ANN backends NetworkX Compatible Export to/import from NetworkX for graph algorithms RDF/Turtle Support Import and export RDF data Visualization Export to PyVis, D2, Mermaid, and Graphviz"},{"location":"getting-started/introduction/#when-to-use-grafito","title":"When to Use Grafito","text":"<p>Grafito is ideal for:</p> <ul> <li>Prototyping graph-based applications without infrastructure overhead</li> <li>Educational purposes \u2014 learning graph databases and Cypher</li> <li>Small to Medium Scale \u2014 graphs up to 100K+ nodes</li> <li>Embedded Applications \u2014 shipping a graph database with your Python app</li> <li>Testing \u2014 graph algorithms without heavy dependencies</li> <li>Hybrid Workflows \u2014 combining structured and semantic search</li> </ul>"},{"location":"getting-started/introduction/#quick-comparison","title":"Quick Comparison","text":"Feature Grafito Neo4j NetworkX Embeddable \u2705 Yes \u274c No \u2705 Yes Persistent \u2705 Yes \u2705 Yes \u274c No Cypher Support \u2705 Full \u2705 Full \u274c No Server Required \u274c No \u2705 Yes \u274c No Vector Search \u2705 Built-in Plugin \u274c No Full-Text Search \u2705 FTS5 \u2705 Native \u274c No"},{"location":"getting-started/introduction/#philosophy","title":"Philosophy","text":"<p>Grafito follows these design principles:</p> <ol> <li>Simplicity First: Simple installation, simple API, simple mental model</li> <li>Python-Native: First-class Python integration with familiar patterns</li> <li>Standards-Based: Cypher queries, SQLite storage, NetworkX compatibility</li> <li>Extensible: Plugin architecture for embeddings, visualization, and more</li> <li>Production-Ready: ACID transactions, indexes, constraints, and testing utilities</li> </ol>"},{"location":"getting-started/introduction/#next-steps","title":"Next Steps","text":"<ul> <li>Installation \u2014 Get Grafito up and running</li> <li>Quick Start \u2014 Your first graph in 5 minutes</li> <li>Core Concepts \u2014 Understanding the property graph model</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get up and running with Grafito in 5 minutes.</p>"},{"location":"getting-started/quickstart/#create-your-first-graph","title":"Create Your First Graph","text":"<pre><code>from grafito import GrafitoDatabase\n\n# Initialize database (in-memory for this example)\ndb = GrafitoDatabase(':memory:')\n\n# Create nodes with labels and properties\nalice = db.create_node(\n    labels=['Person', 'Employee'],\n    properties={'name': 'Alice', 'age': 30, 'city': 'NYC'}\n)\n\nbob = db.create_node(\n    labels=['Person'],\n    properties={'name': 'Bob', 'age': 25, 'city': 'LA'}\n)\n\ncompany = db.create_node(\n    labels=['Company'],\n    properties={'name': 'TechCorp', 'founded': 2010}\n)\n\nprint(f\"Created nodes: Alice ({alice.id}), Bob ({bob.id}), TechCorp ({company.id})\")\n</code></pre>"},{"location":"getting-started/quickstart/#add-relationships","title":"Add Relationships","text":"<pre><code># Create a relationship between Alice and TechCorp\nworks_at = db.create_relationship(\n    alice.id, company.id, 'WORKS_AT',\n    properties={'since': 2020, 'position': 'Engineer'}\n)\n\n# Create a KNOWS relationship between Alice and Bob\nknows = db.create_relationship(alice.id, bob.id, 'KNOWS')\n\nprint(f\"Alice works at TechCorp since 2020\")\n</code></pre>"},{"location":"getting-started/quickstart/#query-your-data","title":"Query Your Data","text":""},{"location":"getting-started/quickstart/#programmatic-api","title":"Programmatic API","text":"<pre><code># Find all Person nodes\npersons = db.match_nodes(labels=['Person'])\nfor person in persons:\n    print(f\"{person.properties['name']} - {person.properties.get('age')} years old\")\n\n# Find employees over 25\nexperienced = db.match_nodes(\n    labels=['Employee'],\n    properties={'age': 30}\n)\n\n# Get Alice's connections\nconnections = db.get_neighbors(alice.id, direction='outgoing')\nfor node in connections:\n    print(f\"Alice knows: {node.properties['name']}\")\n</code></pre>"},{"location":"getting-started/quickstart/#using-cypher","title":"Using Cypher","text":"<pre><code># Execute Cypher queries\nresults = db.execute(\"MATCH (n:Person) RETURN n.name, n.age\")\nfor row in results:\n    print(f\"{row['n.name']}: {row['n.age']}\")\n\n# Find who works where\nresults = db.execute(\"\"\"\n    MATCH (p:Person)-[r:WORKS_AT]-&gt;(c:Company)\n    RETURN p.name, c.name, r.position\n\"\"\")\nfor row in results:\n    print(f\"{row['p.name']} is a {row['r.position']} at {row['c.name']}\")\n</code></pre>"},{"location":"getting-started/quickstart/#graph-traversal","title":"Graph Traversal","text":"<pre><code># Find shortest path between two nodes\npath = db.find_shortest_path(alice.id, bob.id)\nif path:\n    names = ' -&gt; '.join(node.properties['name'] for node in path)\n    print(f\"Path: {names}\")\n\n# Find any path with depth limit\npath = db.find_path(alice.id, bob.id, max_depth=3)\n</code></pre>"},{"location":"getting-started/quickstart/#use-transactions","title":"Use Transactions","text":"<pre><code># Option 1: Context manager (recommended)\nwith db:\n    node1 = db.create_node(labels=['Test'])\n    node2 = db.create_node(labels=['Test'])\n    db.create_relationship(node1.id, node2.id, 'CONNECTS')\n# Auto-commits on success, rolls back on exception\n\n# Option 2: Explicit control\ndb.begin_transaction()\ntry:\n    # ... operations ...\n    db.commit()\nexcept Exception:\n    db.rollback()\n    raise\n</code></pre>"},{"location":"getting-started/quickstart/#metadata-queries","title":"Metadata Queries","text":"<pre><code># Inspect your graph\nprint(f\"Total nodes: {db.get_node_count()}\")\nprint(f\"Total relationships: {db.get_relationship_count()}\")\nprint(f\"All labels: {db.get_all_labels()}\")\nprint(f\"All relationship types: {db.get_all_relationship_types()}\")\n</code></pre>"},{"location":"getting-started/quickstart/#complete-example","title":"Complete Example","text":"<pre><code>from grafito import GrafitoDatabase\n\ndef main():\n    # Create database\n    db = GrafitoDatabase(':memory:')\n\n    # Create a mini social network\n    with db:\n        # Create people\n        alice = db.create_node(labels=['Person'], properties={'name': 'Alice', 'age': 30})\n        bob = db.create_node(labels=['Person'], properties={'name': 'Bob', 'age': 25})\n        carol = db.create_node(labels=['Person'], properties={'name': 'Carol', 'age': 35})\n\n        # Create relationships\n        db.create_relationship(alice.id, bob.id, 'KNOWS', properties={'since': 2015})\n        db.create_relationship(bob.id, carol.id, 'KNOWS', properties={'since': 2018})\n        db.create_relationship(alice.id, carol.id, 'KNOWS', properties={'since': 2020})\n\n    # Query: Find friends of friends\n    results = db.execute(\"\"\"\n        MATCH (me:Person {name: 'Alice'})-[:KNOWS]-&gt;(friend)-[:KNOWS]-&gt;(fof)\n        WHERE fof &lt;&gt; me\n        RETURN DISTINCT fof.name\n    \"\"\")\n\n    print(\"Friends of Alice's friends:\")\n    for row in results:\n        print(f\"  - {row['fof.name']}\")\n\n    # Cleanup\n    db.close()\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Core Concepts</li> <li>Explore the Core API</li> <li>Master Cypher Query Language</li> </ul>"},{"location":"integrations/neo4j-import/","title":"Neo4j Dump Import","text":"<p>Grafito can import data from Neo4j database dumps without requiring a running Neo4j instance.</p>"},{"location":"integrations/neo4j-import/#prerequisites","title":"Prerequisites","text":"<pre><code># zstandard is included by default\npip install grafito\n</code></pre>"},{"location":"integrations/neo4j-import/#importing-a-dump","title":"Importing a Dump","text":""},{"location":"integrations/neo4j-import/#basic-import","title":"Basic Import","text":"<pre><code>from grafito import GrafitoDatabase\n\n# Create database\ndb = GrafitoDatabase(':memory:')\n\n# Import Neo4j dump (Zstandard DZV1)\ndb.import_neo4j_dump('path/to/neo4j.dump')\n\n# Query imported data\nresult = db.execute('MATCH (n) RETURN count(n) as count')\nprint(f'Imported {result[0][\"count\"]} nodes')\n</code></pre>"},{"location":"integrations/neo4j-import/#import-to-file","title":"Import to File","text":"<pre><code># Import to persistent database\ndb = GrafitoDatabase('imported.db')\ndb.import_neo4j_dump('neo4j.dump')\ndb.close()\n\n# Later use\n db = GrafitoDatabase('imported.db')\n</code></pre>"},{"location":"integrations/neo4j-import/#supported-neo4j-versions","title":"Supported Neo4j Versions","text":"Neo4j Version Dump Format Support 4.x Zstandard <code>.dump</code> (DZV1) \u2705 Supported 5.x Zstandard <code>.dump</code> (DZV1) \u2705 Supported <p>Notes: - Gzip <code>.dump</code> files (DGV1) are not supported. - The importer expects Neo4j store files with <code>neostore.*</code> names inside the dump.</p>"},{"location":"integrations/neo4j-import/#low-level-api","title":"Low-Level API","text":"<p>For advanced use cases, import components separately.</p>"},{"location":"integrations/neo4j-import/#extract-dump","title":"Extract Dump","text":"<pre><code>from grafito.importers import extract_dump\n\n# Extract to directory (Zstandard DZV1 dumps only)\nextract_dump('neo4j.dump', 'extracted/')\n\n# This extractor only pulls files that contain \\\"neostore\\\" in their name.\n</code></pre>"},{"location":"integrations/neo4j-import/#find-store-directory","title":"Find Store Directory","text":"<pre><code>from grafito.importers import find_store_dir\n\n# Locate store files\nstore_path = find_store_dir('extracted/')\nprint(f'Store at: {store_path}')\n</code></pre>"},{"location":"integrations/neo4j-import/#custom-import","title":"Custom Import","text":"<pre><code>from grafito.importers import import_dump, Neo4jStoreParser\n\n# Parse store directly\nparser = Neo4jStoreParser('path/to/store')\n\n# Iterate over records\nfor record in parser.iter_nodes():\n    print(f'Node: {record}')\n\nfor record in parser.iter_relationships():\n    print(f'Relationship: {record}')\n\n# Import with progress callback\ndef progress(current, total, type):\n    pct = (current / total) * 100\n    print(f'{type}: {current}/{total} ({pct:.1f}%)')\n\nimport_dump(\n    'neo4j.dump',\n    db,\n    progress_callback=progress\n)\n</code></pre>"},{"location":"integrations/neo4j-import/#migration-workflows","title":"Migration Workflows","text":""},{"location":"integrations/neo4j-import/#full-migration","title":"Full Migration","text":"<pre><code>def migrate_neo4j_to_grafito(neo4j_dump, grafito_db_path):\n    \"\"\"Complete Neo4j to Grafito migration.\"\"\"\n    from grafito import GrafitoDatabase\n\n    # Create fresh Grafito database\n    db = GrafitoDatabase(grafito_db_path)\n\n    try:\n        # Import\n        print('Importing...')\n        db.import_neo4j_dump(neo4j_dump)\n\n        # Create indexes for common queries\n        print('Creating indexes...')\n        db.create_node_index('Person', 'name')\n        db.create_node_index('User', 'email')\n\n        # Verify\n        result = db.execute('MATCH (n) RETURN labels(n) as label, count(*) as count')\n        for row in result:\n            print(f\"{row['label']}: {row['count']}\")\n\n        return db\n    except Exception as e:\n        print(f'Error: {e}')\n        raise\n\n# Usage\ndb = migrate_neo4j_to_grafito('neo4j.dump', 'migrated.db')\n</code></pre>"},{"location":"integrations/neo4j-import/#selective-import","title":"Selective Import","text":"<pre><code>def import_only_users(neo4j_dump, db):\n    \"\"\"Import only User nodes.\"\"\"\n    from grafito.importers import Neo4jStoreParser\n\n    parser = Neo4jStoreParser(neo4j_dump)\n\n    with db:\n        for record in parser.iter_nodes():\n            if 'User' in record.get('labels', []):\n                # Import only User nodes\n                db.create_node(\n                    labels=record['labels'],\n                    properties=record['properties']\n                )\n</code></pre>"},{"location":"integrations/neo4j-import/#what-gets-imported","title":"What Gets Imported","text":"Neo4j Feature Grafito Mapping Nodes Nodes with labels and properties Relationships Relationships with type and properties Properties JSON-compatible types (string, int, float, bool, list) Constraints Manual recreation via Cypher Indexes Manual recreation after import"},{"location":"integrations/neo4j-import/#limitations","title":"Limitations","text":"<ul> <li>Neo4j constraints must be manually recreated</li> <li>Full-text indexes require separate configuration</li> <li>Spatial/temporal types converted to strings</li> <li>Neo4j's <code>id()</code> function differs from Grafito's IDs</li> </ul>"},{"location":"integrations/networkx/","title":"NetworkX Integration","text":"<p>Grafito provides bidirectional integration with NetworkX for graph algorithms and analysis.</p>"},{"location":"integrations/networkx/#export-to-networkx","title":"Export to NetworkX","text":"<p>Convert a Grafito database to a NetworkX <code>MultiDiGraph</code>.</p>"},{"location":"integrations/networkx/#basic-export","title":"Basic Export","text":"<pre><code>from grafito import GrafitoDatabase\n\n# Create database with data\ndb = GrafitoDatabase(':memory:')\nalice = db.create_node(labels=['Person'], properties={'name': 'Alice', 'age': 30})\nbob = db.create_node(labels=['Person'], properties={'name': 'Bob', 'age': 25})\ndb.create_relationship(alice.id, bob.id, 'KNOWS', {'since': 2020})\n\n# Export to NetworkX\ngraph = db.to_networkx()\n\nprint(f'Nodes: {graph.number_of_nodes()}')  # 2\nprint(f'Edges: {graph.number_of_edges()}')  # 1\n</code></pre>"},{"location":"integrations/networkx/#node-attributes","title":"Node Attributes","text":"<p>Node attributes in NetworkX include: - <code>labels</code>: List of node labels - <code>properties</code>: Dictionary of node properties - Original node ID is stored as <code>grafito_id</code></p> <pre><code># Access node attributes\nfor node_id, attrs in graph.nodes(data=True):\n    print(f'Node {node_id}:')\n    print(f'  Labels: {attrs[\"labels\"]}')\n    print(f'  Properties: {attrs[\"properties\"]}')\n</code></pre>"},{"location":"integrations/networkx/#edge-attributes","title":"Edge Attributes","text":"<p>Edge attributes include: - <code>type</code>: Relationship type - <code>properties</code>: Dictionary of relationship properties</p> <pre><code># Access edge attributes\nfor u, v, key, attrs in graph.edges(data=True, keys=True):\n    print(f'Edge {u} -&gt; {v}:')\n    print(f'  Type: {attrs[\"type\"]}')\n    print(f'  Properties: {attrs[\"properties\"]}')\n</code></pre>"},{"location":"integrations/networkx/#import-from-networkx","title":"Import from NetworkX","text":"<p>Import a NetworkX graph into Grafito.</p>"},{"location":"integrations/networkx/#basic-import","title":"Basic Import","text":"<pre><code>import networkx as nx\nfrom grafito import GrafitoDatabase\n\n# Create NetworkX graph\ngraph = nx.MultiDiGraph()\ngraph.add_node('alice', labels=['Person'], properties={'name': 'Alice'})\ngraph.add_node('bob', labels=['Person'], properties={'name': 'Bob'})\ngraph.add_edge('alice', 'bob', type='KNOWS', properties={'since': 2020})\n\n# Import into Grafito\ndb = GrafitoDatabase(':memory:')\nnode_map = db.from_networkx(graph)\n\n# node_map maps NetworkX node IDs to Grafito node IDs\nprint(f'Created {len(node_map)} nodes')\nprint(f'Alice ID: {node_map[\"alice\"]}')\n</code></pre>"},{"location":"integrations/networkx/#import-with-custom-mapping","title":"Import with Custom Mapping","text":"<pre><code># Import and then work with the data\nnode_map = db.from_networkx(graph)\n\n# Query imported data\nalice_id = node_map['alice']\nneighbors = db.get_neighbors(alice_id, direction='outgoing')\nfor n in neighbors:\n    print(f'Alice knows: {n.properties[\"name\"]}')\n</code></pre>"},{"location":"integrations/networkx/#using-networkx-algorithms","title":"Using NetworkX Algorithms","text":"<p>Once exported, use any NetworkX algorithm.</p>"},{"location":"integrations/networkx/#centrality-analysis","title":"Centrality Analysis","text":"<pre><code>import networkx as nx\n\n# Export graph\ngraph = db.to_networkx()\n\n# Degree centrality\ndegree_cent = nx.degree_centrality(graph)\nprint('Most connected:', max(degree_cent, key=degree_cent.get))\n\n# Betweenness centrality\nbetweenness = nx.betweenness_centrality(graph)\nprint('Key connectors:', sorted(betweenness.items(), key=lambda x: -x[1])[:5])\n\n# PageRank\npagerank = nx.pagerank(graph)\nprint('Highest PageRank:', max(pagerank, key=pagerank.get))\n</code></pre>"},{"location":"integrations/networkx/#path-finding","title":"Path Finding","text":"<pre><code># Shortest path\ntry:\n    path = nx.shortest_path(graph, source=alice.id, target=bob.id)\n    print(f'Path: {path}')\nexcept nx.NetworkXNoPath:\n    print('No path exists')\n\n# All simple paths\npaths = list(nx.all_simple_paths(graph, alice.id, bob.id, cutoff=3))\nprint(f'Found {len(paths)} paths')\n</code></pre>"},{"location":"integrations/networkx/#community-detection","title":"Community Detection","text":"<pre><code># Weakly connected components\ncomponents = list(nx.weakly_connected_components(graph))\nprint(f'{len(components)} components')\n\n# Communities using Louvain (undirected)\nundirected = graph.to_undirected()\ncommunities = nx.community.louvain_communities(undirected)\nprint(f'{len(communities)} communities')\n</code></pre>"},{"location":"integrations/networkx/#cycle-detection","title":"Cycle Detection","text":"<pre><code># Find cycles\ncycles = list(nx.simple_cycles(graph))\nprint(f'{len(cycles)} cycles found')\n\n# Check if DAG\nis_dag = nx.is_directed_acyclic_graph(graph)\nprint(f'Is DAG: {is_dag}')\n</code></pre>"},{"location":"integrations/networkx/#data-transformation","title":"Data Transformation","text":""},{"location":"integrations/networkx/#converting-to-undirected","title":"Converting to Undirected","text":"<pre><code># For algorithms requiring undirected graphs\nundirected = graph.to_undirected()\n\n# Check connectivity\nis_connected = nx.is_connected(undirected)\nprint(f'Connected: {is_connected}')\n</code></pre>"},{"location":"integrations/networkx/#extracting-subgraphs","title":"Extracting Subgraphs","text":"<pre><code># Subgraph by nodes\nnode_subset = list(graph.nodes())[:10]\nsubgraph = graph.subgraph(node_subset)\n\n# Egocentric network (1-hop around a node)\negonet = nx.ego_graph(graph.to_undirected(), alice.id, radius=1)\nprint(f'Egonet has {egonet.number_of_nodes()} nodes')\n</code></pre>"},{"location":"integrations/networkx/#roundtrip-example","title":"Roundtrip Example","text":"<pre><code># Create in Grafito\ndb = GrafitoDatabase(':memory:')\nalice = db.create_node(labels=['Person'], properties={'name': 'Alice'})\nbob = db.create_node(labels=['Person'], properties={'name': 'Bob'})\ndb.create_relationship(alice.id, bob.id, 'KNOWS')\n\n# Export to NetworkX\ngraph = db.to_networkx()\n\n# Run algorithms\nscores = nx.pagerank(graph)\n\n# Enrich graph with scores\nfor node_id, score in scores.items():\n    graph.nodes[node_id]['pagerank'] = score\n\n# Import back to Grafito\ndb2 = GrafitoDatabase(':memory:')\nnode_map = db2.from_networkx(graph)\n\n# Query enriched data\nfor old_id, new_id in node_map.items():\n    node = db2.get_node(new_id)\n    print(f\"{node.properties['name']}: PageRank = {node.properties.get('pagerank')}\")\n</code></pre>"},{"location":"integrations/networkx/#best-practices","title":"Best Practices","text":""},{"location":"integrations/networkx/#1-memory-considerations","title":"1. Memory Considerations","text":"<pre><code># For large graphs, process in batches\nbatch_size = 1000\nall_nodes = list(db.match_nodes())\n\nfor i in range(0, len(all_nodes), batch_size):\n    batch = all_nodes[i:i+batch_size]\n    # Process batch\n</code></pre>"},{"location":"integrations/networkx/#2-algorithm-selection","title":"2. Algorithm Selection","text":"<pre><code># Use appropriate graph type\ngraph = db.to_networkx()\n\n# Some algorithms need undirected\nif not nx.is_directed_acyclic_graph(graph):\n    print('Graph has cycles')\n\n# Some need specific attributes\nfor u, v, attrs in graph.edges(data=True):\n    if 'weight' not in attrs.get('properties', {}):\n        # Add default weight\n        attrs['properties']['weight'] = 1.0\n</code></pre>"},{"location":"integrations/networkx/#3-preserving-data-integrity","title":"3. Preserving Data Integrity","text":"<pre><code># Node ID mapping is preserved\nnode_map = db.from_networkx(graph)\n\n# Store original IDs if needed\nfor old_id, new_id in node_map.items():\n    db.update_node_properties(new_id, {'original_id': old_id})\n</code></pre>"},{"location":"integrations/networkx/#limitations","title":"Limitations","text":"<ul> <li>NetworkX graphs are in-memory; large graphs may require significant RAM</li> <li>Some NetworkX algorithms require specific graph types (undirected, weighted)</li> <li>Relationship direction is preserved in <code>MultiDiGraph</code></li> </ul>"},{"location":"integrations/rdf/","title":"RDF/Turtle Integration","text":"<p>Grafito can export to and import from RDF (Resource Description Framework) format.</p>"},{"location":"integrations/rdf/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install grafito[rdf]\n</code></pre> <p>This installs <code>rdflib</code> for RDF handling.</p>"},{"location":"integrations/rdf/#exporting-to-rdf","title":"Exporting to RDF","text":""},{"location":"integrations/rdf/#basic-export","title":"Basic Export","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.integrations import export_rdf, export_turtle\n\n# Create graph\ndb = GrafitoDatabase(':memory:')\nalice = db.create_node(labels=['Person'], properties={'name': 'Alice'})\nbob = db.create_node(labels=['Person'], properties={'name': 'Bob'})\ndb.create_relationship(alice.id, bob.id, 'KNOWS', {'since': 2021})\n\n# Export to RDFLib Graph\nrdf_graph = export_rdf(db, base_uri='grafito:')\n\nprint(f'Triples: {len(rdf_graph)}')\n</code></pre>"},{"location":"integrations/rdf/#export-to-turtle","title":"Export to Turtle","text":"<pre><code># Export to Turtle format\nturtle_str = export_turtle(\n    db,\n    base_uri='grafito:',\n    prefixes={\n        'schema': 'http://schema.org/',\n        'foaf': 'http://xmlns.com/foaf/0.1/'\n    }\n)\n\n# Save to file\nwith open('export.ttl', 'w') as f:\n    f.write(turtle_str)\n\nprint(turtle_str)\n</code></pre> <p>Output format: <pre><code>@prefix gr: &lt;grafito:&gt; .\n@prefix schema: &lt;http://schema.org/&gt; .\n\ngr:node_1 a schema:Person ;\n    schema:name \"Alice\" .\n\ngr:node_2 a schema:Person ;\n    schema:name \"Bob\" .\n\ngr:rel_1 a gr:KNOWS ;\n    schema:since 2021 ;\n    schema:source gr:node_1 ;\n    schema:target gr:node_2 .\n</code></pre></p>"},{"location":"integrations/rdf/#custom-namespace-mapping","title":"Custom Namespace Mapping","text":"<pre><code># Map labels to schema types\nturtle = export_turtle(\n    db,\n    base_uri='http://example.org/',\n    prefixes={'ex': 'http://example.org/'},\n    type_map={\n        'Person': 'http://schema.org/Person',\n        'Company': 'http://schema.org/Organization'\n    }\n)\n</code></pre>"},{"location":"integrations/rdf/#rdf-to-grafito","title":"RDF to Grafito","text":""},{"location":"integrations/rdf/#basic-import","title":"Basic Import","text":"<pre><code>from rdflib import Graph\nfrom grafito import GrafitoDatabase\n\n# Load RDF\nrdf_graph = Graph()\nrdf_graph.parse('data.ttl', format='turtle')\n\n# Convert to Grafito\ndb = GrafitoDatabase(':memory:')\n# Import functionality would be implemented here\n</code></pre>"},{"location":"integrations/rdf/#handling-common-vocabularies","title":"Handling Common Vocabularies","text":"<p>RDF export handles common vocabularies:</p> Grafito Concept RDF Mapping Node <code>rdfs:Resource</code> Label <code>rdf:type</code> Property Predicate Relationship Reified statement"},{"location":"integrations/rdf/#typed-rdf-export","title":"Typed RDF Export","text":"<pre><code>from grafito.integrations import export_typed_rdf\n\n# Export with type inference\nturtle = export_typed_rdf(\n    db,\n    base_uri='http://myapp.org/',\n    type_inference=True\n)\n</code></pre>"},{"location":"integrations/rdf/#ontology-export","title":"Ontology Export","text":"<p>Export schema as OWL/RDFS:</p> <pre><code>from grafito.integrations import export_ontology\n\n# Export schema\nturtle = export_ontology(\n    db,\n    base_uri='http://myapp.org/',\n    include_data=False  # Schema only\n)\n</code></pre>"},{"location":"integrations/rdf/#examples","title":"Examples","text":""},{"location":"integrations/rdf/#exporting-social-network","title":"Exporting Social Network","text":"<pre><code>db = GrafitoDatabase(':memory:')\n\n# Create social network\nalice = db.create_node(labels=['Person'], properties={'name': 'Alice', 'age': 30})\nbob = db.create_node(labels=['Person'], properties={'name': 'Bob', 'age': 25})\ncompany = db.create_node(labels=['Company'], properties={'name': 'TechCorp'})\n\ndb.create_relationship(alice.id, bob.id, 'FRIEND', {'since': 2020})\ndb.create_relationship(alice.id, company.id, 'WORKS_AT', {'role': 'Engineer'})\n\n# Export with FOAF vocabulary\nturtle = export_turtle(\n    db,\n    base_uri='http://example.org/',\n    prefixes={\n        'foaf': 'http://xmlns.com/foaf/0.1/',\n        'schema': 'http://schema.org/'\n    },\n    type_map={\n        'Person': 'foaf:Person',\n        'Company': 'schema:Organization'\n    }\n)\n\nprint(turtle)\n</code></pre>"},{"location":"integrations/rdf/#working-with-schemaorg","title":"Working with Schema.org","text":"<pre><code># Export using Schema.org vocabulary\nschema = {\n    'Person': 'http://schema.org/Person',\n    'name': 'http://schema.org/name',\n    'email': 'http://schema.org/email',\n    'KNOWS': 'http://schema.org/knows'\n}\n\nturtle = export_turtle(db, base_uri='https://example.com/', type_map=schema)\n</code></pre>"},{"location":"integrations/rdf/#limitations","title":"Limitations","text":"<ul> <li>RDF export reifies relationships (creates separate nodes for edges)</li> <li>Property types are mapped to RDF literals</li> <li>Multiple labels become multiple <code>rdf:type</code> statements</li> </ul>"},{"location":"integrations/visualization/","title":"Visualization","text":"<p>Grafito supports multiple visualization backends for exploring your graphs.</p>"},{"location":"integrations/visualization/#pyvis-interactive-html","title":"PyVis (Interactive HTML)","text":"<p>PyVis generates interactive web-based visualizations.</p>"},{"location":"integrations/visualization/#installation","title":"Installation","text":"<pre><code>pip install grafito[viz]\n# Or directly\npip install pyvis\n</code></pre>"},{"location":"integrations/visualization/#basic-export","title":"Basic Export","text":"<pre><code>from grafito import GrafitoDatabase\nfrom grafito.integrations import save_pyvis_html\n\n# Create sample data\ndb = GrafitoDatabase(':memory:')\nalice = db.create_node(labels=['Person'], properties={'name': 'Alice', 'group': 'A'})\nbob = db.create_node(labels=['Person'], properties={'name': 'Bob', 'group': 'B'})\ncharlie = db.create_node(labels=['Person'], properties={'name': 'Charlie', 'group': 'A'})\ndb.create_relationship(alice.id, bob.id, 'KNOWS')\ndb.create_relationship(bob.id, charlie.id, 'KNOWS')\n\n# Export to NetworkX first\ngraph = db.to_networkx()\n\n# Create PyVis visualization\nsave_pyvis_html(\n    graph,\n    path='graph.html',\n    node_label='name',           # Property to use as label\n    color_by_label=True,         # Color nodes by their labels\n    physics='compact'            # Physics preset: 'compact' or 'spread'\n)\n</code></pre>"},{"location":"integrations/visualization/#physics-presets","title":"Physics Presets","text":"Preset Best For <code>compact</code> Dense graphs, clusters <code>spread</code> Sparse graphs, clear separation"},{"location":"integrations/visualization/#custom-styling","title":"Custom Styling","text":"<pre><code>from grafito.integrations import save_pyvis_html\n\n# Group-based coloring\nsave_pyvis_html(\n    graph,\n    path='graph.html',\n    node_label='name',\n    color_by='group',           # Color by 'group' property\n    physics='spread'\n)\n</code></pre>"},{"location":"integrations/visualization/#advanced-pyvis-customization","title":"Advanced PyVis Customization","text":"<p>If you need deeper control over node/edge styling, use PyVis directly after exporting to NetworkX.</p>"},{"location":"integrations/visualization/#per-type-node-styling","title":"Per-Type Node Styling","text":"<pre><code>from pyvis.network import Network\n\ngraph = db.to_networkx()\nnet = Network(height=\"650px\", width=\"100%\", bgcolor=\"#ffffff\", font_color=\"black\")\n\nnode_colors = {\"ACTION\": \"#ffcc80\", \"OBSERVATION\": \"#e3f2fd\"}\n\nfor node_id, attrs in graph.nodes(data=True):\n    props = attrs.get(\"properties\", attrs)\n    ntype = props.get(\"type\", \"OBSERVATION\")\n    label = props.get(\"content\", \"\")[:20] + \"...\"\n    color = node_colors.get(ntype, \"#e3f2fd\")\n    shape = \"box\" if ntype == \"ACTION\" else \"ellipse\"\n    net.add_node(node_id, label=label, color=color, shape=shape)\n</code></pre>"},{"location":"integrations/visualization/#per-relationship-styling","title":"Per-Relationship Styling","text":"<pre><code>edge_colors = {\"TEMPORAL_NEXT\": \"#2962ff\", \"SEMANTIC\": \"#00c853\", \"ENTITY\": \"#d50000\"}\n\nfor source, target, attrs in graph.edges(data=True):\n    rel_type = attrs.get(\"type\")\n    color = edge_colors.get(rel_type, \"#aaaaaa\")\n    net.add_edge(source, target, color=color, label=rel_type, width=2)\n</code></pre>"},{"location":"integrations/visualization/#physics-tuning","title":"Physics Tuning","text":"<pre><code>net.barnes_hut(\n    gravity=-4000,\n    central_gravity=0.3,\n    spring_length=250,\n    spring_strength=0.05,\n    damping=0.09,\n)\n</code></pre>"},{"location":"integrations/visualization/#add-a-legend-optional","title":"Add a Legend (Optional)","text":"<pre><code>from IPython.display import HTML, display\n\nlegend_html = \"\"\"\n&lt;div style=\"font-family: sans-serif; margin-bottom: 10px; border: 1px solid #ddd; padding: 10px; border-radius: 5px; background: #f9f9f9;\"&gt;\n  &lt;strong&gt;Legend:&lt;/strong&gt;&lt;br&gt;\n  &lt;div style=\"display: flex; gap: 15px; flex-wrap: wrap; margin-top: 5px;\"&gt;\n    &lt;div&gt;&lt;span style=\"display:inline-block; width:12px; height:12px; background-color:#ffcc80; border:1px solid #333; margin-right:5px;\"&gt;&lt;/span&gt; Action (Box)&lt;/div&gt;\n    &lt;div&gt;&lt;span style=\"display:inline-block; width:12px; height:12px; background-color:#e3f2fd; border:1px solid #333; margin-right:5px; border-radius:50%;\"&gt;&lt;/span&gt; Observation (Ellipse)&lt;/div&gt;\n    &lt;div&gt;&lt;span style=\"color:#2962ff; font-weight:bold; margin-right:5px;\"&gt;\u2500\u2500\u2500&lt;/span&gt; Temporal&lt;/div&gt;\n    &lt;div&gt;&lt;span style=\"color:#00c853; font-weight:bold; margin-right:5px;\"&gt;\u2500\u2500\u2500&lt;/span&gt; Semantic&lt;/div&gt;\n    &lt;div&gt;&lt;span style=\"color:#d50000; font-weight:bold; margin-right:5px;\"&gt;\u2500\u2500\u2500&lt;/span&gt; Entity&lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\"\"\"\n\ndisplay(HTML(legend_html))\n</code></pre>"},{"location":"integrations/visualization/#d2-declarative-diagramming","title":"D2 (Declarative Diagramming)","text":"<p>D2 generates text-based diagrams that can be rendered to SVG/PNG.</p>"},{"location":"integrations/visualization/#installation_1","title":"Installation","text":"<pre><code># Install D2 CLI separately\nbrew install d2        # macOS\n# or\ncurl -fsSL https://d2.dev/install.sh | sh -s --\n</code></pre>"},{"location":"integrations/visualization/#basic-export_1","title":"Basic Export","text":"<pre><code>from grafito.integrations import export_graph\n\n# Export to D2 format\ngraph = db.to_networkx()\nexport_graph(\n    graph,\n    'graph.d2',\n    backend='d2',\n    node_label='name'\n)\n\n# Content looks like:\n# Alice: Alice\n# Bob: Bob\n# Alice -&gt; Bob: KNOWS\n</code></pre>"},{"location":"integrations/visualization/#render-with-d2","title":"Render with D2","text":"<pre><code># Export and render to SVG\nexport_graph(\n    graph,\n    'graph.d2',\n    backend='d2',\n    node_label='name',\n    render='svg'        # Requires D2 CLI\n)\n# Generates graph.svg\n</code></pre> <p>Note: The D2 renderer is a separate CLI and is not bundled with Grafito.</p>"},{"location":"integrations/visualization/#mermaid","title":"Mermaid","text":"<p>Mermaid is supported in Markdown and many documentation platforms.</p>"},{"location":"integrations/visualization/#basic-export_2","title":"Basic Export","text":"<pre><code>from grafito.integrations import export_graph\n\n# Export to Mermaid format\nexport_graph(\n    graph,\n    'graph.mmd',\n    backend='mermaid',\n    node_label='name'\n)\n\n# Content:\n# graph TD\n#     Alice[Alice]\n#     Bob[Bob]\n#     Alice --&gt;|KNOWS| Bob\n</code></pre>"},{"location":"integrations/visualization/#render","title":"Render","text":"<pre><code># Render with mermaid-cli (requires npm install -g @mermaid-js/mermaid-cli)\nexport_graph(\n    graph,\n    'graph.mmd',\n    backend='mermaid',\n    node_label='name',\n    render='svg'\n)\n</code></pre> <p>Note: Mermaid rendering requires <code>mmdc</code> (<code>npm i -g @mermaid-js/mermaid-cli</code>).</p>"},{"location":"integrations/visualization/#graphviz-dot","title":"Graphviz (DOT)","text":"<p>Graphviz is the classic graph visualization tool.</p>"},{"location":"integrations/visualization/#installation_2","title":"Installation","text":"<pre><code>brew install graphviz    # macOS\napt-get install graphviz # Ubuntu\n</code></pre>"},{"location":"integrations/visualization/#basic-export_3","title":"Basic Export","text":"<pre><code>from grafito.integrations import export_graph\n\n# Export to DOT format\nexport_graph(\n    graph,\n    'graph.dot',\n    backend='graphviz',\n    node_label='name'\n)\n</code></pre>"},{"location":"integrations/visualization/#render_1","title":"Render","text":"<pre><code># Export and render\nexport_graph(\n    graph,\n    'graph.dot',\n    backend='graphviz',\n    node_label='name',\n    render='svg'        # dot command must be in PATH\n)\n</code></pre> <p>Note: Graphviz rendering requires the <code>dot</code> CLI (<code>brew install graphviz</code>).</p>"},{"location":"integrations/visualization/#d3-self-contained-html","title":"D3 (Self-Contained HTML)","text":"<p>D3 export produces a standalone HTML file (no build step).</p> <pre><code>from grafito.integrations import export_graph\n\ngraph = db.to_networkx()\nexport_graph(\n    graph,\n    'graph.html',\n    backend='d3',\n    node_label='label_and_name'\n)\n</code></pre>"},{"location":"integrations/visualization/#cytoscapejs-self-contained-html","title":"Cytoscape.js (Self-Contained HTML)","text":"<p>Cytoscape export produces a standalone HTML file (no build step).</p> <pre><code>from grafito.integrations import export_graph\n\ngraph = db.to_networkx()\nexport_graph(\n    graph,\n    'graph.html',\n    backend='cytoscape',\n    node_label='label_and_name',\n    layout='cose'\n)\n</code></pre>"},{"location":"integrations/visualization/#comparison","title":"Comparison","text":"Backend Output Interactive Best For PyVis HTML \u2705 Yes Exploration, dashboards D2 Text/SVG \u274c No Documentation, version control Mermaid Markdown/SVG \u26a0\ufe0f Partial READMEs, docs integration Graphviz PNG/SVG/PDF \u274c No Publications, static diagrams D3 HTML \u2705 Yes Custom web views Cytoscape HTML \u2705 Yes Large graphs, rich UI"},{"location":"integrations/visualization/#backend-availability","title":"Backend Availability","text":"<pre><code>from grafito.integrations import available_viz_backends\n\nprint(available_viz_backends())\n# ['cytoscape', 'd2', 'd3', 'graphviz', 'mermaid', 'pyvis']\n</code></pre>"},{"location":"integrations/visualization/#large-graph-handling","title":"Large Graph Handling","text":"<p>For large graphs (&gt;1000 nodes):</p> <pre><code># Sample before visualizing\nall_nodes = list(graph.nodes())\nsample_size = min(100, len(all_nodes))\nsample_nodes = random.sample(all_nodes, sample_size)\nsubgraph = graph.subgraph(sample_nodes)\n\n# Export sample\nsave_pyvis_html(subgraph, 'sample.html')\n</code></pre>"},{"location":"integrations/visualization/#custom-visualization","title":"Custom Visualization","text":"<p>Build custom visualizations using the data directly:</p> <pre><code>import matplotlib.pyplot as plt\nimport networkx as nx\n\n# Export\ngraph = db.to_networkx()\n\n# Custom matplotlib plot\nplt.figure(figsize=(12, 8))\npos = nx.spring_layout(graph)\nnx.draw(graph, pos, with_labels=True, node_color='lightblue')\nplt.savefig('custom.png')\n</code></pre>"},{"location":"search/ann-backends/","title":"ANN Backends","text":"<p>Grafito supports multiple Approximate Nearest Neighbor (ANN) backends for vector search.</p>"},{"location":"search/ann-backends/#available-backends","title":"Available Backends","text":"Backend Install Best For Persistence FAISS <code>pip install grafito[faiss]</code> Production, most features \u2705 Yes Annoy <code>pip install grafito[annoy]</code> Large datasets, memory-mapped \u2705 Yes LEANN <code>pip install grafito[leann]</code> Fast builds, small datasets \u2705 Yes HNSWlib <code>pip install grafito[hnswlib]</code> High recall \u26a0\ufe0f Soft delete USearch <code>pip install grafito[usearch]</code> Modern, fast \u2705 Yes Voyager <code>pip install grafito[voyager]</code> Spotify's library \u2705 Yes Brute Force Built-in Small datasets, exact search \u274c No"},{"location":"search/ann-backends/#faiss","title":"FAISS","text":"<p>Facebook AI Similarity Search. Most feature-complete backend.</p>"},{"location":"search/ann-backends/#installation","title":"Installation","text":"<pre><code>pip install grafito[faiss]\n# Or with conda:\nconda install -c pytorch faiss-cpu\n</code></pre>"},{"location":"search/ann-backends/#methods","title":"Methods","text":"<pre><code># Flat (exact search)\ndb.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='faiss',\n    method='flat',\n    options={'metric': 'l2'}\n)\n\n# IVF (inverted file index)\ndb.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='faiss',\n    method='ivf_flat',\n    options={'nlist': 100, 'nprobe': 10}\n)\n\n# HNSW (hierarchical navigable small world)\ndb.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='faiss',\n    method='hnsw',\n    options={'hnsw_m': 16, 'ef_construction': 200}\n)\n</code></pre>"},{"location":"search/ann-backends/#persistence","title":"Persistence","text":"<pre><code>db.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='faiss',\n    method='flat',\n    options={'index_path': 'indexes/docs.faiss'}\n)\n</code></pre>"},{"location":"search/ann-backends/#annoy","title":"Annoy","text":"<p>Spotify's Approximate Nearest Neighbors Oh Yeah.</p>"},{"location":"search/ann-backends/#installation_1","title":"Installation","text":"<pre><code>pip install grafito[annoy]\n</code></pre>"},{"location":"search/ann-backends/#characteristics","title":"Characteristics","text":"<ul> <li>Memory-mapped indexes (shareable between processes)</li> <li>Good for read-heavy workloads</li> <li>Static indexes (rebuild to add vectors)</li> </ul> <pre><code>db.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='annoy',\n    method='annoy',\n    options={\n        'metric': 'angular',  # or 'euclidean', 'manhattan'\n        'n_trees': 50,        # More trees = more accurate, slower build\n        'index_path': 'indexes/docs.annoy'\n    }\n)\n</code></pre>"},{"location":"search/ann-backends/#leann","title":"LEANN","text":"<p>Lightweight Efficient Approximate Nearest Neighbors.</p>"},{"location":"search/ann-backends/#installation_2","title":"Installation","text":"<pre><code>pip install grafito[leann]\n</code></pre>"},{"location":"search/ann-backends/#characteristics_1","title":"Characteristics","text":"<ul> <li>Fast index building</li> <li>Good for small to medium datasets</li> <li>Auto-build control</li> </ul> <pre><code>db.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='leann',\n    method='leann',\n    options={\n        'metric': 'l2',\n        'auto_build': False,  # Disable auto-build\n        'index_path': 'indexes/docs.leann'\n    }\n)\n\n# Add embeddings...\n\n# Manual rebuild\ndb.rebuild_vector_index('docs')\n</code></pre>"},{"location":"search/ann-backends/#hnswlib","title":"HNSWlib","text":"<p>Hierarchical Navigable Small World implementation.</p>"},{"location":"search/ann-backends/#installation_3","title":"Installation","text":"<pre><code>pip install grafito[hnswlib]\n</code></pre>"},{"location":"search/ann-backends/#characteristics_2","title":"Characteristics","text":"<ul> <li>High recall rates</li> <li>Supports incremental adds</li> <li>Soft deletes (need rebuild to purge)</li> </ul> <pre><code>db.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='hnswlib',\n    method='hnswlib',\n    options={\n        'metric': 'l2',\n        'M': 16,\n        'ef_construction': 200,\n        'ef': 50\n    }\n)\n</code></pre> <p>Note</p> <p>HNSWlib uses soft deletes. Call <code>rebuild_vector_index()</code> to fully remove deleted vectors.</p>"},{"location":"search/ann-backends/#usearch","title":"USearch","text":"<p>Modern FAISS alternative by Unum.</p>"},{"location":"search/ann-backends/#installation_4","title":"Installation","text":"<pre><code>pip install grafito[usearch]\n</code></pre>"},{"location":"search/ann-backends/#characteristics_3","title":"Characteristics","text":"<ul> <li>Faster than FAISS for many workloads</li> <li>Smaller memory footprint</li> <li>Native persistence</li> </ul> <pre><code>db.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='usearch',\n    method='usearch',\n    options={\n        'metric': 'cos',\n        'connectivity': 16,\n        'expansion_add': 128,\n        'expansion_search': 64\n    }\n)\n</code></pre>"},{"location":"search/ann-backends/#voyager","title":"Voyager","text":"<p>Spotify's latest ANN library.</p>"},{"location":"search/ann-backends/#installation_5","title":"Installation","text":"<pre><code>pip install grafito[voyager]\n</code></pre>"},{"location":"search/ann-backends/#characteristics_4","title":"Characteristics","text":"<ul> <li>Multi-threaded index building</li> <li>Good for large-scale search</li> <li>EFIL (Enhanced Forward Index Layout)</li> </ul> <pre><code>db.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='voyager',\n    method='voyager',\n    options={\n        'space': 'cosine',  # or 'l2', 'ip'\n        'M': 16,\n        'ef_construction': 200,\n        'index_path': 'indexes/docs.voyager'\n    }\n)\n</code></pre>"},{"location":"search/ann-backends/#brute-force","title":"Brute Force","text":"<p>Built-in exact search for small datasets.</p> <pre><code># No extra installation needed\ndb.create_vector_index(\n    name='docs',\n    dim=384,\n    backend='bruteforce',\n    method='bruteforce',\n    options={'metric': 'l2'}\n)\n</code></pre> <p>Use for: - Datasets &lt; 1000 vectors - When exact results are required - Testing and debugging</p>"},{"location":"search/ann-backends/#backend-comparison","title":"Backend Comparison","text":"Feature FAISS Annoy LEANN HNSWlib USearch Voyager Incremental adds \u2705 \u274c \u2705 \u2705 \u2705 \u2705 GPU support \u2705* \u274c \u274c \u274c \u274c \u274c Memory mapped \u2705 \u2705 \u274c \u274c \u2705 \u2705 Cosine similarity \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Inner product \u2705 \u274c \u2705 \u2705 \u2705 \u2705 L2 distance \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 <p>*Requires faiss-gpu (conda)</p>"},{"location":"search/ann-backends/#choosing-a-backend","title":"Choosing a Backend","text":""},{"location":"search/ann-backends/#small-dataset-10k-vectors","title":"Small Dataset (&lt; 10K vectors)","text":"<pre><code># Brute force or FAISS flat\ndb.create_vector_index(..., backend='bruteforce', method='bruteforce')\n# or\ndb.create_vector_index(..., backend='faiss', method='flat')\n</code></pre>"},{"location":"search/ann-backends/#medium-dataset-10k-100k","title":"Medium Dataset (10K - 100K)","text":"<pre><code># FAISS IVF or HNSW\ndb.create_vector_index(..., backend='faiss', method='ivf_flat')\n# or\ndb.create_vector_index(..., backend='faiss', method='hnsw')\n</code></pre>"},{"location":"search/ann-backends/#large-dataset-100k","title":"Large Dataset (&gt; 100K)","text":"<pre><code># Annoy (memory-mapped) or Voyager\ndb.create_vector_index(..., backend='annoy', method='annoy')\n# or\ndb.create_vector_index(..., backend='voyager', method='voyager')\n</code></pre>"},{"location":"search/ann-backends/#read-heavy-workloads","title":"Read-Heavy Workloads","text":"<pre><code># Annoy with memory mapping\ndb.create_vector_index(..., backend='annoy', method='annoy',\n                       options={'index_path': 'shared.annoy'})\n</code></pre>"},{"location":"search/ann-backends/#write-heavy-workloads","title":"Write-Heavy Workloads","text":"<pre><code># FAISS HNSW or HNSWlib\ndb.create_vector_index(..., backend='faiss', method='hnsw')\n</code></pre>"},{"location":"search/ann-backends/#checking-available-backends","title":"Checking Available Backends","text":"<pre><code>from grafito.integrations import available_vector_backends\n\nprint(available_vector_backends())\n# ['bruteforce', 'faiss', 'annoy', 'leann', 'hnswlib', 'usearch', 'voyager']\n</code></pre>"},{"location":"search/fulltext/","title":"Full-Text Search (FTS5)","text":"<p>Grafito provides full-text search capabilities using SQLite's FTS5 extension.</p>"},{"location":"search/fulltext/#prerequisites","title":"Prerequisites","text":"<p>FTS5 must be enabled in your SQLite build:</p> <pre><code>from grafito import GrafitoDatabase\n\ndb = GrafitoDatabase(':memory:')\n\nif not db.has_fts5():\n    raise RuntimeError(\"FTS5 not available. Install SQLite with FTS5 support.\")\n</code></pre>"},{"location":"search/fulltext/#creating-text-indexes","title":"Creating Text Indexes","text":""},{"location":"search/fulltext/#node-text-index","title":"Node Text Index","text":"<pre><code># Index specific properties on nodes with a label\ndb.create_text_index(\n    entity_type='node',\n    label='Person',\n    properties=['name', 'bio', 'description']\n)\n</code></pre>"},{"location":"search/fulltext/#relationship-text-index","title":"Relationship Text Index","text":"<pre><code># Index properties on relationships\ndb.create_text_index(\n    entity_type='relationship',\n    rel_type='COMMENT',\n    properties=['text', 'title']\n)\n</code></pre>"},{"location":"search/fulltext/#multiple-indexes","title":"Multiple Indexes","text":"<pre><code># Create indexes for different entity types\ndb.create_text_index('node', 'Article', ['title', 'content', 'tags'])\ndb.create_text_index('node', 'Product', ['name', 'description'])\ndb.create_text_index('relationship', 'REVIEW', ['comment'])\n</code></pre>"},{"location":"search/fulltext/#building-the-index","title":"Building the Index","text":"<p>After configuring indexes, rebuild to index existing data:</p> <pre><code># Index all existing data\ndb.rebuild_text_index()\n\n# Future inserts/updates are indexed automatically\n</code></pre>"},{"location":"search/fulltext/#searching","title":"Searching","text":""},{"location":"search/fulltext/#basic-search","title":"Basic Search","text":"<pre><code># Search across all indexed text\nresults = db.text_search('python developer', k=10)\n\nfor result in results:\n    print(f\"Score: {result.score}\")\n    print(f\"Node: {result.node}\")\n    print(f\"Matched properties: {result.matched_properties}\")\n</code></pre>"},{"location":"search/fulltext/#filtered-search","title":"Filtered Search","text":"<pre><code># Search only within specific labels\nresults = db.text_search(\n    query='machine learning',\n    k=10,\n    labels=['Article', 'Paper']\n)\n\n# Search with property filter\nresults = db.text_search(\n    query='database',\n    k=10,\n    labels=['Article'],\n    properties={'status': 'published'}\n)\n</code></pre>"},{"location":"search/fulltext/#search-results","title":"Search Results","text":"<pre><code>results = db.text_search('graph database', k=5)\n\nfor r in results:\n    print(f\"ID: {r.node.id}\")\n    print(f\"Labels: {r.node.labels}\")\n    print(f\"BM25 Score: {r.score}\")\n    print(f\"Properties: {r.node.properties}\")\n</code></pre>"},{"location":"search/fulltext/#query-syntax","title":"Query Syntax","text":""},{"location":"search/fulltext/#basic-terms","title":"Basic Terms","text":"<pre><code># Single term\ndb.text_search('python')\n\n# Multiple terms (AND implied)\ndb.text_search('python graph')\n\n# Exact phrase\ndb.text_search('\"machine learning\"')\n</code></pre>"},{"location":"search/fulltext/#boolean-operators","title":"Boolean Operators","text":"<pre><code># AND (default)\ndb.text_search('python AND graph')\n\n# OR\ndb.text_search('python OR javascript')\n\n# NOT\ndb.text_search('database NOT sql')\n\n# Combined\ndb.text_search('(python OR javascript) AND web')\n</code></pre>"},{"location":"search/fulltext/#prefix-matching","title":"Prefix Matching","text":"<pre><code># Match words starting with 'dev'\ndb.text_search('dev*')\n\n# Match 'graph' prefix\ndb.text_search('graph* database')\n</code></pre>"},{"location":"search/fulltext/#near-operator","title":"NEAR Operator","text":"<pre><code># Terms within 10 words of each other\ndb.text_search('python NEAR/10 database')\n\n# Terms within 5 words\ndb.text_search('machine NEAR/5 learning')\n</code></pre>"},{"location":"search/fulltext/#bm25-ranking","title":"BM25 Ranking","text":"<p>FTS5 uses BM25 ranking by default. Scores are higher for better matches.</p> <pre><code>results = db.text_search('python', k=10)\n\n# Results sorted by BM25 score (descending)\nfor i, r in enumerate(results, 1):\n    print(f\"{i}. {r.node.properties['title']} (score: {r.score:.3f})\")\n</code></pre>"},{"location":"search/fulltext/#integration-with-cypher","title":"Integration with Cypher","text":"<pre><code># Hybrid: Text search + graph pattern\nresults = db.text_search('database', k=20)\nnode_ids = [r.node.id for r in results]\n\n# Then query relationships\ncypher_results = db.execute(\"\"\"\n    MATCH (n)-[:AUTHORED]-&gt;(author:Person)\n    WHERE id(n) IN $node_ids\n    RETURN n.title, author.name\n\"\"\", {'node_ids': node_ids})\n</code></pre>"},{"location":"search/fulltext/#best-practices","title":"Best Practices","text":""},{"location":"search/fulltext/#1-choose-properties-wisely","title":"1. Choose Properties Wisely","text":"<pre><code># Index meaningful text fields\ndb.create_text_index('node', 'Article', [\n    'title',      # Good: descriptive\n    'content',    # Good: searchable body\n    # 'id',       # Skip: not meaningful for search\n    # 'url',      # Skip: usually not helpful\n])\n</code></pre>"},{"location":"search/fulltext/#2-rebuild-after-bulk-import","title":"2. Rebuild After Bulk Import","text":"<pre><code># After importing large dataset\ndb.rebuild_text_index()\n</code></pre>"},{"location":"search/fulltext/#3-combine-with-property-filters","title":"3. Combine with Property Filters","text":"<pre><code># Narrow search space first\nresults = db.text_search(\n    'python',\n    k=10,\n    labels=['Article'],\n    properties={'published': True, 'language': 'en'}\n)\n</code></pre>"},{"location":"search/fulltext/#4-handle-empty-results","title":"4. Handle Empty Results","text":"<pre><code>results = db.text_search('xyzabc123', k=10)\n\nif not results:\n    print(\"No matches found\")\n    # Fall back to different query or show suggestions\n</code></pre>"},{"location":"search/fulltext/#limitations","title":"Limitations","text":"<ol> <li>FTS5 Required: Not available in all SQLite builds</li> <li>Tokenization: Uses SQLite's default tokenizer (unicode61)</li> <li>No Fuzzy Matching: Exact and prefix matches only</li> <li>Single Language: Best for one language per index</li> </ol>"},{"location":"search/fulltext/#troubleshooting","title":"Troubleshooting","text":""},{"location":"search/fulltext/#no-results","title":"No Results","text":"<pre><code># Check if FTS5 is available\nprint(db.has_fts5())\n\n# Check if index exists\nprint(db.list_text_indexes())\n\n# Rebuild index\ndb.rebuild_text_index()\n</code></pre>"},{"location":"search/fulltext/#poor-ranking","title":"Poor Ranking","text":"<pre><code># BM25 scores can be negative (lower is better in FTS5)\n# Grafito normalizes to positive scores\n# Check raw scores to debug\nresults = db.text_search('term', k=10)\nfor r in results:\n    print(f\"Score: {r.score}\")\n</code></pre>"},{"location":"search/hybrid/","title":"Hybrid Search Workflows","text":"<p>Combining full-text search (BM25) with vector search for better results.</p>"},{"location":"search/hybrid/#why-hybrid-search","title":"Why Hybrid Search?","text":"Search Type Strengths Weaknesses Full-Text (BM25) Exact keyword matching, fast No semantic understanding Vector Semantic similarity, conceptual Misses exact keyword matches Hybrid Best of both worlds More complex, slightly slower"},{"location":"search/hybrid/#basic-hybrid-search","title":"Basic Hybrid Search","text":""},{"location":"search/hybrid/#reciprocal-rank-fusion-rrf","title":"Reciprocal Rank Fusion (RRF)","text":"<pre><code>def hybrid_search_rrf(db, query, query_vec, k=10, rank_k=60):\n    \"\"\"\n    Combine BM25 and vector results using RRF.\n    rank_k: constant for RRF formula (typically 60)\n    \"\"\"\n    # Get keyword results\n    text_results = db.text_search(query, k=50)\n    text_ids = {r.node.id: 1/(rank_k + i) for i, r in enumerate(text_results)}\n\n    # Get vector results\n    vec_results = db.semantic_search(query_vec, k=50, index='articles_vec')\n    vec_ids = {r.node.id: 1/(rank_k + i) for i, r in enumerate(vec_results)}\n\n    # Combine scores\n    all_ids = set(text_ids.keys()) | set(vec_ids.keys())\n    scores = {id: text_ids.get(id, 0) + vec_ids.get(id, 0) for id in all_ids}\n\n    # Get top k\n    top_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)[:k]\n\n    # Fetch nodes\n    results = []\n    for node_id in top_ids:\n        node = db.get_node(node_id)\n        results.append({\n            'node': node,\n            'score': scores[node_id],\n            'text_rank': text_ids.get(node_id),\n            'vector_rank': vec_ids.get(node_id)\n        })\n\n    return results\n</code></pre>"},{"location":"search/hybrid/#weighted-combination","title":"Weighted Combination","text":"<pre><code>def hybrid_search_weighted(db, query, query_vec, text_weight=0.3, vec_weight=0.7, k=10):\n    \"\"\"Combine with configurable weights.\"\"\"\n    # Normalize scores to [0, 1]\n    text_results = db.text_search(query, k=50)\n    max_text_score = max((r.score for r in text_results), default=1)\n    text_scores = {r.node.id: (r.score / max_text_score) * text_weight\n                   for r in text_results}\n\n    vec_results = db.semantic_search(query_vec, k=50, index='articles_vec')\n    max_vec_score = max((r.score for r in vec_results), default=1)\n    vec_scores = {r.node.id: (r.score / max_vec_score) * vec_weight\n                  for r in vec_results}\n\n    # Combine\n    all_ids = set(text_scores.keys()) | set(vec_scores.keys())\n    combined = {id: text_scores.get(id, 0) + vec_scores.get(id, 0)\n                for id in all_ids}\n\n    # Return top k\n    top_ids = sorted(combined.keys(), key=lambda x: combined[x], reverse=True)[:k]\n    return [{'node': db.get_node(id), 'score': combined[id]} for id in top_ids]\n</code></pre>"},{"location":"search/hybrid/#advanced-hybrid-patterns","title":"Advanced Hybrid Patterns","text":""},{"location":"search/hybrid/#cascade-search","title":"Cascade Search","text":"<pre><code>def cascade_search(db, query, query_vec, k=10):\n    \"\"\"Use fast text search first, then rerank with vectors.\"\"\"\n    # Stage 1: Fast keyword search to get candidates\n    candidates = db.text_search(query, k=100)\n    candidate_ids = [r.node.id for r in candidates]\n\n    # Stage 2: Rerank with vectors\n    results = []\n    for node_id in candidate_ids:\n        # Get vector for this node (must be stored)\n        vec_result = db.execute(\"\"\"\n            SELECT vector FROM vector_entries\n            WHERE node_id = $id AND index_name = 'articles_vec'\n        \"\"\", {'id': node_id})\n\n        if vec_result:\n            node_vec = vec_result[0]['vector']\n            # Calculate similarity\n            score = cosine_similarity(query_vec, node_vec)\n            results.append({'node_id': node_id, 'score': score})\n\n    # Return top k\n    results.sort(key=lambda x: x['score'], reverse=True)\n    return [db.get_node(r['node_id']) for r in results[:k]]\n</code></pre>"},{"location":"search/hybrid/#filtered-hybrid","title":"Filtered Hybrid","text":"<pre><code>def filtered_hybrid_search(db, query, query_vec, filters, k=10):\n    \"\"\"Apply filters before hybrid search.\"\"\"\n    # Pre-filter with properties\n    base_results = db.text_search(\n        query,\n        k=100,\n        labels=['Article'],\n        properties=filters  # e.g., {'category': 'tech', 'published': True}\n    )\n\n    # Get filtered IDs\n    filtered_ids = {r.node.id for r in base_results}\n\n    # Vector search with same filters\n    vec_results = db.semantic_search(\n        query_vec,\n        k=100,\n        index='articles_vec',\n        labels=['Article'],\n        properties=filters\n    )\n\n    # Combine only filtered results\n    # ... RRF or weighted combination ...\n</code></pre>"},{"location":"search/hybrid/#reranking-strategies","title":"Reranking Strategies","text":""},{"location":"search/hybrid/#cross-encoder-reranking","title":"Cross-Encoder Reranking","text":"<pre><code>def rerank_with_cross_encoder(db, query, initial_results, k=10):\n    \"\"\"Use cross-encoder for final reranking.\"\"\"\n    from sentence_transformers import CrossEncoder\n\n    model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n\n    # Prepare pairs\n    pairs = [(query, r['node'].properties['content']) for r in initial_results]\n\n    # Score\n    scores = model.predict(pairs)\n\n    # Rerank\n    for r, score in zip(initial_results, scores):\n        r['rerank_score'] = score\n\n    initial_results.sort(key=lambda x: x['rerank_score'], reverse=True)\n    return initial_results[:k]\n</code></pre>"},{"location":"search/hybrid/#metadata-boosting","title":"Metadata Boosting","text":"<pre><code>def boost_by_metadata(results, boost_rules):\n    \"\"\"Boost scores based on metadata.\"\"\"\n    for r in results:\n        boost = 1.0\n        node = r['node']\n\n        # Boost recent content\n        if 'created_at' in node.properties:\n            age_days = (now() - node.properties['created_at']).days\n            if age_days &lt; 7:\n                boost *= 1.2\n\n        # Boost by popularity\n        if 'views' in node.properties:\n            if node.properties['views'] &gt; 1000:\n                boost *= 1.1\n\n        # Boost by author reputation\n        if 'author_verified' in node.properties:\n            boost *= 1.15\n\n        r['score'] *= boost\n\n    return sorted(results, key=lambda x: x['score'], reverse=True)\n</code></pre>"},{"location":"search/hybrid/#complete-example","title":"Complete Example","text":"<pre><code>from grafito import GrafitoDatabase\nfrom sentence_transformers import SentenceTransformer\n\nclass HybridSearcher:\n    def __init__(self, db_path):\n        self.db = GrafitoDatabase(db_path)\n        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n\n    def search(self, query, k=10, method='rrf'):\n        # Encode query\n        query_vec = self.model.encode(query).tolist()\n\n        # Get results from both methods\n        text_results = self.db.text_search(query, k=50)\n        vec_results = self.db.semantic_search(\n            query_vec, k=50, index='articles_vec'\n        )\n\n        if method == 'rrf':\n            return self._rrf_merge(text_results, vec_results, k)\n        elif method == 'weighted':\n            return self._weighted_merge(text_results, vec_results, k)\n\n    def _rrf_merge(self, text_results, vec_results, k, rank_k=60):\n        \"\"\"Reciprocal Rank Fusion.\"\"\"\n        scores = {}\n\n        for i, r in enumerate(text_results):\n            scores[r.node.id] = scores.get(r.node.id, 0) + 1/(rank_k + i)\n\n        for i, r in enumerate(vec_results):\n            scores[r.node.id] = scores.get(r.node.id, 0) + 1/(rank_k + i)\n\n        top_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)[:k]\n\n        return [{\n            'node': self.db.get_node(id),\n            'rrf_score': scores[id]\n        } for id in top_ids]\n\n    def _weighted_merge(self, text_results, vec_results, k):\n        \"\"\"Weighted score combination.\"\"\"\n        text_weight, vec_weight = 0.3, 0.7\n\n        # Normalize\n        max_text = max((r.score for r in text_results), default=1)\n        max_vec = max((r.score for r in vec_results), default=1)\n\n        scores = {}\n        for r in text_results:\n            scores[r.node.id] = (r.score / max_text) * text_weight\n        for r in vec_results:\n            scores[r.node.id] = scores.get(r.node.id, 0) + (r.score / max_vec) * vec_weight\n\n        top_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)[:k]\n\n        return [{\n            'node': self.db.get_node(id),\n            'score': scores[id]\n        } for id in top_ids]\n\n# Usage\nsearcher = HybridSearcher('mydb.db')\nresults = searcher.search('python graph database', k=10, method='rrf')\n\nfor r in results:\n    print(f\"{r['node'].properties['title']}: {r.get('rrf_score', r.get('score')):.3f}\")\n</code></pre>"},{"location":"search/hybrid/#evaluation","title":"Evaluation","text":""},{"location":"search/hybrid/#measuring-quality","title":"Measuring Quality","text":"<pre><code>def evaluate_search(db, test_queries, ground_truth):\n    \"\"\"\n    Evaluate search quality.\n    test_queries: list of query strings\n    ground_truth: dict mapping query to list of relevant doc IDs\n    \"\"\"\n    from sklearn.metrics import ndcg_score\n\n    results = {}\n    for query in test_queries:\n        # Get search results\n        search_results = hybrid_search(db, query, model.encode(query))\n        retrieved_ids = [r['node'].id for r in search_results]\n\n        # Calculate metrics\n        relevant = ground_truth[query]\n        precision = len(set(retrieved_ids) &amp; set(relevant)) / len(retrieved_ids)\n        recall = len(set(retrieved_ids) &amp; set(relevant)) / len(relevant)\n\n        results[query] = {\n            'precision': precision,\n            'recall': recall,\n            'f1': 2 * (precision * recall) / (precision + recall)\n        }\n\n    return results\n</code></pre>"},{"location":"search/hybrid/#best-practices","title":"Best Practices","text":"<ol> <li>Tune Weights: Adjust text/vector weights based on your data</li> <li>Candidate Pool: Use larger k for initial retrieval (50-100)</li> <li>Reranking: Apply cross-encoders or metadata boosting for final ranking</li> <li>Caching: Cache query embeddings for repeated queries</li> <li>A/B Testing: Compare hybrid vs single-method search</li> </ol>"},{"location":"search/hybrid/#when-to-use-hybrid","title":"When to Use Hybrid","text":"Scenario Recommendation Technical documentation \u2705 Hybrid (keywords matter) Semantic Q&amp;A \u2705 Hybrid (concepts + keywords) E-commerce search \u2705 Hybrid (product names + intent) Pure semantic similarity \u274c Vector only Log analysis \u274c Text only"},{"location":"search/vector/","title":"Semantic/Vector Search","text":"<p>Grafito supports semantic search using vector embeddings and approximate nearest neighbor (ANN) search.</p>"},{"location":"search/vector/#overview","title":"Overview","text":"<p>Vector search allows you to: - Find semantically similar content - Implement recommendation systems - Build RAG (Retrieval-Augmented Generation) pipelines - Combine semantic and keyword search</p>"},{"location":"search/vector/#creating-vector-indexes","title":"Creating Vector Indexes","text":""},{"location":"search/vector/#basic-faiss-index","title":"Basic FAISS Index","text":"<pre><code># Create a flat (exact) index\ndb.create_vector_index(\n    name='articles_vec',\n    dim=384,                    # Embedding dimension\n    backend='faiss',\n    method='flat',\n    options={'metric': 'l2'}    # L2 distance\n)\n</code></pre>"},{"location":"search/vector/#ivf-index-approximate","title":"IVF Index (Approximate)","text":"<pre><code># Faster search, approximate results\ndb.create_vector_index(\n    name='articles_vec',\n    dim=384,\n    backend='faiss',\n    method='ivf_flat',\n    options={\n        'metric': 'l2',\n        'nlist': 100,      # Number of clusters\n        'nprobe': 10       # Clusters to search\n    }\n)\n</code></pre>"},{"location":"search/vector/#hnsw-index","title":"HNSW Index","text":"<pre><code># Graph-based ANN (good balance)\ndb.create_vector_index(\n    name='articles_vec',\n    dim=384,\n    backend='faiss',\n    method='hnsw',\n    options={\n        'metric': 'l2',\n        'hnsw_m': 16,           # Connections per node\n        'ef_construction': 200,  # Build-time search depth\n        'ef_search': 64          # Query-time search depth\n    }\n)\n</code></pre>"},{"location":"search/vector/#persistent-index","title":"Persistent Index","text":"<pre><code># Save index to disk\ndb.create_vector_index(\n    name='articles_vec',\n    dim=384,\n    backend='faiss',\n    method='flat',\n    options={\n        'metric': 'l2',\n        'index_path': '.grafito/indexes/articles.faiss'\n    }\n)\n</code></pre>"},{"location":"search/vector/#adding-embeddings","title":"Adding Embeddings","text":""},{"location":"search/vector/#single-embedding","title":"Single Embedding","text":"<pre><code># Get embedding from your model\nembedding = model.encode(\"Python graph databases\")  # [0.1, -0.2, ...]\n\n# Upsert into index\ndb.upsert_embedding(\n    node_id=article.id,\n    vector=embedding.tolist(),\n    index='articles_vec'\n)\n</code></pre>"},{"location":"search/vector/#batch-upsert","title":"Batch Upsert","text":"<pre><code># Efficient batch insertion\nwith db:\n    for article in articles:\n        embedding = model.encode(article['content'])\n        db.upsert_embedding(\n            node_id=article['id'],\n            vector=embedding.tolist(),\n            index='articles_vec'\n        )\n</code></pre>"},{"location":"search/vector/#with-stored-vectors","title":"With Stored Vectors","text":"<pre><code># Also store raw vectors in SQLite\ndb.create_vector_index(\n    name='articles_vec',\n    dim=384,\n    backend='faiss',\n    method='flat',\n    options={'store_embeddings': True}  # Persist in SQLite\n)\n</code></pre>"},{"location":"search/vector/#searching","title":"Searching","text":""},{"location":"search/vector/#basic-semantic-search","title":"Basic Semantic Search","text":"<pre><code># Encode query\nquery = \"How to build graph applications\"\nquery_vec = model.encode(query).tolist()\n\n# Search\nresults = db.semantic_search(\n    query_vector=query_vec,\n    k=10,\n    index='articles_vec'\n)\n\nfor r in results:\n    print(f\"Score: {r.score:.3f}\")\n    print(f\"Title: {r.node.properties['title']}\")\n</code></pre>"},{"location":"search/vector/#filtered-search","title":"Filtered Search","text":"<pre><code># Search within specific labels\nresults = db.semantic_search(\n    query_vector=query_vec,\n    k=10,\n    index='articles_vec',\n    labels=['Article', 'Tutorial']\n)\n\n# Search with property filter\nresults = db.semantic_search(\n    query_vector=query_vec,\n    k=10,\n    index='articles_vec',\n    labels=['Article'],\n    properties={'published': True}\n)\n</code></pre>"},{"location":"search/vector/#with-reranking","title":"With Reranking","text":"<pre><code># Use custom reranker\ndef my_reranker(query_vector, candidates):\n    # candidates: [{\"id\": int, \"vector\": [...], \"score\": float, \"node\": Node}, ...]\n    # Return re-ranked list\n    return [{\"id\": c[\"id\"], \"score\": c[\"score\"] * 1.1} for c in candidates]\n\n# Register and use\ndb.register_reranker('custom', my_reranker)\nresults = db.semantic_search(\n    query_vector=query_vec,\n    k=10,\n    index='articles_vec',\n    reranker='custom'\n)\n</code></pre>"},{"location":"search/vector/#cypher-integration","title":"Cypher Integration","text":""},{"location":"search/vector/#vector-search-procedure","title":"Vector Search Procedure","text":"<pre><code>results = db.execute(\"\"\"\n    CALL db.vector.search('articles_vec', $query_vec, 10, {labels: ['Article']})\n    YIELD node, score\n    RETURN node.title, score\n\"\"\", {'query_vec': query_vec})\n</code></pre>"},{"location":"search/vector/#formatting-vectors-for-cypher","title":"Formatting Vectors for Cypher","text":"<pre><code>from grafito.cypher import format_vector_literal\n\n# Format vector for Cypher query\nvector_str = format_vector_literal(query_vec, precision=8)\n\ncypher = f\"\"\"\n    CALL db.vector.search('articles_vec', {vector_str}, 5)\n    YIELD node, score\n    RETURN node.title, score\n\"\"\"\n\nresults = db.execute(cypher)\n</code></pre>"},{"location":"search/vector/#distance-metrics","title":"Distance Metrics","text":"Metric Use Case Backend Support <code>l2</code> Euclidean distance All <code>ip</code> Inner product (for normalized vectors) All <code>cosine</code> Cosine similarity FAISS, usearch <pre><code># Cosine similarity (for normalized embeddings)\ndb.create_vector_index(\n    name='articles_vec',\n    dim=384,\n    backend='faiss',\n    method='flat',\n    options={'metric': 'ip'}  # For normalized vectors\n)\n</code></pre>"},{"location":"search/vector/#default-k-values","title":"Default k Values","text":"<pre><code># Global default\ndb = GrafitoDatabase(':memory:', default_top_k=20)\n\n# Per-index default\ndb.create_vector_index(\n    name='articles_vec',\n    dim=384,\n    backend='faiss',\n    method='flat',\n    options={'metric': 'l2', 'default_k': 5}\n)\n\n# Uses index default (5)\nresults = db.semantic_search(query_vec, index='articles_vec')\n\n# Override default\nresults = db.semantic_search(query_vec, k=10, index='articles_vec')\n</code></pre>"},{"location":"search/vector/#best-practices","title":"Best Practices","text":""},{"location":"search/vector/#1-choose-right-backend","title":"1. Choose Right Backend","text":"<pre><code># Small dataset (&lt;10K): Brute force or flat\n# Medium (10K-100K): IVF or HNSW\n# Large (&gt;100K): HNSW with persistence\n</code></pre>"},{"location":"search/vector/#2-normalize-for-cosine","title":"2. Normalize for Cosine","text":"<pre><code>import numpy as np\n\n# Normalize embeddings for cosine similarity\nembedding = model.encode(text)\nembedding = embedding / np.linalg.norm(embedding)\n\ndb.upsert_embedding(node_id, embedding.tolist(), index='articles_vec')\n</code></pre>"},{"location":"search/vector/#3-batch-operations","title":"3. Batch Operations","text":"<pre><code># Build index in batches\nbatch_size = 1000\nfor i in range(0, len(articles), batch_size):\n    batch = articles[i:i+batch_size]\n    with db:\n        for article in batch:\n            emb = model.encode(article['content'])\n            db.upsert_embedding(article['id'], emb.tolist(), 'articles_vec')\n</code></pre>"},{"location":"search/vector/#4-hybrid-search","title":"4. Hybrid Search","text":"<pre><code># Combine keyword + semantic\nkeyword_results = db.text_search('python graph', k=20)\nsemantic_results = db.semantic_search(query_vec, k=20, index='articles_vec')\n\n# Merge and deduplicate\nall_ids = set()\nfor r in keyword_results + semantic_results:\n    all_ids.add(r.node.id)\n</code></pre>"},{"location":"search/vector/#troubleshooting","title":"Troubleshooting","text":""},{"location":"search/vector/#index-not-found","title":"Index Not Found","text":"<pre><code># List available indexes\nprint(db.list_vector_indexes())\n</code></pre>"},{"location":"search/vector/#wrong-dimension","title":"Wrong Dimension","text":"<pre><code># Check dimension mismatch\n# Error: \"Vector dimension 768 does not match index dimension 384\"\n# Solution: Create index with correct dimension or resize embeddings\n</code></pre>"},{"location":"search/vector/#empty-results","title":"Empty Results","text":"<pre><code># Check if embeddings exist\nresults = db.execute(\"SELECT COUNT(*) FROM vector_entries WHERE index_name = 'articles_vec'\")\n\n# Rebuild if needed\nfor node in db.match_nodes(labels=['Article']):\n    emb = model.encode(node.properties['content'])\n    db.upsert_embedding(node.id, emb.tolist(), 'articles_vec')\n</code></pre>"}]}